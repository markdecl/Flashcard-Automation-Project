{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proj_dir = 'C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy'\n",
    "\n",
    "support_files_dir = 'C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests \\\\computer science (technical)\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\General support files'\n",
    "\n",
    "desktop_dir = 'C:\\\\Users\\\\MdeCL\\\\Desktop\\\\Vocab Project Desktop Files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define source and target languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_lang = 'ru'\n",
    "target_lang = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MdeCL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MdeCL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MdeCL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import math\n",
    "\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "eng_stop_words = set(stopwords.words('english'))\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from pyinflect import getAllInflections, getInflection\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "ru_stemmer = SnowballStemmer(\"russian\") \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "english_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "from wiktionaryparser import WiktionaryParser\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from inspect import currentframe, getframeinfo\n",
    "from pandas.core.common import SettingWithCopyError\n",
    "import numpy as np\n",
    "from translate.storage.tmx import tmxfile\n",
    "import seaborn as sns\n",
    "\n",
    "import genanki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Russian National Corpus frequency list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poss_in_full = {\n",
    "    '(v)' : 'verb',\n",
    "    '(pr)' : 'preposition',\n",
    "    '(conj)' : 'conjunction',\n",
    "    '(apro)' : 'pronoun',\n",
    "    '(spro)' : 'pronoun',\n",
    "    '(s)' : 'noun',\n",
    "    '(part)' : 'particle',\n",
    "    '(a)' : 'adjective',\n",
    "    '(adv)' : 'adverb',\n",
    "    '(advpro)' : 'adverb',\n",
    "    '(anum)' : 'numeral',\n",
    "    '(num)' : 'numeral',\n",
    "    '(intj)' : 'interjection',\n",
    "    '(v)f' : 'verb'\n",
    "}\n",
    "\n",
    "freq_ranks = []\n",
    "words = []\n",
    "pos_tags = []\n",
    "\n",
    "with open(\"C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\ru_nat_corpus_freq_list.txt\", 'r', encoding='utf8') as file:\n",
    "    file_read = file.read()\n",
    "    lines = file_read.split('\\n')\n",
    "    idx = 1\n",
    "    for line in lines:\n",
    "        freq_rank = idx\n",
    "        freq_ranks.append(freq_rank)\n",
    "        bare_word = line.split(' ')[0]\n",
    "        words.append(bare_word)\n",
    "        pos_tag = line.split(' ')[1]\n",
    "        pos_tags.append(poss_in_full[pos_tag])\n",
    "        \n",
    "        idx += 1\n",
    "        \n",
    "est_freqs_df = pd.read_csv(desktop_dir + '\\\\freqs.csv')\n",
    "freqs_list = est_freqs_df.head(len(freq_ranks))['Frequency'].to_list()\n",
    "freqs_list = [round(item) for item in freqs_list]\n",
    "        \n",
    "rnc_freq_list = pd.DataFrame({'Frequency rank' : freq_ranks, 'Estimated frequency' : freqs_list, 'Word' : words, 'PoS tag' : pos_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency rank</th>\n",
       "      <th>Estimated frequency</th>\n",
       "      <th>Word</th>\n",
       "      <th>PoS tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>4001</td>\n",
       "      <td>2854</td>\n",
       "      <td>сбросить</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>4002</td>\n",
       "      <td>2853</td>\n",
       "      <td>уснуть</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>4003</td>\n",
       "      <td>2851</td>\n",
       "      <td>близость</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>4004</td>\n",
       "      <td>2850</td>\n",
       "      <td>возрождение</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>4005</td>\n",
       "      <td>2849</td>\n",
       "      <td>заключенный</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>4006</td>\n",
       "      <td>2849</td>\n",
       "      <td>кружка</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>4007</td>\n",
       "      <td>2847</td>\n",
       "      <td>мяч</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>4008</td>\n",
       "      <td>2847</td>\n",
       "      <td>неведомый</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>4009</td>\n",
       "      <td>2846</td>\n",
       "      <td>референдум</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>4010</td>\n",
       "      <td>2845</td>\n",
       "      <td>сниться</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency rank  Estimated frequency         Word    PoS tag\n",
       "4000            4001                 2854     сбросить       verb\n",
       "4001            4002                 2853       уснуть       verb\n",
       "4002            4003                 2851     близость       noun\n",
       "4003            4004                 2850  возрождение       noun\n",
       "4004            4005                 2849  заключенный       noun\n",
       "4005            4006                 2849       кружка       noun\n",
       "4006            4007                 2847          мяч       noun\n",
       "4007            4008                 2847    неведомый  adjective\n",
       "4008            4009                 2846   референдум       noun\n",
       "4009            4010                 2845      сниться       verb"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnc_freq_list.iloc[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency rank</th>\n",
       "      <th>Estimated frequency</th>\n",
       "      <th>Word</th>\n",
       "      <th>PoS tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1968</td>\n",
       "      <td>7857</td>\n",
       "      <td>сбор</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency rank  Estimated frequency  Word PoS tag\n",
       "1967            1968                 7857  сбор    noun"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnc_freq_list[rnc_freq_list['Word']=='сбор']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus_size = rnc_freq_list['Estimated frequency'].sum()\n",
    "\n",
    "grouped_df = pd.DataFrame()\n",
    "idx = 0\n",
    "while idx <= 10000:\n",
    "    sect_df = rnc_freq_list.iloc[idx:idx + 100]\n",
    "    sect_est_freq = sect_df['Estimated frequency'].sum()\n",
    "    grouped_df = grouped_df.append(\n",
    "                                {'Frequency ranks' : str(idx) + '-' + str(idx + 100), \n",
    "                                   'Estimated frequency' : sect_est_freq,\n",
    "                                   'Percentage of corpus' : sect_est_freq / corpus_size * 100},\n",
    "                                  ignore_index = True\n",
    "                                  )\n",
    "    idx += 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ed5d7ae588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Frequency ranks', y='Estimated frequency', data=grouped_df.iloc[20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile a corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load tmx files using translate toolkit module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fsplit.filesplit import FileSplit\n",
    "\n",
    "fs = FileSplit(file='C:\\\\Users\\\\MdeCL\\\\Desktop\\\\opus tmx files\\\\Russian\\\\UNPC (need to split).tmx', splitsize=700000000, output_dir='C:\\\\Users\\\\MdeCL\\\\Desktop\\\\UNPC split files')\n",
    "\n",
    "fs.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parallel_corp_folder = 'C:\\\\Users\\\\MdeCL\\\\Desktop\\\\opus tmx files\\\\Russian\\\\For para_texts_df'\n",
    "\n",
    "num_sources = 0\n",
    "for tmx_folder in os.listdir(parallel_corp_folder):\n",
    "    num_sources += 1\n",
    "    \n",
    "para_texts_df = pd.DataFrame()\n",
    "\n",
    "ru_sents = []\n",
    "en_sents = []\n",
    "chunk_idx = 1\n",
    "\n",
    "for tmx_folder in os.listdir(parallel_corp_folder):\n",
    "    sent_idx = 1\n",
    "    \n",
    "    print(tmx_folder)\n",
    "    \n",
    "    with open(\"C:\\\\Users\\\\MdeCL\\\\Desktop\\\\opus tmx files\\\\Russian\\\\For para_texts_df\\\\\" + tmx_folder, 'rb') as fin:\n",
    "        tmx_file = tmxfile(fin, 'en', 'ru')\n",
    "\n",
    "        for node in tmx_file.unit_iter():\n",
    "            try:\n",
    "                node_target_sent = node.gettarget()\n",
    "                if 16 < len(node_target_sent) < 75:\n",
    "                    en_sents.append(node.getsource())\n",
    "                    ru_sents.append(node_target_sent)\n",
    "                    sent_idx += 1\n",
    "                    chunk_idx += 1\n",
    "            except Exception:\n",
    "                print(node)\n",
    "\n",
    "            if chunk_idx > 20000:\n",
    "                para_text_df = pd.DataFrame({'Source sentence' : ru_sents,\n",
    "                                            'Target sentence' : en_sents})\n",
    "                para_text_df['Source'] = tmx_folder\n",
    "                para_texts_df = para_texts_df.append(para_text_df, ignore_index = True)\n",
    "                print('20,000 sentences appended to para_texts_df.')\n",
    "                ru_sents = []\n",
    "                en_sents = []\n",
    "                chunk_idx = 1\n",
    "\n",
    "        print(sent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Randomly order DataFrame rows\n",
    "para_texts_df = para_texts_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean, standardise and pre-process parallel corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Remove duplicates in source_sentence column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df = para_texts_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates in source and target sentences\n",
    "para_texts_df.drop_duplicates('Source sentence', inplace=True)\n",
    "para_texts_df.drop_duplicates('Target sentence', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def filter_sent_quality(df_row):\n",
    "    return_bool = True\n",
    "    src_sent = df_row['Source sentence']\n",
    "    src_sent_tokens = src_sent.split(' ')\n",
    "    target_sent = df_row['Target sentence']\n",
    "    target_sent_tokens = target_sent.split(' ')\n",
    "    if len(src_sent_tokens) > 2.2 * len(target_sent_tokens) or len(src_sent_tokens) * 2 < len(target_sent_tokens):\n",
    "        return_bool = False\n",
    "    if sum(c.isdigit() for c in src_sent) >= 7:\n",
    "        return_bool = False\n",
    "    if len(src_sent) < 22:\n",
    "        return_bool = False\n",
    "    \n",
    "    return return_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df = para_texts_df[para_texts_df.apply(filter_sent_quality, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bare_source_sent(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = [char for char in sent if char.isalpha() or char.isspace()]\n",
    "    sent = ''.join(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Delete rows whose first 20 characters are the same as those of another row\n",
    "para_texts_df['Bare source sentence'] = para_texts_df['Source sentence'].apply(bare_source_sent)\n",
    "para_texts_df['Bare source sentence first chars'] = para_texts_df['Bare source sentence'].str[:20]\n",
    "para_texts_df.drop_duplicates('Bare source sentence first chars', inplace=True)\n",
    "para_texts_df = para_texts_df.drop(columns = ['Bare source sentence', 'Bare source sentence first chars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Standardise the source and target sentences so they can be uniformly processed at later stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stand_sent(sent):\n",
    "    sent = ''.join([char for char in sent if (char.isalpha() or char.isdigit() or char.isspace() or char in string.punctuation)])\n",
    "    sent = sent.strip().lower()\n",
    "    sent = ' ' + sent + ' '\n",
    "    puncts = [',', '.', ';', ':', '!', '?', '(', ')', '{', '}', '\\\"', '\\'', '[', ']']\n",
    "    for punct in puncts:\n",
    "        sent = sent.replace(punct, ' ' + punct + ' ')\n",
    "    sent = sent.replace('  ', ' ').replace('   ', ' ').strip()\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stand_src_sents = para_texts_df['Source sentence'].apply(stand_sent)\n",
    "para_texts_df['Standardised source sentence'] = stand_src_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stand_en_sent(sent):\n",
    "    \n",
    "    sent = ''.join([char for char in sent if (char.isalpha() or char.isdigit() or char.isspace() or char in string.punctuation)])\n",
    "    if type(sent) == str:\n",
    "        sent = sent.strip().lower()\n",
    "        sent = ' ' + sent + ' '\n",
    "        elisions = {'that\\'s' : 'that is',\n",
    "                    'it\\'s' : 'it is',\n",
    "                    'what\\'s' : 'what is',\n",
    "                    'who\\'s' : 'who is',\n",
    "                    'I\\'m' : 'I am',\n",
    "                    'I\\'ve' : 'I have',\n",
    "                    'he\\'s' : 'he is',\n",
    "                    'she\\'s' : 'she is',\n",
    "                    'isn\\'t' : 'is not',\n",
    "                    'won\\'t' : 'will not',\n",
    "                    'gonna' : 'going to',\n",
    "                    '\\'ve' : ' have',\n",
    "                    '\\'re' : ' are'\n",
    "                   }\n",
    "        for elision_key in elisions.keys():\n",
    "            sent = sent.replace(elision_key, elisions[elision_key])\n",
    "        puncts = [',', '.', ';', ':', '!', '?', '(', ')', '{', '}', '\\\"', '\\'', '[', ']']\n",
    "        for punct in puncts:\n",
    "            sent = sent.replace(punct, ' ' + punct + ' ')\n",
    "        sent = sent.replace('  ', ' ').replace('   ', ' ').strip()\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stand_target_sents = para_texts_df['Target sentence'].apply(stand_en_sent)\n",
    "para_texts_df['Standardised target sentence'] = stand_target_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pre-process the source sentences to make subsequent processing faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_sent(sent_df_row):\n",
    "    \n",
    "    sent = sent_df_row['Standardised source sentence'].replace('  ', ' ').replace('   ', ' ').strip()\n",
    "    \n",
    "    lemmed_sent = []\n",
    "    coll_lemmed_sent = []\n",
    "    pos_tag_list = []\n",
    "    cases_list = []\n",
    "    \n",
    "    sent_tokens = sent.split(' ')\n",
    "    lem = True\n",
    "    for token in sent_tokens:\n",
    "        p = morph.parse(token)[0]\n",
    "        lemmed_sent.append(p.normal_form)\n",
    "        pos = str(p.tag.POS)\n",
    "        if pos != None:\n",
    "            pos_tag_list.append(pos)\n",
    "        else:\n",
    "            pos_tag_list.append('None')\n",
    "        case = p.tag.case\n",
    "        if case != None:\n",
    "            cases_list.append(case)\n",
    "        else:\n",
    "            cases_list.append('None')\n",
    "        if lem == True:\n",
    "            coll_lemmed_sent.append(p.normal_form)\n",
    "        else:\n",
    "            coll_lemmed_sent.append(token)\n",
    "        if pos == 'PREP':\n",
    "            lem = False\n",
    "        elif pos in ['INFN', 'VERB', 'NOUN']:\n",
    "            lem = True\n",
    "    \n",
    "    lemmed_sent = ' '.join(lemmed_sent)\n",
    "    coll_lemmed_sent = ' '.join(coll_lemmed_sent)\n",
    "    pos_tag_list = ' '.join(pos_tag_list)\n",
    "    cases_list = ' '.join(cases_list)\n",
    "    \n",
    "    return lemmed_sent, coll_lemmed_sent, pos_tag_list, cases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "l_df = para_texts_df\n",
    "lemmed_sents, coll_lemmed_sents, pos_tag_list, case_list = zip(*l_df.apply(preprocess_sent, axis=1))\n",
    "l_df.insert(1, 'Lemmed source sentence', list(lemmed_sents))\n",
    "l_df.insert(2, 'Coll lemmed source sentence', coll_lemmed_sents)\n",
    "l_df.insert(3, 'Source sentence PoS tags', pos_tag_list)\n",
    "l_df.insert(3, 'Source sentence cases', case_list)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df = para_texts_df[~para_texts_df['Lemmed source sentence'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Explore the data to find disparities between estimated frequency and frequency in parallel corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index, row in para_texts_df.iloc[100:200].iterrows():\n",
    "    print(row['Standardised source sentence'])\n",
    "    print(row['Standardised target sentence'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anomalies_df = pd.DataFrame()\n",
    "\n",
    "for index, row in rnc_freq_list.iloc[2000:2010].iterrows():\n",
    "\n",
    "    estimated_freq = row['Estimated frequency']\n",
    "    query = row['Word']\n",
    "    query_pos_full = row['PoS tag']\n",
    "    print(index)\n",
    "    print(query)\n",
    "    \n",
    "    query_forms = []\n",
    "    query_parse = morph.parse(query)[0]\n",
    "    for word_form in query_parse.lexeme:\n",
    "        form = word_form[0]\n",
    "        query_forms.append(form)\n",
    "        if 'ё' in form:\n",
    "            query_forms.append(form.replace('ё', 'е'))\n",
    "    query_forms = list(set(query_forms))\n",
    "\n",
    "    results_df = pd.DataFrame()\n",
    "    for query_form in query_forms:\n",
    "        query_form_results_df = para_texts_df[para_texts_df['Standardised source sentence'].str.contains(' ' + query_form + ' ', regex = False)]\n",
    "        results_df = results_df.append(query_form_results_df)\n",
    "#     p = morph.parse(query)[0]\n",
    "#     lemmed_query = p.normal_form\n",
    "#     results_df = reduced_df[reduced_df['Lemmed source sentence'].str.contains(' ' + lemmed_query + ' ', regex = False)]\n",
    "    results_df = results_df.drop_duplicates('Source sentence')\n",
    "    print('NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES:', len(results_df.index))\n",
    "    concordance_freq = len(results_df.iloc[:])\n",
    "    \n",
    "    open_subtitles_freq = len(results_df[results_df['Source'].str.contains('OpenSubtitles')])\n",
    "    un_freq = len(results_df[results_df['Source'].str.contains('MultiUN')])\n",
    "    qed_freq = len(results_df[results_df['Source'].str.contains('QED')])\n",
    "    wiki_freq = len(results_df[results_df['Source'].str.contains('Wikipedia')])\n",
    "    \n",
    "    anomalies_df = anomalies_df.append({\n",
    "                                        'Term' : query,\n",
    "                                        'Estimated frequency' : estimated_freq,\n",
    "                                        'Actual frequency' : concordance_freq,\n",
    "                                        'Open Subtitles frequency' : open_subtitles_freq,\n",
    "                                        'Multi UN frequency' : un_freq,\n",
    "                                        'QED frequency' : qed_freq,\n",
    "                                        'Wikipedia frequency' : wiki_freq\n",
    "                                       },\n",
    "                                        ignore_index = True)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "anomalies_df['Anomaly score'] = anomalies_df['Estimated frequency'] / anomalies_df['Actual frequency']\n",
    "anomalies_df.sort_values('Anomaly score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for group_name, group_df in para_texts_df.groupby('Source'):\n",
    "    print(group_name)\n",
    "    for index, row in group_df.iloc[0:30].iterrows():\n",
    "        print(row['Standardised source sentence'])\n",
    "        print(row['Standardised target sentence'])\n",
    "        print('\\n')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add a column for the sentences' genre/register and create a function to return a register tag from a list of registers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_register(source):\n",
    "    register_dict = {\n",
    "        'GlobalVoices' : \n",
    "        'MultiUN_1' : 'political',\n",
    "        'MultiUN_2' : 'political',\n",
    "        'MultiUN_3' : 'political',\n",
    "        'MultiUN_4' : 'political',\n",
    "        'MultiUN_5' : 'political',\n",
    "        'MultiUN_6' : 'political',\n",
    "        'MultiUN_7' : 'political',\n",
    "        'MultiUN_8' : 'political',\n",
    "        'OpenSubtitles_1' : 'informal',\n",
    "        'OpenSubtitles_2' : 'informal',\n",
    "        'OpenSubtitles_4' : 'informal',\n",
    "        'QED' : 'journalism'\n",
    "        'TED2013' : 'journalism',\n",
    "        'Tanzil.tmx' : \n",
    "        'Tatoeba' : 'general'\n",
    "        'Wikipedia' : 'general'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for group_name, group_df in para_texts_df.groupby('Source'):\n",
    "    print(group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Save para_texts_df to csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df.to_csv(desktop_dir + '\\\\para_texts_df.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load para_texts_df from csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df = pd.read_csv(desktop_dir + '\\\\para_texts_df.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dictionary webscraping functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\ru_prepositions.txt\", 'r', encoding='utf8') as file:\n",
    "    file_read = file.read()\n",
    "    preps = file_read.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def abbyy_scrape(word):\n",
    "    \"\"\"\"Web-scrape the ABBYY Lingvo Live website\n",
    "    for English definitions of a given Russian word\"\"\"\n",
    "    \n",
    "    url = \"https://www.lingvolive.com/en-us/translate/ru-en/\" + word\n",
    "    \n",
    "    def web_scrape_this_url(url):\n",
    "        \n",
    "        return_dict = {\n",
    "        'PoS' : '',\n",
    "        'Term with accent' : '',\n",
    "        'Case taken' : '',\n",
    "        'Grammatical info' : '',\n",
    "        'Distinguishing gram info' : '',\n",
    "        'English translations' : [],\n",
    "        }\n",
    "        \n",
    "        reroute_link_found = False\n",
    "        eng_def_found = False\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            print('RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY:', response)\n",
    "            #try:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            dict_div = soup.find('div', {'name' : '#dictionary'})\n",
    "            first_def_div = dict_div.find('div', {'class' : '_1mexQ Zf_4w _3bSyz'})\n",
    "            term_div = first_def_div.find('h1', {'class' : '_2bepj _2lIoa _3bSyz sSWiV Zf_4w _3bSyz'})\n",
    "            print('TERM:', term_div.get_text())\n",
    "            \n",
    "            gram_info_div = first_def_div.find('p', {'data-reactid' : '.1a8ou94m96o.1.0.$content.0.1.1.1.1.0.0:$0.2:$1'})\n",
    "            \n",
    "            if first_def_div.find('ol', {'class' : '_2xKEq _1TaPP'}) != None:\n",
    "                defs_div = first_def_div.find('ol', {'class' : '_2xKEq _1TaPP'})\n",
    "            else:\n",
    "                defs_div = first_def_div\n",
    "                \n",
    "            case_taken_dict = {\n",
    "                'к' : ' к',\n",
    "                'с' : ' с',\n",
    "                'из' : ' из',\n",
    "                'от' : ' от',\n",
    "                'к' : ' к',\n",
    "                'у' : ' у',\n",
    "                'в' : ' в',\n",
    "                'на' : ' на',\n",
    "                'за' : ' за',\n",
    "                'от' : ' от',\n",
    "                'к' : ' к',\n",
    "                'у' : ' у',\n",
    "                'что-л.' : ' + acc',\n",
    "                'кого-л./что-л.' : '+ acc',\n",
    "                'кого-л.' : ' + <font color=\"green\">gen</font>',\n",
    "                'чего-л.' : ' + <font color=\"green\">gen</font>',\n",
    "                'кого-л./чего-л.' : ' + <font color=\"green\">gen</font>',\n",
    "                'кому-л.' : ' + <font color=\"purple\">dat</font>',\n",
    "                'чему-л.' : ' + <font color=\"purple\">dat</font>',\n",
    "                'кому-л./чему-л.' : ' + <font color=\"purple\">dat</font>',\n",
    "                'кем-л.' : ' + <font color=\"blue\">instr</font>',\n",
    "                'чем-л.' : ' + <font color=\"blue\">instr</font>',\n",
    "                'кем-л./чем-л.' : ' + <font color=\"blue\">instr</font>',\n",
    "            }\n",
    "            \n",
    "            def_texts = {}\n",
    "            try:\n",
    "                case_found = False\n",
    "                \n",
    "                # Iterate over definition divs\n",
    "                for p_div in defs_div.find_all('p'):\n",
    "                    \n",
    "                    s = p_div.get_text()\n",
    "                    \n",
    "                    # Find the case that the word takes\n",
    "                    if case_found == False:\n",
    "                        case_tag = s[s.find(\"(\")+1:s.find(\")\")]\n",
    "                        case_tag = case_tag.replace(' / ', '/').strip()\n",
    "                        case_units = case_tag.split(';')\n",
    "                        case_unit = case_units[0]\n",
    "                        case_unit_cases = case_unit.split(' ')\n",
    "                        cases_taken = []\n",
    "                        for case in case_unit_cases:\n",
    "                            if case in preps:\n",
    "                                cases_taken.append(' ' + case)\n",
    "                            elif case in case_taken_dict:\n",
    "                                value = case_taken_dict[case]\n",
    "                                cases_taken.append(value)\n",
    "                                case_found = True\n",
    "                        return_dict['Case taken'] = ' '.join(cases_taken)\n",
    "\n",
    "                    # Get filtered definition text\n",
    "                    def_items = []\n",
    "                    for span in p_div.find_all('span', {'class' : '_3zJig'}):\n",
    "                        word = span.get_text()\n",
    "                        if word != 'I':\n",
    "                            def_items.append(word)\n",
    "                    def_text = ' '.join(def_items)\n",
    "                    \n",
    "                    # Add div text and filtered div text to def_texts dictionary\n",
    "                    def_texts[s] = def_text\n",
    "                    \n",
    "                for s, def_text in def_texts.items():\n",
    "                    \n",
    "                    # Remove the long text in brackets that interfers with the later text splitting\n",
    "                    def_text = re.sub(r\" ?\\([^)]+\\|\\|[^)]+\\)\", \"\", def_text).strip()\n",
    "                    # Remove the text in brackets that contains a comma, as it interfers with the later text splitting:\n",
    "                    def_text = re.sub(r\" ?\\([^)]+\\,[^)]+\\)\", \"\", def_text).strip()\n",
    "                    \n",
    "                    final_defs = []\n",
    "\n",
    "                    def_text = def_text.replace('; ', ', ')\n",
    "                    def_texts = def_text.split(', ')\n",
    "                    \n",
    "                    for defin in def_texts:\n",
    "                        \n",
    "                        defins = []\n",
    "                        \n",
    "                        if bool(re.search('[a-zA-Z]', defin)) == True:\n",
    "                            \n",
    "                            eng_def_found = True\n",
    "                            if ' / ' in defin:\n",
    "                                if defin.count(' / ') >= 2:\n",
    "                                    defins += defin.split(' / ')\n",
    "                                else:\n",
    "                                    word_tokens = defin.split(' ')\n",
    "                                    word_tokens = ['', '', ''] + word_tokens + ['', '', '']\n",
    "                                    slash_idx = word_tokens.index('/')\n",
    "                                    var_one = ' '.join(word_tokens[:slash_idx] + word_tokens[slash_idx+2:]).strip()\n",
    "                                    var_two = ' '.join(word_tokens[:slash_idx-2] + word_tokens[slash_idx+1:]).strip()\n",
    "                                    defins.append(var_one)\n",
    "                                    defins.append(var_two)\n",
    "                            else:\n",
    "                                defins.append(defin)\n",
    "                                \n",
    "                            for defin in defins:\n",
    "                                if '(' and ')' in defin:\n",
    "                                    def_text_without_bracket_text = re.sub(r\" ?\\([^)]+\\)\", \"\", defin).strip()\n",
    "                                    def_text_with_bracket_text = defin.replace('(', '').replace(')', '').strip()\n",
    "         \n",
    "                                    if '||' not in def_text_with_bracket_text:\n",
    "                                        final_defs += [def_text_without_bracket_text, def_text_with_bracket_text]\n",
    "                                    else:\n",
    "                                        final_defs += [def_text_without_bracket_text]\n",
    "                                else:\n",
    "                                    defin = defin.replace('(', '').replace(')', '').strip().lower()\n",
    "                                    final_defs += [defin]\n",
    "\n",
    "                    to_dict = ', '.join(final_defs)\n",
    "                    \n",
    "                    if to_dict != '':\n",
    "                        if any(item in to_dict for item in ['Все права защищены.', 'II']) == False:\n",
    "                            to_dict = re.sub(r'[\\s]+', ' ', to_dict)\n",
    "                            to_dict = re.sub(r'[а-яА-Я]+', '', to_dict)\n",
    "                            to_dict = to_dict.replace('smb.', '')\n",
    "                            to_dict = re.sub(r'[\\s]+\\, ', ', ', to_dict)\n",
    "                            to_dict = to_dict.replace('(', '').replace(')', '').strip()\n",
    "\n",
    "                            cleaned_def = re.sub(r\" ?\\([^)]+\\)\", \"\", to_dict)\n",
    "                            cleaned_def = cleaned_def.replace(')', '')\n",
    "                            cleaned_def = cleaned_def.replace('the ', '')\n",
    "                            if cleaned_def.startswith('to '):\n",
    "                                cleaned_def = cleaned_def[2:]\n",
    "                            cleaned_def = cleaned_def.replace(', ', '|').replace('; ', '|').strip()\n",
    "                            cleaned_def_list = cleaned_def.split('|')\n",
    "                            \n",
    "                            [defin.strip() for defin in cleaned_def_list]\n",
    "                            \n",
    "                            cleaned_def_list = [''.join([char for char in defin if char.isalpha() or char.isspace()]).strip() for defin in cleaned_def_list]\n",
    "                            \n",
    "                            cleaned_def_list = list(set(cleaned_def_list))\n",
    "                            \n",
    "                            return_dict['English translations'].append([s, cleaned_def_list])\n",
    "                            \n",
    "                            eng_def_found = True\n",
    "                            \n",
    "                    if p_div.get_text() != '':\n",
    "                        if p_div.find('a') != None:\n",
    "                            reroute_link_found = True\n",
    "                            a_element = p_div.find('a')\n",
    "                            reroute_url = 'https://www.lingvolive.com' + a_element['href']\n",
    "                            break\n",
    "                        else:\n",
    "                            reroute_url = ''\n",
    "                            \n",
    "            except Exception as e:\n",
    "                reroute = False\n",
    "                reroute_url = ''\n",
    "                return return_dict, reroute, reroute_url\n",
    "            \n",
    "            if reroute_link_found == True and eng_def_found == False:\n",
    "                reroute = True\n",
    "            else:\n",
    "                reroute = False\n",
    "            \n",
    "            return return_dict, reroute, reroute_url\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print('-----------ABBYY LINGVO SCRAPE RAISED AN ERROR:')\n",
    "            print(e)\n",
    "            reroute = False\n",
    "            reroute_url = ''\n",
    "            return return_dict, reroute, reroute_url\n",
    "                \n",
    "    return_dict, reroute, reroute_url = web_scrape_this_url(url)\n",
    "    if reroute == True:\n",
    "        print('REROUTING...')\n",
    "        return_dict, reroute, reroute_url = web_scrape_this_url(reroute_url)\n",
    "        if reroute == True:\n",
    "            return_dict, reroute, reroute_url = web_scrape_this_url(reroute_url)\n",
    "    \n",
    "\n",
    "    pos_codes = {\n",
    "        'нареч.' : 'adverb',\n",
    "        'прил.' : 'adjective',\n",
    "        'ж.р.' : 'noun',\n",
    "        'м.р.' : 'noun',\n",
    "        'несовер.' : 'verb',\n",
    "        'предл.' : 'preposition',\n",
    "        'союз' : 'conjunction',\n",
    "        'частица' : 'particle'\n",
    "    }\n",
    "\n",
    "    term_pos = ''\n",
    "\n",
    "    return_dict['PoS'] = term_pos\n",
    "        \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "-----------ABBYY LINGVO SCRAPE RAISED AN ERROR:\n",
      "'NoneType' object has no attribute 'find'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PoS': '',\n",
       " 'Term with accent': '',\n",
       " 'Case taken': '',\n",
       " 'Grammatical info': '',\n",
       " 'Distinguishing gram info': '',\n",
       " 'English translations': []}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbyy_scrape('чей-то')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def wiktionary_parser_eng_trans_scrape(word, pos):\n",
    "    language = 'russian'\n",
    "    parser = WiktionaryParser()\n",
    "    return_dict = {\n",
    "        'PoS' : '',\n",
    "        'Term with accent' : '',\n",
    "        'Grammatical info' : '',\n",
    "        'Distinguishing gram info' : '',\n",
    "        'English translations' : [],\n",
    "        'Idiomatic phrases' : []\n",
    "    }\n",
    "    try:\n",
    "        if parser.fetch(word, language) != None:\n",
    "            try:\n",
    "                data = parser.fetch(word, language)[0]\n",
    "                #print(data)\n",
    "                try:\n",
    "                    for definition in data['definitions']:\n",
    "                        if definition['partOfSpeech'] == pos:\n",
    "                            return_dict['PoS'] = definition['partOfSpeech']\n",
    "                            term_with_accent = definition['text'][0]\n",
    "                            return_dict['Idiomatic phrases'] = definition['examples']\n",
    "                            term_with_accent = ''\n",
    "                            eng_trans = []\n",
    "                            text_idx = 0\n",
    "                            defs_to_reroute = ['Alternative spelling of', 'superlative degree of', 'short neuter singular of', ]\n",
    "                            if any(item in definition['text'][1] for item in defs_to_reroute):\n",
    "                                alt_spelling = definition['text'][1].split(' of ')[1]\n",
    "                                alt_spelling = alt_spelling.split()[0]\n",
    "                                alt_spelling = alt_spelling.replace('о́', 'о').replace('е́', 'е').replace('и́', 'и').replace('у́', 'у')\n",
    "                                alt_spelling = alt_spelling.replace('ы́','ы').replace('а́','а')\n",
    "                                if parser.fetch(alt_spelling, language) != None:\n",
    "                                    try:\n",
    "                                        data = parser.fetch(alt_spelling, language)[0]\n",
    "                                        try:\n",
    "                                            for definition in data['definitions']: \n",
    "                                                if definition['partOfSpeech'] == pos:\n",
    "                                                    return_dict['PoS'] = definition['partOfSpeech']\n",
    "                                                    term_with_accent = definition['text'][0]\n",
    "                                                    return_dict['Idiomatic phrases'] = definition['examples']\n",
    "                                                    term_with_accent = ''\n",
    "                                                    eng_trans = []\n",
    "                                                    text_idx = 0\n",
    "                                                    while text_idx + 1 <= len(definition['text']):\n",
    "                                                        item = definition['text'][text_idx]\n",
    "                                                        if text_idx == 0:\n",
    "                                                            return_dict['Term with accent'] = item.split(' • ')[0]\n",
    "                                                            return_dict['Grammatical info'] = item.split(' • ')[1]\n",
    "                                                        else:\n",
    "                                                            if 'passive of ' not in item:\n",
    "                                                                eng_trans.append(item)\n",
    "                                                        text_idx += 1\n",
    "                                                    return_dict['English translations'] = eng_trans\n",
    "                                        except Exception:\n",
    "                                            print('Wiktionary Parser returned None.')\n",
    "                                            sys.exit()\n",
    "                                    except Exception:\n",
    "                                        print('Wiktionary Parser returned None.')\n",
    "                                        sys.exit()\n",
    "                                else:\n",
    "                                    print('Wiktionary Parser returned None.')\n",
    "                                    sys.exit()\n",
    "                            else:\n",
    "                                while text_idx + 1 <= len(definition['text']):\n",
    "                                    item = definition['text'][text_idx]\n",
    "                                    if text_idx == 0:\n",
    "                                        return_dict['Term with accent'] = item.split(' • ')[0]\n",
    "                                        return_dict['Grammatical info'] = item.split(' • ')[1]\n",
    "                                    else:\n",
    "                                        if 'passive of ' not in item:\n",
    "                                            eng_trans.append(item)\n",
    "                                    text_idx += 1\n",
    "                                return_dict['English translations'] = eng_trans\n",
    "                except Exception:\n",
    "                    print('Wiktionary Parser returned None.')\n",
    "            except Exception:\n",
    "                print('Wiktionary Parser returned None.')\n",
    "        else:\n",
    "            print('Wiktionary Parser returned None.')\n",
    "    except Exception as e:\n",
    "        print('Wiktionary Parser returned None.')\n",
    "    formatted_eng_trans = []\n",
    "    eng_tran_idx = 0\n",
    "    while eng_tran_idx + 1 <= len(return_dict['English translations']):\n",
    "        formatted_eng_trans.append(return_dict['English translations'][eng_tran_idx])\n",
    "        eng_tran_idx += 1\n",
    "    return_dict['English translations'] = formatted_eng_trans\n",
    "    if 'impf (perfective' in return_dict['Grammatical info']:\n",
    "        return_dict['Distinguishing gram info'] = 'imperfective'\n",
    "    elif 'pf (imperfective'in return_dict['Grammatical info']:\n",
    "        return_dict['Distinguishing gram info'] = 'perfective'\n",
    "    \n",
    "    return(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PoS': '',\n",
       " 'Term with accent': '',\n",
       " 'Grammatical info': '',\n",
       " 'Distinguishing gram info': '',\n",
       " 'English translations': [],\n",
       " 'Idiomatic phrases': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiktionary_parser_eng_trans_scrape('жаль', 'noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def coll_eng_tran(coll):\n",
    "    \n",
    "#     translation = translate_client.translate(coll, source_language='ru', target_language='en')\n",
    "#     time.sleep(1)\n",
    "    \n",
    "#     return translation['translatedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cooljugator_scrape(word, query_pos_full):\n",
    "    \n",
    "    conjugs_dict = {}\n",
    "    \n",
    "    pos_dict = {\n",
    "        'adjective' : 'a',\n",
    "        'noun' : 'n',\n",
    "        'verb' : ''\n",
    "    }\n",
    "    \n",
    "    base_url = 'https://cooljugator.com/ru'\n",
    "    if query_pos_full in pos_dict:\n",
    "        url = base_url + pos_dict[query_pos_full] + '/' + word\n",
    "\n",
    "        response = requests.get(url)\n",
    "        print('RESPONSE FROM COOLJUGATOR:', response)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        conjug_div = soup.find('section', {'id' : 'conjugations'})\n",
    "        \n",
    "        try:\n",
    "            for table_div in conjug_div.find_all('div', {'class' : 'conjugation-table collapsable'}):\n",
    "                for cell_div in table_div.find_all('div', {'class' : 'conjugation-cell conjugation-cell-four'}):\n",
    "                    if cell_div.has_attr('id'):\n",
    "                        cell_id = cell_div['id'].replace('_no_accent', '')\n",
    "                        if cell_div.has_attr('data-stressed'):\n",
    "                            conjugs_dict[cell_id] = cell_div['data-stressed']\n",
    "                        elif cell_div.has_attr('data-default'):\n",
    "                            conjugs_dict[cell_id] = cell_div['data-default']\n",
    "\n",
    "                for cell_div in conjug_div.find_all('div', {'class' : 'conjugation-cell conjugation-cell-four leftmost'}):\n",
    "                    if cell_div.has_attr('id'):\n",
    "                        cell_id = cell_div['id'].replace('_no_accent', '')\n",
    "                        if cell_div.has_attr('data-stressed'):\n",
    "                            conjugs_dict[cell_id] = cell_div['data-stressed']\n",
    "                        elif cell_div.has_attr('data-default'):\n",
    "                            conjugs_dict[cell_id] = cell_div['data-default']\n",
    "                            \n",
    "        except Exception as e:\n",
    "            print('COOLJUGATOR SCRAPE RAISED AN ERROR:')\n",
    "            print(e)\n",
    "    \n",
    "    else:\n",
    "        print('COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.')\n",
    "                \n",
    "    return conjugs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nom_P': 'еди́ные',\n",
       " 'gen_P': 'еди́ных',\n",
       " 'dat_P': 'еди́ным',\n",
       " 'acc_anim_P': 'еди́ных',\n",
       " 'acc_inanim_P': 'еди́ные',\n",
       " 'instr_P': 'еди́ными',\n",
       " 'prep_P': 'еди́ных',\n",
       " 'short_P': 'еди́ны',\n",
       " 'nom_M': 'еди́ный',\n",
       " 'gen_M': 'еди́ного',\n",
       " 'dat_M': 'еди́ному',\n",
       " 'acc_anim_M': 'еди́ного',\n",
       " 'acc_inanim_M': 'еди́ный',\n",
       " 'instr_M': 'еди́ным',\n",
       " 'prep_M': 'еди́ном',\n",
       " 'short_M': 'еди́н',\n",
       " 'nom_F': 'еди́ная',\n",
       " 'gen_F': 'еди́ной',\n",
       " 'dat_F': 'еди́ной',\n",
       " 'acc_anim_F': 'еди́ную',\n",
       " 'acc_inanim_F': 'еди́ную',\n",
       " 'instr_F': 'еди́ной',\n",
       " 'prep_F': 'еди́ной',\n",
       " 'short_F': 'еди́на',\n",
       " 'nom_N': 'еди́ное',\n",
       " 'gen_N': 'еди́ного',\n",
       " 'dat_N': 'еди́ному',\n",
       " 'acc_anim_N': 'еди́ное',\n",
       " 'acc_inanim_N': 'еди́ное',\n",
       " 'instr_N': 'еди́ным',\n",
       " 'prep_N': 'еди́ном',\n",
       " 'short_N': 'еди́но'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooljugator_scrape('единый', 'adjective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eng_trans_and_syns(query, query_pos_full):\n",
    "    wikt_results = wiktionary_parser_eng_trans_scrape(query, query_pos_full)\n",
    "    term_with_accent = wikt_results['Term with accent']\n",
    "    if term_with_accent == '':\n",
    "        term_with_accent = query\n",
    "    term_without_accent = term_with_accent.replace('о́', 'о').replace('ы́', 'ы').replace('у́', 'у').replace('а́', 'а').replace('е́', 'е').replace('и́', 'и').replace('я́', 'я').replace('э́', 'э')\n",
    "    term_with_accent = re.sub(r\"(.)\\1\", '<u>' + r\"\\1\\1\" + '</u>', term_with_accent)\n",
    "    gram_info = wikt_results['Grammatical info']\n",
    "    disting_gram_info = wikt_results['Distinguishing gram info']\n",
    "    \n",
    "    if '\\xa0n\\xa0' in gram_info:\n",
    "        term_gender_colour = 'grey'\n",
    "    elif '\\xa0f\\xa0' in gram_info:\n",
    "        term_gender_colour = 'red'\n",
    "    elif '\\xa0m\\xa0' in gram_info:\n",
    "        term_gender_colour = 'blue'\n",
    "    else:\n",
    "        term_gender_colour = 'black'\n",
    "            \n",
    "    inflected_forms =  []\n",
    "    inflected_forms_dict = cooljugator_scrape(term_without_accent, query_pos_full) \n",
    "    query_parse = morph.parse(query)[0]\n",
    "    if query_pos_full == 'noun':\n",
    "        for key, value in inflected_forms_dict.items():\n",
    "            value = value.replace('о́', 'о').replace('ы́', 'ы').replace('у́', 'у').replace('а́', 'а').replace('е́', 'е').replace('и́', 'и').replace('я́', 'я').replace('э́', 'э')\n",
    "            if key == 'nom_P':\n",
    "                if term_gender_colour == 'blue':\n",
    "                    if (value.endswith('ы') == False) and (term_without_accent.endswith(('ь', 'к', 'г', 'х', 'ш', 'щ', 'ч', 'ж')) == False):\n",
    "                        inflected_forms.append(value[:-2] + '<font size=\\\"+5\\\" color=\\\"blue\\\">' + value[-2:]  + '</font>')\n",
    "                    if (value.endswith('и') == False) and (term_without_accent.endswith(('ь')) == True):\n",
    "                        inflected_forms.append(value[:-2] + '<font size=\\\"+5\\\" color=\\\"blue\\\">' + value[-2:]  + '</font>')\n",
    "                    elif len(value) > len(term_without_accent) + 1:\n",
    "                        inflected_forms.append(value[:-3] + '<font size=\\\"+5\\\" color=\\\"blue\\\">' + value[-3:]  + '</font>')\n",
    "                    else:\n",
    "                        inflected_forms.append(value)\n",
    "                elif (term_gender_colour == 'grey') and (term_without_accent.endswith('е') == False) and (value.endswith('а') == False):\n",
    "                    inflected_forms.append(value[:-2] + '<font size=\\\"+5\\\" color=\\\"blue\\\">' + value[-2:]  + '</font>')\n",
    "                elif (term_gender_colour == 'grey') and (term_without_accent.endswith('е') == True) and (value.endswith('я') == False):\n",
    "                    inflected_forms.append(value[:-2] + '<font size=\\\"+5\\\" color=\\\"blue\\\">' + value[-2:]  + '</font>')\n",
    "                elif ('ё' in value) and ('ё' not in term_without_accent):\n",
    "                    inflected_forms.append(value.replace('ё', '<font size=\\\"+5\\\" color=\\\"blue\\\">ё</font>'))\n",
    "                elif len(value) > len(term_without_accent) + 1:\n",
    "                    inflected_forms.append(value[:-3] + '<font size=\\\"+5\\\" color=\\\"blue\\\">' + value[-3:]  + '</font>')\n",
    "                else:\n",
    "                    inflected_forms.append(value)\n",
    "            elif key == 'loc':\n",
    "                if value.endswith('у'):\n",
    "                    inflected_forms.append(value[:-1] + '<font size=\\\"+5\\\" color=\\\"purple\\\">у</font>')\n",
    "                elif value.endswith('у́'):\n",
    "                    inflected_forms.append(value[:-2] + '<font size=\\\"+5\\\" color=\\\"purple\\\">у́</font>')\n",
    "                else:\n",
    "                    inflected_forms.append(value)\n",
    "            else:\n",
    "                inflected_forms.append(value)\n",
    "                    \n",
    "    elif query_pos_full == 'verb':\n",
    "        for key, value in inflected_forms_dict.items():\n",
    "            second_sing_form = ''\n",
    "            if 'present2' in inflected_forms_dict:\n",
    "                second_sing_form = inflected_forms_dict['present2']\n",
    "            elif 'future2' in inflected_forms_dict:\n",
    "                second_sing_form = inflected_forms_dict['future2']\n",
    "            if second_sing_form != '':\n",
    "                if second_sing_form.endswith(('аешь', 'яешь', 'ешься', 'яешься', 'а́ешь', 'я́ешь', 'а́ешься', 'я́ешься')):\n",
    "                    color = 'orange'\n",
    "                    term_gender_colour = 'orange'\n",
    "                else:\n",
    "                    if second_sing_form.endswith(('ишь', 'ишься', 'и́шь', 'и́шься')):\n",
    "                        color = 'blue'\n",
    "                        term_gender_colour = 'blue'\n",
    "                    elif second_sing_form.endswith(('ешь', 'ешься')):\n",
    "                        color = 'purple'\n",
    "                        term_gender_colour = 'purple'\n",
    "                    elif second_sing_form.endswith(('ёшь', 'ёшься')):\n",
    "                        color = 'firebrick'\n",
    "                        term_gender_colour = 'firebrick'\n",
    "                    else:\n",
    "                        color = 'black'\n",
    "            else:\n",
    "                color = 'black'\n",
    "                        \n",
    "        for key, value in inflected_forms_dict.items():\n",
    "            inflected_forms.append('<font color=\\\"' + color + '\\\">' + value + '</font>')\n",
    "            \n",
    "    elif query_pos_full == 'adjective':\n",
    "        if query_parse.inflect({'COMP'}) != None:\n",
    "            comp_form = query_parse.inflect({'COMP'}).word\n",
    "            if comp_form.endswith('ее') == False:\n",
    "                inflected_forms.append(comp_form[:-2] + '<font size=\\\"+5\\\" color=\\\"orange\\\">' + comp_form[-2:] + '</font>')\n",
    "            else:\n",
    "                inflected_forms.append(comp_form)\n",
    "\n",
    "    abbyy_results = abbyy_scrape(query)\n",
    "    \n",
    "    case_taken = abbyy_results['Case taken']\n",
    "    \n",
    "    cleaned_defs = abbyy_results['English translations']\n",
    "\n",
    "    syn_pos_tags = {\n",
    "        'noun' : '.n.',\n",
    "        'verb' : '.v.',\n",
    "        'adjective' : '.a.',\n",
    "        'adverb' : '',\n",
    "        'preposition' : ''\n",
    "    }\n",
    "    \n",
    "    infl_pos_tags = {\n",
    "        'verb' : 'V',\n",
    "        'adjective' : 'A',\n",
    "        'noun' : 'N',\n",
    "    } \n",
    "    \n",
    "    \n",
    "    defs_for_check = []\n",
    "    for defin in cleaned_defs:\n",
    "        for word in defin[1]:\n",
    "            defs_for_check.append(word)\n",
    "    \n",
    "    # CREATE A DICTIONARY WITH EACH FULL DEF AS A KEY AND ALL THEIR SYNS AND INFLECTED FORMS AS ITS VALUE:\n",
    "    inflected_eng_defs = {}\n",
    "    basic_defs_added = []\n",
    "    syns_added = []\n",
    "    for basic_def in cleaned_defs:\n",
    "        full_def = basic_def[0]\n",
    "        basic_def = basic_def[1]\n",
    "        n_basic_def = []\n",
    "        all_forms = []\n",
    "        # Find the synonyms of each word\n",
    "        for word in basic_def:\n",
    "            word = word.strip()\n",
    "            if word not in basic_defs_added:\n",
    "                basic_defs_added.append(word)\n",
    "                n_basic_def.append(word)\n",
    "                if query_pos_full == 'verb':\n",
    "                    syn_results = wordnet.synsets(word, pos=wordnet.VERB)\n",
    "                elif query_pos_full == 'noun':\n",
    "                    syn_results =  wordnet.synsets(word, pos=wordnet.NOUN)\n",
    "                elif query_pos_full == 'adjective':\n",
    "                    syn_results = wordnet.synsets(word, pos=wordnet.ADJ)\n",
    "                elif query_pos_full == 'adverb':\n",
    "                    syn_results = wordnet.synsets(word, pos=wordnet.ADV)\n",
    "                else:\n",
    "                    syn_results = wordnet.synsets(word)\n",
    "                syn_words = []\n",
    "                for syn in syn_results:\n",
    "                    for lm in syn.lemmas():\n",
    "                        syn_word = lm.name()\n",
    "                        if syn_word not in defs_for_check:\n",
    "                            syn_words.append(syn_word)\n",
    "                syn_words.append(word)\n",
    "                \n",
    "                # FIND THE INFLECTED FORMS OF EACH SYNONYM (SENSITIVE TO PoS) AND ADD TO WORD FORMS LIST:\n",
    "                word_forms = []\n",
    "                for syn_word in syn_words:\n",
    "                    syn_word = syn_word.replace('_', ' ').strip()\n",
    "                    if syn_word not in syns_added:\n",
    "                        syns_added.append(syn_word)\n",
    "                        # CHECK IF THE SYNONYM IS MORE THAN ONE WORD. IF IT IS, ONLY INFLECT THE FIRST WORD:\n",
    "                        syn_word_list = nltk.word_tokenize(syn_word)\n",
    "                        if query_pos_full in infl_pos_tags:\n",
    "                            infl_pos_tag = infl_pos_tags[query_pos_full]\n",
    "                            if syn_word_list != []:\n",
    "                                if len(syn_word_list) == 1:\n",
    "                                    if getAllInflections(syn_word_list[0], pos_type=infl_pos_tag) != {}:\n",
    "                                        [word_forms.append(value[0]) for key, value in getAllInflections(syn_word_list[0], pos_type=infl_pos_tag).items()]\n",
    "                                    else:\n",
    "                                        word_forms.append(syn_word)\n",
    "                                else:\n",
    "                                    if getAllInflections(syn_word_list[0], pos_type=infl_pos_tag) != {}:\n",
    "                                        word_forms = [infl_form[0]+' '+' '.join(syn_word_list[1:]) for infl_form in list(getAllInflections(syn_word_list[0], pos_type=infl_pos_tag).values())]\n",
    "                                    else:\n",
    "                                        word_forms.append(syn_word)\n",
    "                        else:\n",
    "                            if syn_word_list != []:\n",
    "                                if len(syn_word_list) == 1:\n",
    "                                    if getAllInflections(syn_word_list[0]) != {}:\n",
    "                                        [word_forms.append(value[0]) for key, value in getAllInflections(syn_word_list[0]).items()]\n",
    "                                    else:\n",
    "                                        word_forms.append(syn_word)\n",
    "                                else:\n",
    "                                    if getAllInflections(syn_word_list[0]) != {}:\n",
    "                                        word_forms = [infl_form[0]+' '+' '.join(syn_word_list[1:]) for infl_form in list(getAllInflections(syn_word_list[0]).values())]\n",
    "                                    else:\n",
    "                                        word_forms.append(syn_word)\n",
    "                    all_forms += word_forms\n",
    "                    \n",
    "        all_forms = list(set(all_forms))\n",
    "        inflected_eng_defs[full_def] = all_forms\n",
    "        \n",
    "    print('TERM\\'S INFLECTED FORMS:', ', '.join(inflected_forms))\n",
    "    \n",
    "    return {'inflected_eng_defs' : inflected_eng_defs,\n",
    "            'term_with_accent' : term_with_accent,\n",
    "            'case_taken' : case_taken,\n",
    "            'term_gender_colour' : term_gender_colour,\n",
    "            'disting_gram_info' : disting_gram_info,\n",
    "            'conjugation_declension_info' : inflected_forms}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: единый\n",
      "TERM'S INFLECTED FORMS: единее\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inflected_eng_defs': {'united, unified; common; indivisible': ['coarser',\n",
       "   'usual',\n",
       "   'united',\n",
       "   'mutual',\n",
       "   'usualest',\n",
       "   'plebeianner',\n",
       "   'commoner',\n",
       "   'mutualer',\n",
       "   'rough-cut',\n",
       "   'common',\n",
       "   'incorporated',\n",
       "   'vulgar',\n",
       "   'coarse',\n",
       "   'interconnected',\n",
       "   'merged',\n",
       "   'indivisible',\n",
       "   'joined',\n",
       "   'vernacular',\n",
       "   'incorporate',\n",
       "   'plebeian',\n",
       "   'uncouthest',\n",
       "   'mutualest',\n",
       "   'uncouth',\n",
       "   'commonest',\n",
       "   'coordinated',\n",
       "   'coarsest',\n",
       "   'integrated',\n",
       "   'uncouther',\n",
       "   'co-ordinated',\n",
       "   'usualer',\n",
       "   'plebeiannest',\n",
       "   'vulgarer',\n",
       "   'unwashed',\n",
       "   'unified',\n",
       "   'vulgarest'],\n",
       "  'one, single, sole': ['unmatched',\n",
       "   'nonpareil',\n",
       "   'solest',\n",
       "   'solitary',\n",
       "   'lonesome',\n",
       "   'oner',\n",
       "   'unmatchable',\n",
       "   'onest',\n",
       "   'undivided',\n",
       "   'onliest',\n",
       "   'anest',\n",
       "   'exclusive',\n",
       "   'unrivaled',\n",
       "   'ier',\n",
       "   'lone',\n",
       "   'loner',\n",
       "   'soler',\n",
       "   'individual',\n",
       "   'lonest',\n",
       "   'singler',\n",
       "   '1',\n",
       "   'unitary',\n",
       "   'i',\n",
       "   'oner and only',\n",
       "   'sole',\n",
       "   'aner',\n",
       "   'ane',\n",
       "   'unrivalled',\n",
       "   'matchless',\n",
       "   'singlest',\n",
       "   'peerless',\n",
       "   'unmarried',\n",
       "   'onest and only',\n",
       "   'single',\n",
       "   'one',\n",
       "   'one and only',\n",
       "   'iest']},\n",
       " 'term_with_accent': 'еди́ный',\n",
       " 'case_taken': '',\n",
       " 'term_gender_colour': 'black',\n",
       " 'disting_gram_info': '',\n",
       " 'conjugation_declension_info': ['единее']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_trans_and_syns('единый', 'adjective')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Find word's monolingual dictionary definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests \\\\computer science (technical)\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\wiktionary_abbrevs_trans.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-71536e77e009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mabbrevs_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproj_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\wiktionary_abbrevs_trans.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mfile_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_read\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests \\\\computer science (technical)\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\wiktionary_abbrevs_trans.txt'"
     ]
    }
   ],
   "source": [
    "abbrevs_dict = {}\n",
    "\n",
    "with open(proj_dir + '\\\\wiktionary_abbrevs_trans.txt', 'r') as file:\n",
    "    file_read = file.read()\n",
    "    for line in file_read.split('\\n'):\n",
    "        \n",
    "        abbrev = line.split('£')[0]\n",
    "        expl = line.split('£')[1]\n",
    "        \n",
    "        \n",
    "        abbrevs_dict[abbrev] = expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def monoling_wikt_scrape(word):\n",
    "    url = \"https://ru.wiktionary.org/w/index.php?title=\" + word + '&printable=yes'\n",
    "    response = requests.get(url)\n",
    "    wikt_definitions = []\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        if soup.find('ol') != None:\n",
    "            entries = soup.find('ol')\n",
    "            if entries.findAll('li') != None:\n",
    "                number_of_defs = len(entries.findAll('li'))\n",
    "                index = 0\n",
    "                while index + 1 <= number_of_defs:\n",
    "    \n",
    "                    # definition:\n",
    "                    entry = entries.find_all('li')[index]\n",
    "                    entry_text = entry.get_text()\n",
    "                    \n",
    "                    if entry_text != '':\n",
    "                    \n",
    "                        definition_text = entry_text.split('◆')[0]\n",
    "                        definition_text_extra = ''\n",
    "\n",
    "                        #clean up definition text before translating:\n",
    "                        definition_text = definition_text.replace(' гл.', ' глаголя ')\n",
    "                        \n",
    "                        if 'по значению глаголя ' in definition_text:\n",
    "                            definition_text_extra = definition_text.split('по значению глаголя ')[1]\n",
    "                        \n",
    "                        if 'соотносящийся по значению с существительным ' in definition_text:\n",
    "                            definition_text_extra = definition_text.split('соотносящийся по значению с существительным ')[1]\n",
    "                        \n",
    "                        definition_text = re.sub(\"\\[.*?\\]\", \"\", definition_text) \n",
    "                        definition_text = definition_text.replace('по значению глаголя', 'of verb: ')\n",
    "                        definition_text = definition_text.replace('свойство по значению прилагательного', 'quality of being ')\n",
    "                        definition_text = definition_text.replace(' по значению с существительным', ' to noun: ')\n",
    "                        \n",
    "                        # register tag:\n",
    "                        register_tag = ''\n",
    "                        for key, value in abbrevs_dict.items():\n",
    "                            if key in definition_text:\n",
    "                                definition_text = definition_text.replace(key, '')\n",
    "                                register_tag += '<i>' + value + '</i>'\n",
    "                                \n",
    "                        # example sentence:\n",
    "                        if entry.find('span', {'class' : 'example-absent'}) == None:\n",
    "                            if entry.find('span', {'class' : 'example-block'}) != None:\n",
    "                                ex_sentence_1 = entry.find('span', {'class' : 'example-block'})\n",
    "                                \n",
    "                                ex_sentence_one_text = ex_sentence_1.get_text()\n",
    "                            \n",
    "                                if entry.find('span', {'class' : 'example-details'}) != None:\n",
    "                                    text_to_remove = entry.find('span', {'class' : 'example-details'}).get_text()\n",
    "                                    ex_sentence_one_text = ex_sentence_one_text.replace(text_to_remove, '')\n",
    "                                \n",
    "                                ex_sent_with_blank = ex_sentence_one_text\n",
    "                                ex_sent_full = ex_sentence_one_text\n",
    "                                \n",
    "                                query_parse = morph.parse(word)[0]\n",
    "\n",
    "                                forms = []\n",
    "\n",
    "                                for word_form in query_parse.lexeme:\n",
    "                                    query = word_form[0]\n",
    "                                    forms.append(query)\n",
    "\n",
    "                                forms = list(set(forms))\n",
    "                                \n",
    "                                for form in forms:\n",
    "                                    capitalised_form = form.replace(form[0], form[0].upper())\n",
    "                                    \n",
    "                                    ex_sent_with_blank = re.sub('\\s' + form + '[\\s.]', ' ____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub('\\s' + form + '[\\s,]', ' ____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub('\\s' + form + '[\\s!]', ' ____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub('\\s' + form + '[\\s?]', ' ____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub(capitalised_form + '[\\s.]', '____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub(capitalised_form + '[\\s,]', '____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub(capitalised_form + '[\\s!]', '____ ', ex_sent_with_blank)\n",
    "                                    ex_sent_with_blank = re.sub(capitalised_form + '[\\s?]', '____ ', ex_sent_with_blank)\n",
    "                                    \n",
    "                                    #ex_sent_with_blank = ex_sent_with_blank.replace(form, '_____')\n",
    "                                    #ex_sent_with_blank = ex_sent_with_blank.replace(capitalised_form, '_____')\n",
    "                                    ex_sent_full = ex_sent_full.replace(form, '<b>' + form + '</b>')\n",
    "                                    ex_sent_full = ex_sent_full.replace(capitalised_form, '<b>' + capitalised_form + '</b>')\n",
    "                                \n",
    "                            else:\n",
    "                                ex_sent_with_blank = ''\n",
    "                                ex_sent_full = ''\n",
    "                        else:\n",
    "                            ex_sent_with_blank = ''\n",
    "                            ex_sent_full = ''\n",
    "                        \n",
    "                        added_to_register_tag = ''\n",
    "                        #move eg. 'about water' from definition_text to register_tag:\n",
    "                        definition_text = definition_text.replace(' - ', ' — ')\n",
    "                        definition_text = definition_text.replace('· ', ' — ')\n",
    "                        if ' — ' in definition_text:\n",
    "                            split_def = re.split(' — ', definition_text)\n",
    "                            added_to_register_tag += split_def[0]\n",
    "                            definition_text = split_def[1]\n",
    "                        #add text in brackets in definition_text to register_tag:\n",
    "                        if '(' and ')' in definition_text:\n",
    "                            text_in_brackets = definition_text[definition_text.find(\"(\")+1:definition_text.find(\")\")]\n",
    "                            added_to_register_tag += text_in_brackets\n",
    "                        if added_to_register_tag != '':\n",
    "                            register_tag += ', ' + added_to_register_tag\n",
    "                            \n",
    "                        definition_eng = definition_text\n",
    "                        \n",
    "                        definition_eng = definition_eng.replace(' it', ' ')\n",
    "                        definition_eng = definition_eng.replace('the ', ' ')\n",
    "                        definition_eng = definition_eng.replace(' a ', ' ')\n",
    "                        \n",
    "                        if definition_text_extra != '':\n",
    "                            definition_text_extra = ' (' + definition_text_extra + ')'\n",
    "\n",
    "                        definition_package = {'register_tag_ru' : register_tag,\n",
    "                                              'definition_ru' : definition_eng + definition_text_extra,\n",
    "                                              'ex_sentence_blank' : ex_sent_with_blank,\n",
    "                                                'ex_sentence_full' : ex_sent_full\n",
    "                                             }\n",
    "\n",
    "                        wikt_definitions.append(definition_package)\n",
    "                        \n",
    "                    index += 1\n",
    "                \n",
    "                \n",
    "                #translate all defs in one API request:\n",
    "                reg_tags_to_translate = []\n",
    "                defs_to_translate = []\n",
    "                for definition in wikt_definitions:\n",
    "                    if definition['register_tag_ru']:\n",
    "                        reg_tags_to_translate.append(definition['register_tag_ru'])\n",
    "                    else:\n",
    "                        reg_tags_to_translate.append('_')\n",
    "                    if definition['definition_ru']:\n",
    "                        defs_to_translate.append(definition['definition_ru'])\n",
    "                    else:\n",
    "                        defs_to_translate.append('_')\n",
    "                    \n",
    "                if reg_tags_to_translate == ['']:\n",
    "                    reg_tags_to_translate = ['_']\n",
    "                \n",
    "                if defs_to_translate == ['']:\n",
    "                    defs_to_translate = ['_']\n",
    "                \n",
    "                text_for_google_translate = ' | '.join(reg_tags_to_translate) + ' || ' + ' | '.join(defs_to_translate)\n",
    "                text_translated = coll_eng_tran(text_for_google_translate)\n",
    "                \n",
    "                reg_tags_translated_text = text_translated.split(' || ')[0]\n",
    "                reg_tags_translated = reg_tags_translated_text.split(' | ')\n",
    "                \n",
    "                defs_translated_text = text_translated.split(' || ')[1]\n",
    "                defs_translated = defs_translated_text.split(' | ')\n",
    "                \n",
    "                idx = 0\n",
    "                while idx + 1 <= len(wikt_definitions):\n",
    "                    definition = wikt_definitions[idx]\n",
    "                    definition['definition_eng'] = defs_translated[idx]\n",
    "                    definition['register_tag_eng'] = reg_tags_translated[idx]\n",
    "                    \n",
    "                    idx += 1\n",
    "                    \n",
    "                \n",
    "                return(wikt_definitions)\n",
    "            else:\n",
    "                return('Error')\n",
    "        else:\n",
    "            return('Error')\n",
    "    except Exception as e:\n",
    "        return('Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "monoling_wikt_scrape('панель')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Collocation filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\ru_prepositions.txt\", 'r', encoding='utf8') as file:\n",
    "    file_read = file.read()\n",
    "    preps = file_read.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define Russian stop words\n",
    "stop_words_lems = []\n",
    "for index, row in rnc_freq_list.iloc[1:1000].iterrows():\n",
    "    poss_to_keep = ['pronoun', 'verb', 'conjunction', 'adverb']\n",
    "    if row['PoS tag'] in poss_to_keep:\n",
    "        if index <= 50 or row['PoS tag'] in ['pronoun', 'conjunction']:\n",
    "            stop_words_lems.append(row['Word'])\n",
    "\n",
    "ru_stop_words = stop_words_lems    \n",
    "\n",
    "particles = ['не']\n",
    "conjs = ['и', 'но', 'а', 'или', ]\n",
    "prons = ['он', 'который']\n",
    "\n",
    "ru_stop_words.remove('сказать')\n",
    "ru_stop_words.remove('всякий')\n",
    "ru_stop_words.remove('некий')\n",
    "ru_stop_words.remove('данный')\n",
    "\n",
    "ru_stop_words += ['нет', 'да', 'более', 'также', 'это', 'все', 'нее', 'очень'] + particles + conjs + prons\n",
    "\n",
    "ru_stop_words = list(set(ru_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Import idiom_dict_df from csv file and convert back to Python dict format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idiom_dict_df = pd.read_csv('C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\idiom_dict_df.csv')\n",
    "\n",
    "idiom_dict_for_check = {}\n",
    "for index, row in idiom_dict_df.iterrows():\n",
    "    idiom_dict_for_check[row['Lemmed coll']] = {'Original ru phrase' : row['Original ru phrase'],\n",
    "                                      'Eng tran' : row['Eng tran']        \n",
    "                                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original ru phrase': ' еще бы ', 'Eng tran': 'coll\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idiom_dict_for_check[' еще бы ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### coll_type_filter function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def coll_type_filter(lemmed_coll, pos_tag_list, case_ahead):\n",
    "    \n",
    "    \n",
    "    punct = ['=', '.', ':', '!', '?', ';', '-', '—', '\\\"', '\\`\\`', '«', '»', '(', ')', ]\n",
    "    ignored_words = ru_stop_words\n",
    "    \n",
    "    coll_as_idiom_dict_key = ' ' + ' '.join(lemmed_coll) + ' '\n",
    "    if (coll_as_idiom_dict_key in idiom_dict_for_check) or (coll_as_idiom_dict_key.replace('ё', 'е') in idiom_dict_for_check):\n",
    "        coll_type = 'lex'\n",
    "    else:\n",
    "        if any([item in punct for item in lemmed_coll]):\n",
    "            coll_type = 'punct'\n",
    "        elif any([item.isdigit() for item in lemmed_coll]):\n",
    "            coll_type = 'ignore'\n",
    "        else:\n",
    "            if (str(lemmed_coll[0]) == ',') or (str(lemmed_coll[-1]) == ','):\n",
    "                coll_type = 'punct'\n",
    "            else:\n",
    "                if len(pos_tag_list) == 1:\n",
    "                    coll_type = 'ignore'\n",
    "                \n",
    "                elif len(pos_tag_list) == 2:\n",
    "                    \n",
    "                    if pos_tag_list[0] == 'PREP' and pos_tag_list[1] == 'NOUN':\n",
    "                        coll_type = 'gram without case ahead'\n",
    "                    elif pos_tag_list[0] == 'NOUN' and pos_tag_list[1] == 'PREP' and case_ahead != 'No case ahead':\n",
    "                        coll_type = 'gram with case ahead'\n",
    "                    elif pos_tag_list[0] in ['INFN', 'PRTF', 'VERB'] and pos_tag_list[1] == 'PREP' and case_ahead != 'No case ahead':\n",
    "                        coll_type = 'gram with case ahead'\n",
    "                    elif pos_tag_list[0] == 'ADJF' and pos_tag_list[1] == 'PREP' and case_ahead != 'No case ahead':\n",
    "                        coll_type = 'gram with case ahead'\n",
    "                    elif pos_tag_list[0] == 'ADVB' and pos_tag_list[1] == 'PREP' and case_ahead != 'No case ahead':\n",
    "                        coll_type = 'gram with case ahead'\n",
    "                    \n",
    "                    elif pos_tag_list[0] == 'ADVB' and pos_tag_list[1] == 'ADJF':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'ADVB' and pos_tag_list[1]  in ['INFN', 'PRTF', 'VERB']:\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'ADJF' and pos_tag_list[1] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'NOUN' and pos_tag_list[1] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0]  in ['INFN', 'PRTF', 'VERB'] and pos_tag_list[1] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'NOUN' and pos_tag_list[1]  in ['INFN', 'PRTF', 'VERB']:\n",
    "                        coll_type = 'lex'\n",
    "\n",
    "                    else:\n",
    "                        coll_type = 'ignore'\n",
    "                \n",
    "                elif len(pos_tag_list) == 3:\n",
    "                    \n",
    "                    if pos_tag_list[0] == 'PREP' and pos_tag_list[1] == 'NOUN' and pos_tag_list[2] == 'PREP' and case_ahead != 'No case ahead':\n",
    "                        coll_type = 'gram with case ahead'\n",
    "                        \n",
    "                    elif pos_tag_list[0] == 'NOUN' and pos_tag_list[2] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'NOUN' and pos_tag_list[1] != 'CONJ' and pos_tag_list[2] in ['INFN', 'PRTF', 'VERB']:\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] in ['INFN', 'PRTF', 'VERB'] and pos_tag_list[1] != 'CONJ' and pos_tag_list[2] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'ADJF' and pos_tag_list[1] == 'NOUN' and pos_tag_list[2] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'PREP' and pos_tag_list[1] == 'ADJF' and pos_tag_list[2] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'PREP' and pos_tag_list[1] == 'NOUN' and pos_tag_list[2] == 'NOUN':\n",
    "                        coll_type = 'lex'\n",
    "                    elif pos_tag_list[0] == 'ADJF' and pos_tag_list[1] == 'CONJ' and pos_tag_list[2] == 'ADJF':\n",
    "                        coll_type = 'lex'\n",
    "                    \n",
    "                    else:\n",
    "                        coll_type = 'ignore'\n",
    "                        \n",
    "                elif len(pos_tag_list) >= 4:\n",
    "                    \n",
    "                    if pos_tag_list[-1] != 'ADJF':\n",
    "                        coll_type = 'lex'\n",
    "                    else:\n",
    "                        coll_type = 'ignore'\n",
    "                                \n",
    "        stop_word_bool = False\n",
    "        if coll_type == 'lex':\n",
    "            if str(lemmed_coll[0]) not in ignored_words and str(lemmed_coll[-1]) not in ignored_words:\n",
    "                coll_type = 'lex'\n",
    "            else:\n",
    "                coll_type = 'ignore'\n",
    "    \n",
    "    if len(lemmed_coll) == 1:\n",
    "        coll_type = 'ignore'\n",
    "        \n",
    "    return coll_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lex'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_type_filter(('хотя', 'бы'), ['CONJ', 'PART'], 'No case ahead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus_size = rnc_freq_list['Estimated frequency'].sum()\n",
    "word_freq_dict = {}\n",
    "for index, row in rnc_freq_list.iterrows():\n",
    "    word_freq_dict[row['Word']] = row['Estimated frequency']\n",
    "    \n",
    "def coll_score(n_grams_df_row):\n",
    "    lemmed_coll = n_grams_df_row['Lemmed collocation']\n",
    "    raw_freq = n_grams_df_row['Raw frequency']\n",
    "    freq = n_grams_df_row['Frequency']\n",
    "    \n",
    "    combined_freq = 1\n",
    "    for item in lemmed_coll:\n",
    "        combined_freq = combined_freq * word_freq_dict[item]\n",
    "    \n",
    "    mi_score = math.log2(freq * corpus_size / combined_freq)\n",
    "    \n",
    "    return mi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-41.982015669342914"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'Lemmed collocation': [('как', 'бы', 'то', 'ни', 'быть')],\n",
    "                       'Raw frequency' : 110,\n",
    "                       'Frequency' : 2000})\n",
    "\n",
    "coll_score(test_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Collocational analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lem_coll(coll):\n",
    "    lem_coll = []\n",
    "    for word in coll:\n",
    "        p = morph.parse(word)[0]\n",
    "        lem_coll.append(p.normal_form)\n",
    "    return lem_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['для', ',', 'время']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_coll(['для', ',', 'времен'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def complex_lem_coll(coll):\n",
    "    lem_coll = []\n",
    "    lem = True\n",
    "    for word in coll:\n",
    "        p = morph.parse(word)[0]\n",
    "        pos = p.tag.POS\n",
    "        if lem == True:\n",
    "            lem_coll.append(p.normal_form)\n",
    "        else:\n",
    "            lem_coll.append(word)\n",
    "        if pos == 'PREP':\n",
    "            lem = False\n",
    "        elif pos in ['INFN', 'VERB', 'NOUN']:\n",
    "            lem = True\n",
    "        \n",
    "    return lem_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sent = 'Из тумана вышла лагерная ограда – ряды проволоки , натянутые между железобетонными столбами'\n",
    "coll = sent.split(' ')\n",
    "complex_lem_coll(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lem_coll(['для', ',', 'времен'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def colls_from_sents_df_row(row, **kwargs):\n",
    "    \n",
    "    for arg in kwargs:\n",
    "        query_forms = kwargs[arg] \n",
    "    \n",
    "    source = row['Source']\n",
    "    src_sent = row['Standardised source sentence']\n",
    "    sent_words_raw = row['Standardised source sentence'].replace('  ', ' ').split(' ')\n",
    "    lemmed_sent_words_raw = row['Lemmed source sentence'].replace('  ', ' ').split(' ')\n",
    "#     lemmed_sent_words_raw = row['Coll lemmed source sentence'].replace('  ', ' ').split(' ')\n",
    "    pos_tag_list_raw = row['Source sentence PoS tags'].split(' ')\n",
    "    case_list_raw = row['Source sentence cases'].split(' ')\n",
    "    target_sent = row['Standardised target sentence']\n",
    "    \n",
    "    sent_words = []\n",
    "    lemmed_sent_words = []\n",
    "    pos_tag_list = []\n",
    "    case_list = []\n",
    "    token_idx = 0\n",
    "    for token in lemmed_sent_words_raw:\n",
    "        if token != '':\n",
    "            lemmed_sent_words.append(token)\n",
    "            sent_words.append(sent_words_raw[token_idx])\n",
    "            pos_tag_list.append(pos_tag_list_raw[token_idx])\n",
    "            if case_list_raw[token_idx] == 'nomn':\n",
    "                case_list.append('accs')\n",
    "            else:\n",
    "                case_list.append(case_list_raw[token_idx])\n",
    "        token_idx += 1\n",
    "\n",
    "    for query in query_forms:\n",
    "        try:\n",
    "            q_idx = lemmed_sent_words.index(query)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    start_b0 = []\n",
    "    start_b1 = []\n",
    "    start_b2 = []\n",
    "    start_b3 = []\n",
    "    start_b4 = []\n",
    "    \n",
    "    words_behind = 0\n",
    "    while words_behind <= 3 and words_behind <= q_idx:\n",
    "        words_ahead = 3\n",
    "        while words_ahead >= 1:\n",
    "            if q_idx + words_ahead <= len(sent_words):\n",
    "                n_gram = sent_words[q_idx - words_behind:q_idx + words_ahead]\n",
    "                n_gram = [word.lower() for word in n_gram]\n",
    "                lemmed_n_gram = lemmed_sent_words[q_idx - words_behind:q_idx + words_ahead]\n",
    "                n_gram_pos_list = pos_tag_list[q_idx - words_behind:q_idx + words_ahead]\n",
    "                n_gram_case_list = case_list[q_idx - words_behind:q_idx + words_ahead]\n",
    "                \n",
    "                if q_idx + words_ahead + 1 < len(sent_words):\n",
    "                    if n_gram_pos_list[-1] == 'VERB' or 'INFN' or 'PREP':\n",
    "                        case_of_next_token = str(case_list[q_idx + words_ahead + 1])\n",
    "                        if case_of_next_token != 'None':\n",
    "                            case_ahead = case_of_next_token\n",
    "                        else:\n",
    "                            case_ahead = 'No case ahead'\n",
    "                    else:\n",
    "                        case_ahead = 'No case ahead'\n",
    "                else:\n",
    "                    case_ahead = 'No case ahead'\n",
    "                if case_ahead == 'None':\n",
    "                    print('COLLS FROM SENTS DF ROW LABELLED CASE AHEAD AS NONE')\n",
    "                    case_ahead = 'No case ahead'\n",
    "\n",
    "                # PASS N-GRAM THROUGH COLL TYPE FILTER TO FIND COLL TYPE:\n",
    "                coll_type = coll_type_filter(lemmed_n_gram, n_gram_pos_list, case_ahead)\n",
    "                \n",
    "                src_sent_term_bold_list = []\n",
    "                src_sent_coll_bold_list = []\n",
    "                idx = 0\n",
    "                for token in sent_words_raw:\n",
    "                    if idx == q_idx:\n",
    "                        src_sent_term_bold_list.append('<b><i>' + token + '</i></b>')\n",
    "                        src_sent_coll_bold_list.append('<b><i>' + token + '</i></b>')\n",
    "                    elif idx in [i for i in range(q_idx - words_behind, q_idx + words_ahead) if i != q_idx]:\n",
    "                        src_sent_term_bold_list.append(token)\n",
    "                        src_sent_coll_bold_list.append('<b>' + token + '</b>')\n",
    "                    else:\n",
    "                        src_sent_term_bold_list.append(token)\n",
    "                        src_sent_coll_bold_list.append(token)\n",
    "                    idx += 1\n",
    "                src_sent_term_bold = ' '.join(src_sent_term_bold_list)\n",
    "                src_sent_coll_bold = ' '.join(src_sent_coll_bold_list)\n",
    "                \n",
    "                meaning_dependent_info = []\n",
    "                count_case = False\n",
    "                for token in n_gram:\n",
    "                    if count_case == True:\n",
    "                        meaning_dependent_info.append(n_gram_pos_list[n_gram.index(token)])\n",
    "                    else:\n",
    "                        meaning_dependent_info.append('')\n",
    "                    if n_gram_pos_list[n_gram.index(token)] == 'PREP':\n",
    "                        count_case = True\n",
    "                        \n",
    "                n_gram_package = {}\n",
    "                n_gram_package['Source'] = source\n",
    "                n_gram_package['Source sentence with term bold'] = src_sent_term_bold\n",
    "                n_gram_package['Source sentence with coll bold'] = src_sent_coll_bold\n",
    "                n_gram_package['Source'] = source\n",
    "                n_gram_package['Collocation type'] = coll_type\n",
    "                n_gram_package['Original N-gram'] = n_gram\n",
    "                n_gram_package['Lemmed N-gram'] = lemmed_n_gram\n",
    "                n_gram_package['Case ahead'] = case_ahead\n",
    "                n_gram_package['N-gram PoS tags'] = n_gram_pos_list\n",
    "                n_gram_package['N-gram cases'] = n_gram_case_list\n",
    "                n_gram_package['N-gram meaning dependent info'] = meaning_dependent_info\n",
    "                n_gram_package['N-gram term position'] = q_idx\n",
    "                n_gram_package['N-gram collocate positions'] = [i for i in range(q_idx - words_behind, q_idx + words_ahead)  if i != q_idx]\n",
    "                n_gram_package['Edited N-grams'] = []\n",
    "\n",
    "                #COUNT COLLOCATIONS AT A DISTANCE (i.e. colls separated by a word).\n",
    "                for word in n_gram[1:-1]:\n",
    "                    word_idx = n_gram.index(word)\n",
    "                    if sent_words.index(word) != q_idx:\n",
    "                        word_before_pos = pos_tag_list[sent_words.index(word)-1] \n",
    "                        word_pos = pos_tag_list[sent_words.index(word)] \n",
    "                        word_ahead_pos = pos_tag_list[sent_words.index(word)+1] \n",
    "                        removable_pos_tags = ['ADVB', 'ADJF']\n",
    "                        if (word_pos in removable_pos_tags) or (word_before_pos in ['INFN', 'VERB'] and word_pos in ['NOUN', 'NPRO'] and word_ahead_pos == 'PREP'):\n",
    "\n",
    "                            mut_n_gram = n_gram[:]\n",
    "                            del mut_n_gram[word_idx]\n",
    "                            edited_n_gram = mut_n_gram\n",
    "                            edited_n_gram = [word.lower() for word in edited_n_gram]\n",
    "\n",
    "                            mut_lemmed_n_gram = lemmed_n_gram[:]\n",
    "                            del mut_lemmed_n_gram[word_idx]\n",
    "                            lemmed_edited_n_gram = [word.lower() for word in mut_lemmed_n_gram]\n",
    "\n",
    "                            mut_pos_list = n_gram_pos_list[:]\n",
    "                            del mut_pos_list[word_idx]\n",
    "                            edited_pos_tags = mut_pos_list\n",
    "\n",
    "                            mut_case_list = n_gram_case_list[:]\n",
    "                            del mut_case_list[word_idx]\n",
    "                            edited_case_list = mut_case_list\n",
    "                            \n",
    "                            # PASS N-GRAM THROUGH COLL TYPE FILTER TO FIND COLL TYPE:\n",
    "                            edited_coll_type = coll_type_filter(lemmed_edited_n_gram, edited_pos_tags, case_ahead)\n",
    "\n",
    "                            src_sent_term_bold_list = []\n",
    "                            src_sent_coll_bold_list = []\n",
    "                            idx = 0\n",
    "                            for token in sent_words_raw:\n",
    "                                if idx == q_idx:\n",
    "                                    src_sent_term_bold_list.append('<b><i>' + token + '</i></b>')\n",
    "                                    src_sent_coll_bold_list.append('<b><i>' + token + '</i></b>')\n",
    "                                elif idx in [i for i in range(q_idx - words_behind, q_idx + words_ahead)  if i != q_idx and i != sent_words.index(word)]:\n",
    "                                    src_sent_term_bold_list.append(token)\n",
    "                                    src_sent_coll_bold_list.append('<b>' + token + '</b>')\n",
    "                                else:\n",
    "                                    src_sent_term_bold_list.append(token)\n",
    "                                    src_sent_coll_bold_list.append(token)\n",
    "                                idx += 1\n",
    "                            src_sent_term_bold = ' '.join(src_sent_term_bold_list)\n",
    "                            src_sent_coll_bold = ' '.join(src_sent_coll_bold_list)\n",
    "                            \n",
    "                            meaning_dependent_info = []\n",
    "                            count_case = False\n",
    "                            for token in n_gram:\n",
    "                                if count_case == True:\n",
    "                                    meaning_dependent_info.append(n_gram_pos_list[n_gram.index(token)])\n",
    "                                else:\n",
    "                                    meaning_dependent_info.append('')\n",
    "                                if n_gram_pos_list[n_gram.index(token)] == 'PREP':\n",
    "                                    count_case = True\n",
    "                            \n",
    "                            n_gram_package['Edited N-grams'].append({'Source' : source,\n",
    "                                                                     'N-gram collocate positions' : [i for i in range(q_idx - words_behind, q_idx + words_ahead) if i != q_idx and i != sent_words.index(word)]\n",
    "                                                                    })\n",
    "                if words_behind == 0:\n",
    "                    if n_gram_package not in start_b0:\n",
    "                        start_b0.append(n_gram_package)\n",
    "                elif words_behind == 1:\n",
    "                    if n_gram_package not in start_b1:\n",
    "                        start_b1.append(n_gram_package)\n",
    "                elif words_behind == 2:\n",
    "                    if n_gram_package not in start_b2:\n",
    "                        start_b2.append(n_gram_package)\n",
    "                elif words_behind == 3:\n",
    "                    if n_gram_package not in start_b3:\n",
    "                        start_b3.append(n_gram_package)\n",
    "                elif words_behind == 4:\n",
    "                    if n_gram_package not in start_b4:\n",
    "                        start_b4.append(n_gram_package)\n",
    "\n",
    "            words_ahead = words_ahead - 1\n",
    "        words_behind += 1\n",
    "\n",
    "    sent_package = {'Source' : source,\n",
    "                    'Source sentence' : src_sent,\n",
    "                    'Target sentence' : target_sent,\n",
    "                    'PoS tag list' : pos_tag_list,\n",
    "                    'Case list' : case_list,\n",
    "                    'N-grams' : {'start_b0' : start_b0,\n",
    "                                  'start_b1' : start_b1,\n",
    "                                  'start_b2' : start_b2,\n",
    "                                  'start_b3' : start_b3,\n",
    "                                  'start_b4' : start_b4\n",
    "                                 }\n",
    "                    }\n",
    "\n",
    "    return sent_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-33f95a51e974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolls_from_sents_df_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_forms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_forms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "idx = 1\n",
    "while idx <= 1:\n",
    "    pp.pprint(colls_from_sents_df_row(results_df.iloc[6], query_forms = query_forms))\n",
    "    idx += 1\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     157,
     182
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_colls(sent_packages, query_forms, raw_min_coll_freq, est_min_coll_freq, est_eng_def_freq, raw_eng_def_freq, est_term_freq, raw_term_freq):\n",
    "\n",
    "    n_grams_df = pd.DataFrame()\n",
    "    colls_added = []\n",
    "    \n",
    "    for package in sent_packages:\n",
    "        src_sent = package['Source sentence']\n",
    "        target_sent = package['Target sentence']\n",
    "        pos_tag_list = package['PoS tag list']\n",
    "        case_list = package['Case list']\n",
    "        n_grams_package = package['N-grams']\n",
    "\n",
    "        for group, package in n_grams_package.items():\n",
    "\n",
    "            coll_matched = False\n",
    "            if package != []:\n",
    "                for n_gram in package:\n",
    "\n",
    "                        src = n_gram['Source']\n",
    "                        src_sent_term_bold = n_gram['Source sentence with term bold']\n",
    "                        src_sent_coll_bold = n_gram['Source sentence with coll bold']\n",
    "                        coll_type = n_gram['Collocation type']\n",
    "                        lemmed_coll_only = n_gram['Lemmed N-gram']\n",
    "                        original_coll_only = n_gram['Original N-gram']\n",
    "                        case_ahead = n_gram['Case ahead']\n",
    "                        coll_pos_tags = tuple(n_gram['N-gram PoS tags'])\n",
    "                        coll_cases = tuple(n_gram['N-gram cases'])\n",
    "                        n_gram_idx = len(original_coll_only)\n",
    "\n",
    "                        if coll_type == 'gram with case ahead':\n",
    "                            lemmed_coll = tuple(lemmed_coll_only + [case_ahead])\n",
    "                            original_coll = tuple(original_coll_only + [case_ahead])\n",
    "                        else:\n",
    "                            lemmed_coll = tuple(lemmed_coll_only)\n",
    "                            original_coll = tuple(original_coll_only)\n",
    "\n",
    "                        reorder_coll = False\n",
    "                        if n_gram_idx == 2:\n",
    "                            if ('ADVB' in coll_pos_tags) and (any(['INFN', 'PRTF', 'VERB']) in coll_pos_tags):\n",
    "                                reordered_lemmed_coll = [lemmed_coll[1], lemmed_coll[0]]\n",
    "                                reorder_coll = True\n",
    "                        elif n_gram_idx == 3:\n",
    "                            if (coll_pos_tags[0] == 'PREP') and (coll_pos_tags[1] == 'NOUN') and (coll_pos_tags[2] in ['INFN', 'PRTF', 'VERB']):\n",
    "                                reordered_lemmed_coll = [lemmed_coll[2], lemmed_coll[0], lemmed_coll[1]]\n",
    "                                reorder_coll = True\n",
    "\n",
    "                        if lemmed_coll in colls_added:\n",
    "                            n_grams_df = n_grams_df.append({'Source' : src,\n",
    "                                                            'Source sentence with term bold' : src_sent_term_bold,\n",
    "                                                            'Source sentence with coll bold' : src_sent_coll_bold,\n",
    "                                                            'Target sentence' : target_sent,\n",
    "                                                            'Original collocation' : original_coll,\n",
    "                                                            'Lemmed collocation' : lemmed_coll,\n",
    "                                                            'Collocation type' : coll_type\n",
    "                                                            },\n",
    "                                                              ignore_index = True)\n",
    "                            coll_matched = True\n",
    "                            colls_added.append(lemmed_coll)\n",
    "\n",
    "                        elif (lemmed_coll not in colls_added) and (reorder_coll == True):\n",
    "                            if reordered_lemmed_coll in colls_added:\n",
    "                                n_grams_df = n_grams_df.append({'Source' : src,\n",
    "                                                                'Source sentence with term bold' : src_sent_term_bold,\n",
    "                                                                'Source sentence with coll bold' : src_sent_coll_bold,\n",
    "                                                                'Target sentence' : target_sent,\n",
    "                                                                'Original collocation' : original_coll,\n",
    "                                                                'Lemmed collocation' : reordered_lemmed_coll,\n",
    "                                                                'Collocation type' : coll_type\n",
    "                                                                },\n",
    "                                                                  ignore_index = True)\n",
    "                                coll_matched = True\n",
    "                                colls_added.append(reordered_lemmed_coll)\n",
    "\n",
    "                        elif (lemmed_coll not in colls_added) and (reorder_coll == False):\n",
    "                                n_grams_df = n_grams_df.append({'Source' : src,\n",
    "                                                                'Source sentence with term bold' : src_sent_term_bold,\n",
    "                                                                'Source sentence with coll bold' : src_sent_coll_bold,\n",
    "                                                                'Target sentence' : target_sent,\n",
    "                                                                'Original collocation' : original_coll,\n",
    "                                                                'Lemmed collocation' : lemmed_coll,\n",
    "                                                                'Collocation type' : coll_type\n",
    "                                                                },\n",
    "                                                                  ignore_index = True)\n",
    "                                colls_added.append(lemmed_coll)\n",
    "\n",
    "                        if coll_matched == False:\n",
    "                            edited_n_grams = n_gram['Edited N-grams']\n",
    "                            for edited_n_gram in edited_n_grams:\n",
    "\n",
    "                                src = edited_n_gram['Source']\n",
    "                                src_sent_term_bold = edited_n_gram['Source sentence with term bold']\n",
    "                                src_sent_coll_bold = edited_n_gram['Source sentence with coll bold']\n",
    "                                coll_type = edited_n_gram['Collocation type']\n",
    "                                lemmed_coll_only = edited_n_gram['Lemmed Edited N-gram']\n",
    "                                original_coll_only = edited_n_gram['Original Edited N-gram']\n",
    "                                case_ahead = edited_n_gram['Case ahead']\n",
    "                                coll_pos_tags = tuple(edited_n_gram['Edited N-gram PoS tags'])\n",
    "                                coll_cases = tuple(edited_n_gram['Edited N-gram cases'])\n",
    "                                n_gram_idx = len(original_coll_only)\n",
    "\n",
    "                                if coll_type == 'gram with case ahead':\n",
    "                                    lemmed_coll = tuple(lemmed_coll_only + [case_ahead])\n",
    "                                    original_coll = tuple(original_coll_only + [case_ahead])\n",
    "                                else:\n",
    "                                    lemmed_coll = tuple(lemmed_coll_only)\n",
    "                                    original_coll = tuple(original_coll_only)\n",
    "\n",
    "                                reorder_coll = False\n",
    "                                if n_gram_idx == 2:\n",
    "                                    if ('ADVB' in coll_pos_tags) and (any(['INFN', 'PRTF', 'VERB']) in coll_pos_tags):\n",
    "                                        reordered_lemmed_coll = [lemmed_coll[1], lemmed_coll[0]]\n",
    "                                        reorder_coll = True\n",
    "                                elif n_gram_idx == 3:\n",
    "                                    if (coll_pos_tags[0] == 'PREP') and (coll_pos_tags[1] == 'NOUN') and (coll_pos_tags[2] in ['INFN', 'PRTF', 'VERB']):\n",
    "                                        reordered_lemmed_coll = [lemmed_coll[2], lemmed_coll[0], lemmed_coll[1]]\n",
    "                                        reorder_coll = True\n",
    "\n",
    "                                if lemmed_coll in colls_added:\n",
    "                                    n_grams_df = n_grams_df.append({'Source' : src,\n",
    "                                                                    'Source sentence with term bold' : src_sent_term_bold,\n",
    "                                                                    'Source sentence with coll bold' : src_sent_coll_bold,\n",
    "                                                                    'Target sentence' : target_sent,\n",
    "                                                                    'Original collocation' : original_coll,\n",
    "                                                                    'Lemmed collocation' : lemmed_coll,\n",
    "                                                                    'Collocation type' : coll_type\n",
    "                                                                    },\n",
    "                                                                      ignore_index = True)\n",
    "                                    coll_matched = True\n",
    "                                    colls_added.append(lemmed_coll)\n",
    "\n",
    "                                elif (lemmed_coll not in colls_added) and (reorder_coll == True):\n",
    "                                    if reordered_lemmed_coll in colls_added:\n",
    "                                        n_grams_df = n_grams_df.append({'Source' : src,\n",
    "                                                                        'Source sentence with term bold' : src_sent_term_bold,\n",
    "                                                                        'Source sentence with coll bold' : src_sent_coll_bold,\n",
    "                                                                        'Target sentence' : target_sent,\n",
    "                                                                        'Original collocation' : original_coll,\n",
    "                                                                        'Lemmed collocation' : reordered_lemmed_coll,\n",
    "                                                                        'Collocation type' : coll_type\n",
    "                                                                        },\n",
    "                                                                          ignore_index = True)\n",
    "                                        coll_matched = True\n",
    "                                        colls_added.append(reordered_lemmed_coll)\n",
    "\n",
    "                                elif (lemmed_coll not in colls_added) and (reorder_coll == False):\n",
    "                                    n_grams_df = n_grams_df.append({'Source' : src,\n",
    "                                                                    'Source sentence with term bold' : src_sent_term_bold,\n",
    "                                                                    'Source sentence with coll bold' : src_sent_coll_bold,\n",
    "                                                                    'Target sentence' : target_sent,\n",
    "                                                                    'Original collocation' : original_coll,\n",
    "                                                                    'Lemmed collocation' : lemmed_coll,\n",
    "                                                                    'Collocation type' : coll_type\n",
    "                                                                    },\n",
    "                                                                      ignore_index = True)\n",
    "                                    colls_added.append(lemmed_coll)\n",
    "\n",
    "\n",
    "    def extract_eng_n_grams(df_row):\n",
    "        target_sent = df_row['Target sentence']\n",
    "        sent_tokens1 = target_sent.split(' ')\n",
    "        sent_tokens = []\n",
    "        for token in sent_tokens1:\n",
    "            if token != '':\n",
    "                sent_tokens.append(token)\n",
    "        n_grams_package = []\n",
    "        start_token_idx = 0\n",
    "        while start_token_idx < sent_tokens.index(sent_tokens[-1]):\n",
    "            start_token_list = []\n",
    "            end_token_idx = sent_tokens.index(sent_tokens[-1])\n",
    "            while start_token_idx < end_token_idx:\n",
    "                n_gram_list = sent_tokens[start_token_idx:end_token_idx]\n",
    "                lemmed_n_gram_list = n_gram_list\n",
    "                #lemmed_n_gram_list = [english_lemmatizer.lemmatize(token) for token in n_gram_list]\n",
    "                start_token_list.append({'Original n-gram' : n_gram_list,\n",
    "                                         'Lemmed n-gram' : lemmed_n_gram_list,\n",
    "                                         'Target sentence' : target_sent\n",
    "                                        })\n",
    "                end_token_idx = end_token_idx - 1\n",
    "            n_grams_package.append(start_token_list)\n",
    "            start_token_idx += 1\n",
    "        return n_grams_package\n",
    "\n",
    "    def top_eng_n_gram(series):\n",
    "        n_grams_df = pd.DataFrame()\n",
    "        colls_added = []\n",
    "        for n_grams_package in series:\n",
    "            for start_token_list in n_grams_package:\n",
    "                coll_matched = False\n",
    "                for n_gram_package in start_token_list:\n",
    "                    n_gram_tuple = tuple(n_gram_package['Original n-gram'])\n",
    "                    lemmed_n_gram_tuple = n_gram_package['Lemmed n-gram']\n",
    "                    target_sent = n_gram_package['Target sentence']\n",
    "                    if coll_matched == False:\n",
    "                        # FILTER THE ENG N-GRAMS HERE:\n",
    "                        if any(token in string.punctuation for token in lemmed_n_gram_tuple) == False:\n",
    "                            contains_num = False\n",
    "                            for token in lemmed_n_gram_tuple:\n",
    "                                if any(char.isnumeric() for char in token):\n",
    "                                    contains_num = True\n",
    "                            if contains_num == False:\n",
    "                                if lemmed_n_gram_tuple[0] not in eng_stop_words:\n",
    "                                    if lemmed_n_gram_tuple[-1] not in eng_stop_words:\n",
    "                                        ('--> PASSED THROUGH ENG COLL FILTER.')\n",
    "                                        if lemmed_n_gram_tuple in colls_added:\n",
    "                                            n_grams_df = n_grams_df.append({'Lemmed n-gram' : lemmed_n_gram_tuple,\n",
    "                                                                            'Original n-gram' : n_gram_tuple,\n",
    "                                                                            'Target sentence' : target_sent\n",
    "                                                                           }, ignore_index = True)\n",
    "                                            coll_matched = True\n",
    "                                            colls_added.append(lemmed_n_gram_tuple)\n",
    "                                        else:\n",
    "                                            n_grams_df = n_grams_df.append({'Lemmed n-gram' : lemmed_n_gram_tuple,\n",
    "                                                                            'Original n-gram' : n_gram_tuple,\n",
    "                                                                            'Target sentence' : target_sent\n",
    "                                                                           }, ignore_index = True)\n",
    "                                            colls_added.append(lemmed_n_gram_tuple)\n",
    "#                                     else:\n",
    "#                                         print('COLL CONTAINS STOP WORDS AT END --> DIDN\\'T PASS THROUGH ENG COLL FILTER.')\n",
    "#                                 else:\n",
    "#                                     print('COLL CONTAINS STOP WORDS AT START --> DIDN\\'T PASS THROUGH ENG COLL FILTER.')\n",
    "#                             else:\n",
    "#                                 print('COLL CONTAINS NUMERAL --> DIDN\\'T PASS THROUGH ENG COLL FILTER.')\n",
    "#                         else:\n",
    "#                             print('COLL CONTAINS PUNCT --> DIDN\\'T PASS THROUGH ENG COLL FILTER.')\n",
    "\n",
    "        if n_grams_df.empty == True:\n",
    "            top_eng_coll_df_row = pd.DataFrame()\n",
    "        else:\n",
    "            group_idx = 1\n",
    "            for name, group_df in n_grams_df.groupby(['Lemmed n-gram']):\n",
    "                if group_idx == 1:\n",
    "                    top_eng_coll_df_row = group_df.head(1)\n",
    "                group_idx += 1\n",
    "\n",
    "        return top_eng_coll_df_row\n",
    "\n",
    "    colls_df = pd.DataFrame()\n",
    "    if n_grams_df.empty == False:\n",
    "        for name, group_df in n_grams_df.groupby(['Lemmed collocation']):\n",
    "            top_n_gram_row = group_df.head(1)\n",
    "            top_n_gram_row['Target sentence n-gram'] = top_n_gram_row['Target sentence']\n",
    "            top_n_gram_row['Raw frequency'] = len(group_df.index)\n",
    "            top_n_gram_row['Frequency'] = round(est_term_freq * len(group_df.index)/raw_term_freq)\n",
    "            #top_n_gram_row['Source sentence with term bold'] = group_df.iloc[0]['Source sentence with term bold']\n",
    "            #top_n_gram_row['Source sentence with coll bold'] = group_df.iloc[0]['Source sentence with coll bold']\n",
    "            #top_n_gram_row['Target sentence'] = group_df.iloc[0]['Target sentence']\n",
    "            \n",
    "            other_sent_pairs_en = ''\n",
    "            other_sent_pairs_ru_term_in_bold = ''\n",
    "            other_sent_pairs_ru_coll_in_bold = ''\n",
    "            other_sent_pairs_en_ru_term_in_bold = ''\n",
    "            other_sent_pairs_ru_term_in_bold_en = ''\n",
    "            other_sent_pairs_en_ru_coll_in_bold = ''\n",
    "            other_sent_pairs_ru_coll_in_bold_en = ''\n",
    "            idx = 1\n",
    "            for index, row in group_df.iloc[1:].iterrows():\n",
    "                other_sent_pairs_en += row['Target sentence'] + '<br><br>'\n",
    "                other_sent_pairs_ru_term_in_bold += row['Source sentence with term bold'] + '<br><br>'\n",
    "                other_sent_pairs_ru_coll_in_bold += row['Source sentence with coll bold'] + '<br><br>'\n",
    "                other_sent_pairs_en_ru_term_in_bold += str(row['Target sentence']) + '<br>' + '<font color=\\\"green\\\">' + row['Source sentence with term bold'] + '</font>' + '<br><br>'\n",
    "                other_sent_pairs_ru_term_in_bold_en += row['Source sentence with term bold'] + '<br>' + '<font color=\\\"green\\\">' + row['Target sentence'] + '</font>' + '<br><br>'\n",
    "                other_sent_pairs_en_ru_coll_in_bold += str(row['Target sentence']) + '<br>' + '<font color=\\\"green\\\">' + row['Source sentence with coll bold'] + '</font>' + '<br><br>'\n",
    "                other_sent_pairs_ru_coll_in_bold_en += row['Source sentence with coll bold'] + '<br>' + '<font color=\\\"green\\\">' + row['Target sentence'] + '</font>' + '<br><br>'\n",
    "                idx += 1\n",
    "                if idx == 7:\n",
    "                    break\n",
    "\n",
    "            top_n_gram_row['Other sentence pairs en'] = other_sent_pairs_en\n",
    "            top_n_gram_row['Other sentence pairs ru term in bold'] = other_sent_pairs_ru_term_in_bold\n",
    "            top_n_gram_row['Other sentence pairs ru coll in bold'] = other_sent_pairs_ru_coll_in_bold\n",
    "            top_n_gram_row['Other sentence pairs en ru term in bold'] = other_sent_pairs_en_ru_term_in_bold\n",
    "            top_n_gram_row['Other sentence pairs ru term in bold en'] = other_sent_pairs_ru_term_in_bold_en\n",
    "            top_n_gram_row['Other sentence pairs en ru coll in bold'] = other_sent_pairs_en_ru_coll_in_bold\n",
    "            top_n_gram_row['Other sentence pairs ru coll in bold en'] = other_sent_pairs_ru_coll_in_bold_en\n",
    "\n",
    "            colls_df = colls_df.append(top_n_gram_row, ignore_index = True)\n",
    "\n",
    "    colls_df = colls_df.sort_values('Frequency', ascending=False)\n",
    "    \n",
    "    gram_colls_df = colls_df[colls_df['Collocation type'].isin(['gram with case ahead', 'gram without case ahead'])]\n",
    "    lex_colls_df = colls_df[colls_df['Collocation type']=='lex']\n",
    "        \n",
    "    print('\\n\\tCOUNT COLLS: EST MIN COLL FREQ:', est_min_coll_freq)\n",
    "    print('\\tCOUNT COLLS: RAW MIN COLL FREQ:', raw_min_coll_freq)\n",
    "    \n",
    "    print('\\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ')\n",
    "    if lex_colls_df[(lex_colls_df['Frequency']>=est_min_coll_freq) & (lex_colls_df['Raw frequency']>= raw_min_coll_freq)].empty == False:\n",
    "        return_df = lex_colls_df[(lex_colls_df['Frequency']>=est_min_coll_freq) & (lex_colls_df['Raw frequency']>= raw_min_coll_freq)]\n",
    "        default_to_top_coll = False\n",
    "    else:\n",
    "        default_to_top_coll = True\n",
    "        print('\\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ')\n",
    "        if gram_colls_df[(gram_colls_df['Frequency']>=est_min_coll_freq) & (gram_colls_df['Raw frequency']>= raw_min_coll_freq)].empty == False:\n",
    "            return_df = gram_colls_df[(gram_colls_df['Frequency']>=est_min_coll_freq) & (gram_colls_df['Raw frequency']>= raw_min_coll_freq)].head(1)\n",
    "        else:\n",
    "            print('\\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ')\n",
    "            if lex_colls_df.empty == False:\n",
    "                return_df = lex_colls_df.head(1)\n",
    "            else:\n",
    "                print('\\tCOUNT COLLS: FILTERING FOR DEFAULT GRAM COLLS BELOW MIN COLL FREQ')\n",
    "                if gram_colls_df.empty == False:\n",
    "                    return_df = gram_colls_df.head(1)\n",
    "                else:\n",
    "                    print('\\tCOUNT COLLS: FILTERING FOR NO PUNCT COLLS')\n",
    "                    no_punct_df = colls_df[colls_df['Collocation type']!='punct']\n",
    "                    if no_punct_df.empty == False:\n",
    "                        return_df = no_punct_df.head(1)\n",
    "                    else:\n",
    "                        print('\\tCOUNT COLLS: DEFAULTING TO FIRST ROW IN COLLS DF')\n",
    "                        if colls_df.empty == False:\n",
    "                            return_df = colls_df.head(1)\n",
    "                        else:\n",
    "                            print('\\tCOUNT_COLLS: NO COLLOCATIONS FOUND.')\n",
    "\n",
    "    return lex_colls_df, return_df, gram_colls_df.head(3), default_to_top_coll\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create idiom dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Scrape wordreference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def wordref_phrases_scrape(word):\n",
    "    \n",
    "    base_url = \"https://www.wordreference.com/ruen\"\n",
    "    full_url = base_url + '/' + word\n",
    "    full_url = full_url.replace('\\n','')\n",
    "    response = requests.get(full_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        for a in soup.select('div #article'):\n",
    "            # to extract the phrases in the wordref definition\n",
    "            if a.find('span', 'phrase') != None:\n",
    "                extracted_phrases_dict = {}\n",
    "                \n",
    "                quick_dict = {}\n",
    "                \n",
    "                for phrase_ru_tag in a.findAll('span', 'phrase'):\n",
    "                    \n",
    "                    phrase_ru_text = phrase_ru_tag.get_text()\n",
    "                    phrase_ru_text = phrase_ru_text\n",
    "                    \n",
    "                    #print(phrase_ru_text, phrase_en_text)\n",
    "                    \n",
    "                    #Divide phrase syntax into multiple phrases where applicable:\n",
    "                    phrase_variants = ['', '', '']\n",
    "                    \n",
    "                    phrase_ru_text_list = []\n",
    "                    \n",
    "                    idx = 0\n",
    "                    for word in phrase_ru_text.split(' '):\n",
    "                        \n",
    "                        #print(word)\n",
    "                        \n",
    "                        if '/' in phrase_ru_text:\n",
    "                            #print(phrase_ru_text.split('/'))\n",
    "                            phrase_ru_text_list.append(word.split('/'))\n",
    "                        else:\n",
    "                            phrase_ru_text_list.append([word])\n",
    "                        \n",
    "                        idx += 1\n",
    "                            \n",
    "                    #print(phrase_ru_text_list)\n",
    "                    \n",
    "                    \n",
    "                    for word_group in phrase_ru_text_list:\n",
    "                        #print(word_group)\n",
    "                        for word in word_group:\n",
    "                            for item in phrase_variants:\n",
    "                                item += word + ' '\n",
    "                    \n",
    "                    #print(phrase_variants)\n",
    "                    \n",
    "                    next_el = phrase_ru_tag.findNext()\n",
    "                    if next_el.has_attr('class'):\n",
    "                        \n",
    "                        if next_el[\"class\"][0] == 'IN':\n",
    "                            \n",
    "                            phrase_ru_text += ' (' + next_el.get_text() + ')'\n",
    "                        \n",
    "                        elif next_el.get(\"class\")[0] == 'ital' and next_el.get_text() == 'или':\n",
    "                            \n",
    "                            words = phrase_ru_text.split(' ')\n",
    "            \n",
    "                            idx = 0\n",
    "                            phrase_start = ''\n",
    "                            phrase_one_end = ''\n",
    "                            phrase_two_end = ''\n",
    "                            for word in words:\n",
    "                                \n",
    "                                if word == words[words.index('или') - 1]:\n",
    "                                    phrase_one_end = word\n",
    "                                    \n",
    "                                elif word == words[words.index('или') + 1]:\n",
    "                                    phrase_two_end = word\n",
    "                                \n",
    "                                else:\n",
    "                                    if word != words[words.index('или')]:\n",
    "                                        phrase_start += word + ' '\n",
    "                                    \n",
    "                                idx += 1\n",
    "                            \n",
    "                            phrase_ru_text = phrase_start + phrase_one_end\n",
    "                            extracted_phrases_dict[phrase_start + phrase_two_end] = phrase_ru_tag.findNext('a').get_text()\n",
    "                    \n",
    "                    phrase_en_tag = phrase_ru_tag.findNext('a')\n",
    "                    phrase_en_text = phrase_en_tag.get_text()\n",
    "                    \n",
    "                    next_en_tag = phrase_en_tag.findNext()\n",
    "                    \n",
    "                    if next_en_tag.has_attr('class'):\n",
    "                        if next_en_tag.get(\"class\")[0] == 'ital' and next_en_tag.get_text() == 'или':\n",
    "                            phrase_en_text += ' или'\n",
    "                            nn_en_tag = next_en_tag.findNext()\n",
    "                            if nn_en_tag.has_attr('href'):\n",
    "                                phrase_en_text += ' ' + nn_en_tag.get_text()\n",
    "\n",
    "                    \n",
    "                    extracted_phrases_dict[phrase_ru_text] = phrase_en_text\n",
    "                    \n",
    "                return(extracted_phrases_dict)\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        print(response)\n",
    "        print('\\tError connecting to wordreference.com.\\nProgram stopped.')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordref_phrases_scrape('от')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "terms = []\n",
    "\n",
    "# import freq list\n",
    "with open('ru_corpus_freq_list.tsv', 'r') as file:\n",
    "    \n",
    "    output_file = open(proj_dir + '/ru_phrases_file10.txt', 'w+')\n",
    "    \n",
    "    row_count = 1\n",
    "    \n",
    "    start_now = False\n",
    "    \n",
    "    for index,row in rnc_freq_list.iterrows():\n",
    "            \n",
    "        term = row['words']\n",
    "        term = term.replace('\\n','')\n",
    "        \n",
    "        if term == 'рупор':\n",
    "            start_now = True\n",
    "\n",
    "        if start_now == True:\n",
    "            print(term.upper())\n",
    "\n",
    "            if wordref_phrases_scrape(word = term) != None:\n",
    "                phrases = wordref_phrases_scrape(word = term)\n",
    "                # clean up phrase: remove brackets, obj pronouns and accents\n",
    "\n",
    "                if phrases:\n",
    "                    for ru,eng in phrases.items():\n",
    "\n",
    "                        print(ru + ' ' + '£' + eng + '\\n')\n",
    "\n",
    "                        output_file.write(ru + ' ' + '£' + eng + '\\n')\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "        row_count += 1\n",
    "\n",
    "    output_file.close()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Scrape phrases from dic.academic.ru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def academic_ru_scrape(word):\n",
    "    \n",
    "    phrase_list = []\n",
    "    full_url = 'https://translate.academic.ru/{}/ru/en/'.format(word)\n",
    "    full_url = full_url.replace('\\n','')\n",
    "    response = requests.get(full_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        for div in soup.find_all('div'):\n",
    "            div_text = div.get_text()\n",
    "            if bool(re.search('[а-яА-Я]', div_text)) == True and len(div_text) <= 130:\n",
    "                phrase_list.append(div_text.replace('\\n', ' ').replace('\\t', ' '))\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "            \n",
    "    return phrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_file = open(proj_dir + '\\\\dic_academic_ru_phrases.txt', 'w+', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 и\n",
      "1 в\n",
      "2 не\n",
      "3 на\n",
      "4 я\n",
      "5 быть\n",
      "6 он\n",
      "7 с\n",
      "8 что\n",
      "9 а\n",
      "10 по\n",
      "11 это\n",
      "12 она\n",
      "13 этот\n",
      "14 к\n",
      "15 но\n",
      "16 они\n",
      "17 мы\n",
      "18 как\n",
      "19 из\n",
      "20 у\n",
      "21 который\n",
      "22 то\n",
      "23 за\n",
      "24 свой\n",
      "25 что\n",
      "26 весь\n",
      "27 год\n",
      "28 от\n",
      "29 так\n",
      "30 о\n",
      "31 для\n",
      "32 ты\n",
      "33 же\n",
      "34 все\n",
      "35 тот\n",
      "36 мочь\n",
      "37 вы\n",
      "38 человек\n",
      "39 такой\n",
      "40 его\n",
      "41 сказать\n",
      "42 только\n",
      "43 или\n",
      "44 еще\n",
      "45 бы\n",
      "46 себя\n",
      "47 один\n",
      "48 как\n",
      "49 уже\n",
      "50 до\n",
      "51 время\n",
      "52 если\n",
      "53 сам\n",
      "54 когда\n",
      "55 другой\n",
      "56 вот\n",
      "57 говорить\n",
      "58 наш\n",
      "59 мой\n",
      "60 знать\n",
      "61 стать\n",
      "62 при\n",
      "63 чтобы\n",
      "64 дело\n",
      "65 жизнь\n",
      "66 кто\n",
      "67 первый\n",
      "68 очень\n",
      "69 два\n",
      "70 день\n",
      "71 ее\n",
      "72 новый\n",
      "73 рука\n",
      "74 даже\n",
      "75 во\n",
      "76 со\n",
      "77 раз\n",
      "78 где\n",
      "79 там\n",
      "80 под\n",
      "81 можно\n",
      "82 ну\n",
      "83 какой\n",
      "84 после\n",
      "85 их\n",
      "86 работа\n",
      "87 без\n",
      "88 самый\n",
      "89 потом\n",
      "90 надо\n",
      "91 хотеть\n",
      "92 ли\n",
      "93 слово\n",
      "94 идти\n",
      "95 большой\n",
      "96 должен\n",
      "97 место\n",
      "98 иметь\n",
      "99 ничто\n",
      "100 то\n",
      "101 сейчас\n",
      "102 тут\n",
      "103 лицо\n",
      "104 каждый\n",
      "105 друг\n",
      "106 нет\n",
      "107 теперь\n",
      "108 ни\n",
      "109 глаз\n",
      "110 тоже\n",
      "111 тогда\n",
      "112 видеть\n",
      "113 вопрос\n",
      "114 через\n",
      "115 да\n",
      "116 здесь\n",
      "117 дом\n",
      "118 да\n",
      "119 потому\n",
      "120 сторона\n",
      "121 какой-то\n",
      "122 думать\n",
      "123 сделать\n",
      "124 страна\n",
      "125 жить\n",
      "126 чем\n",
      "127 мир\n",
      "128 об\n",
      "129 последний\n",
      "130 случай\n",
      "131 голова\n",
      "132 более\n",
      "133 делать\n",
      "134 что-то\n",
      "135 смотреть\n",
      "136 ребенок\n",
      "137 просто\n",
      "138 конечно\n",
      "139 сила\n",
      "140 российский\n",
      "141 конец\n",
      "142 перед\n",
      "143 несколько\n",
      "144 вид\n",
      "145 система\n",
      "146 всегда\n",
      "147 работать\n",
      "148 между\n",
      "149 три\n",
      "150 нет\n",
      "151 понять\n",
      "152 пойти\n",
      "153 часть\n",
      "154 спросить\n",
      "155 город\n",
      "156 дать\n",
      "157 также\n",
      "158 никто\n",
      "159 понимать\n",
      "160 получить\n",
      "161 отношение\n",
      "162 лишь\n",
      "163 второй\n",
      "164 именно\n",
      "165 ваш\n",
      "166 хотя\n",
      "167 ни\n",
      "168 сидеть\n",
      "169 над\n",
      "170 женщина\n",
      "171 оказаться\n",
      "172 русский\n",
      "173 один\n",
      "174 взять\n",
      "175 прийти\n",
      "176 являться\n",
      "177 деньги\n",
      "178 почему\n",
      "179 вдруг\n",
      "180 любить\n",
      "181 стоить\n",
      "182 почти\n",
      "183 земля\n",
      "184 общий\n",
      "185 ведь\n",
      "186 машина\n",
      "187 однако\n",
      "188 сразу\n",
      "189 хорошо\n",
      "190 вода\n",
      "191 отец\n",
      "192 высокий\n",
      "193 остаться\n",
      "194 выйти\n",
      "195 много\n",
      "196 проблема\n",
      "197 начать\n",
      "198 хороший\n",
      "199 час\n",
      "200 это\n",
      "201 сегодня\n",
      "202 право\n",
      "203 совсем\n",
      "204 нога\n",
      "205 считать\n",
      "206 главный\n",
      "207 решение\n",
      "208 увидеть\n",
      "209 дверь\n",
      "210 казаться\n",
      "211 образ\n",
      "212 писать\n",
      "213 история\n",
      "214 лучший\n",
      "215 власть\n",
      "216 закон\n",
      "217 все\n",
      "218 война\n",
      "219 бог\n",
      "220 голос\n",
      "221 найти\n",
      "222 поэтому\n",
      "223 стоять\n",
      "224 вообще\n",
      "225 тысяча\n",
      "226 больше\n",
      "227 вместе\n",
      "228 маленький\n",
      "229 книга\n",
      "230 некоторый\n",
      "231 решить\n",
      "232 любой\n",
      "233 возможность\n",
      "234 результат\n",
      "235 ночь\n",
      "236 стол\n",
      "237 никогда\n",
      "238 имя\n",
      "239 область\n",
      "240 молодой\n",
      "241 пройти\n",
      "242 например\n",
      "243 статья\n",
      "244 оно\n",
      "245 число\n",
      "246 компания\n",
      "247 про\n",
      "248 государственный\n",
      "249 полный\n",
      "250 принять\n",
      "251 народ\n",
      "252 никакой\n",
      "253 советский\n",
      "254 жена\n",
      "255 настоящий\n",
      "256 всякий\n",
      "257 группа\n",
      "258 развитие\n",
      "259 процесс\n",
      "260 суд\n",
      "261 давать\n",
      "262 ответить\n",
      "263 старый\n",
      "264 условие\n",
      "265 твой\n",
      "266 пока\n",
      "267 средство\n",
      "268 помнить\n",
      "269 начало\n",
      "270 ждать\n",
      "271 свет\n",
      "272 пора\n",
      "273 путь\n",
      "274 душа\n",
      "275 куда\n",
      "276 нужно\n",
      "277 разный\n",
      "278 нужный\n",
      "279 уровень\n",
      "280 иной\n",
      "281 форма\n",
      "282 связь\n",
      "283 уж\n",
      "284 минута\n",
      "285 кроме\n",
      "286 находиться\n",
      "287 опять\n",
      "288 многий\n",
      "289 белый\n",
      "290 собственный\n",
      "291 улица\n",
      "292 черный\n",
      "293 написать\n",
      "294 вечер\n",
      "295 снова\n",
      "296 основной\n",
      "297 качество\n",
      "298 мысль\n",
      "299 дорога\n",
      "300 мать\n",
      "301 действие\n",
      "302 месяц\n",
      "303 оставаться\n",
      "304 государство\n",
      "305 язык\n",
      "306 любовь\n",
      "307 взгляд\n",
      "308 мама\n",
      "309 играть\n",
      "310 далекий\n",
      "311 лежать\n",
      "312 нельзя\n",
      "313 век\n",
      "314 школа\n",
      "315 подумать\n",
      "316 уйти\n",
      "317 цель\n",
      "318 среди\n",
      "319 общество\n",
      "320 посмотреть\n",
      "321 деятельность\n",
      "322 организация\n",
      "323 кто-то\n",
      "324 вернуться\n",
      "325 президент\n",
      "326 комната\n",
      "327 порядок\n",
      "328 момент\n",
      "329 театр\n",
      "330 следовать\n",
      "331 читать\n",
      "332 письмо\n",
      "333 подобный\n",
      "334 следующий\n",
      "335 утро\n",
      "336 особенно\n",
      "337 помощь\n",
      "338 ситуация\n",
      "339 роль\n",
      "340 бывать\n",
      "341 ходить\n",
      "342 рубль\n",
      "343 начинать\n",
      "344 появиться\n",
      "345 смысл\n",
      "346 состояние\n",
      "347 называть\n",
      "348 рядом\n",
      "349 квартира\n",
      "350 назад\n",
      "351 равный\n",
      "352 из-за\n",
      "353 орган\n",
      "354 внимание\n",
      "355 тело\n",
      "356 труд\n",
      "357 прийтись\n",
      "358 хотеться\n",
      "359 сын\n",
      "360 мера\n",
      "361 пять\n",
      "362 смерть\n",
      "363 живой\n",
      "364 рынок\n",
      "365 программа\n",
      "366 задача\n",
      "367 предприятие\n",
      "368 известный\n",
      "369 окно\n",
      "370 вести\n",
      "371 совершенно\n",
      "372 военный\n",
      "373 разговор\n",
      "374 показать\n",
      "375 правительство\n",
      "376 важный\n",
      "377 семья\n",
      "378 великий\n",
      "379 производство\n",
      "380 простой\n",
      "381 значит\n",
      "382 третий\n",
      "383 сколько\n",
      "384 огромный\n",
      "385 давно\n",
      "386 политический\n",
      "387 информация\n",
      "388 действительно\n",
      "389 положение\n",
      "390 поставить\n",
      "391 бояться\n",
      "392 наконец\n",
      "393 центр\n",
      "394 происходить\n",
      "395 ответ\n",
      "396 муж\n",
      "397 автор\n",
      "398 все-таки\n",
      "399 стена\n",
      "400 существовать\n",
      "401 даже\n",
      "402 интерес\n",
      "403 становиться\n",
      "404 федерация\n",
      "405 правило\n",
      "406 оба\n",
      "407 часто\n",
      "408 московский\n",
      "409 управление\n",
      "410 слышать\n",
      "411 быстро\n",
      "412 смочь\n",
      "413 заметить\n",
      "414 как-то\n",
      "415 мужчина\n",
      "416 долго\n",
      "417 правда\n",
      "418 идея\n",
      "419 партия\n",
      "420 иногда\n",
      "421 использовать\n",
      "422 пытаться\n",
      "423 готовый\n",
      "424 чуть\n",
      "425 зачем\n",
      "426 представить\n",
      "427 чувствовать\n",
      "428 создать\n",
      "429 совет\n",
      "430 счет\n",
      "431 сердце\n",
      "432 движение\n",
      "433 вещь\n",
      "434 материал\n",
      "435 неделя\n",
      "436 чувство\n",
      "437 затем\n",
      "438 данный\n",
      "439 заниматься\n",
      "440 продолжать\n",
      "441 красный\n",
      "442 глава\n",
      "443 ко\n",
      "444 слушать\n",
      "445 наука\n",
      "446 узнать\n",
      "447 ряд\n",
      "448 газета\n",
      "449 причина\n",
      "450 против\n",
      "451 плечо\n",
      "452 современный\n",
      "453 цена\n",
      "454 план\n",
      "455 приехать\n",
      "456 речь\n",
      "457 четыре\n",
      "458 отвечать\n",
      "459 точка\n",
      "460 основа\n",
      "461 товарищ\n",
      "462 культура\n",
      "463 слишком\n",
      "464 рассказывать\n",
      "465 вполне\n",
      "466 далее\n",
      "467 рассказать\n",
      "468 данные\n",
      "469 представлять\n",
      "470 мнение\n",
      "471 социальный\n",
      "472 около\n",
      "473 документ\n",
      "474 институт\n",
      "475 ход\n",
      "476 брать\n",
      "477 забыть\n",
      "478 проект\n",
      "479 ранний\n",
      "480 встреча\n",
      "481 особый\n",
      "482 целый\n",
      "483 директор\n",
      "484 провести\n",
      "485 спать\n",
      "486 плохой\n",
      "487 может\n",
      "488 впрочем\n",
      "489 сильный\n",
      "490 наверное\n",
      "491 скорый\n",
      "492 ведь\n",
      "493 срок\n",
      "494 палец\n",
      "495 опыт\n",
      "496 помочь\n",
      "497 больше\n",
      "498 приходить\n",
      "499 служба\n",
      "500 крупный\n",
      "501 внутренний\n",
      "502 просить\n",
      "503 вспомнить\n",
      "504 открыть\n",
      "505 привести\n",
      "506 судьба\n",
      "507 пока\n",
      "508 девушка\n",
      "509 поскольку\n",
      "510 очередь\n",
      "511 лес\n",
      "512 пусть\n",
      "513 экономический\n",
      "514 оставить\n",
      "515 правый\n",
      "516 состав\n",
      "517 словно\n",
      "518 федеральный\n",
      "519 спрашивать\n",
      "520 принимать\n",
      "521 член\n",
      "522 искать\n",
      "523 близкий\n",
      "524 количество\n",
      "525 похожий\n",
      "526 событие\n",
      "527 объект\n",
      "528 зал\n",
      "529 создание\n",
      "530 войти\n",
      "531 различный\n",
      "532 значение\n",
      "533 назвать\n",
      "534 достаточно\n",
      "535 период\n",
      "536 хоть\n",
      "537 шаг\n",
      "538 необходимый\n",
      "539 успеть\n",
      "540 произойти\n",
      "541 брат\n",
      "542 искусство\n",
      "543 единственный\n",
      "544 легкий\n",
      "545 структура\n",
      "546 выходить\n",
      "547 номер\n",
      "548 предложить\n",
      "549 пример\n",
      "550 пить\n",
      "551 исследование\n",
      "552 гражданин\n",
      "553 глядеть\n",
      "554 человеческий\n",
      "555 игра\n",
      "556 начальник\n",
      "557 сей\n",
      "558 рост\n",
      "559 ехать\n",
      "560 международный\n",
      "561 тема\n",
      "562 принцип\n",
      "563 дорогой\n",
      "564 попасть\n",
      "565 десять\n",
      "566 начаться\n",
      "567 верить\n",
      "568 метод\n",
      "569 тип\n",
      "570 фильм\n",
      "571 небольшой\n",
      "572 держать\n",
      "573 либо\n",
      "574 позволять\n",
      "575 край\n",
      "576 местный\n",
      "577 менее\n",
      "578 гость\n",
      "579 купить\n",
      "580 уходить\n",
      "581 собираться\n",
      "582 воздух\n",
      "583 туда\n",
      "584 относиться\n",
      "585 бывший\n",
      "586 требовать\n",
      "587 характер\n",
      "588 борьба\n",
      "589 использование\n",
      "590 кстати\n",
      "591 подойти\n",
      "592 размер\n",
      "593 удаться\n",
      "594 образование\n",
      "595 получать\n",
      "596 мальчик\n",
      "597 кровь\n",
      "598 район\n",
      "599 небо\n",
      "600 американский\n",
      "601 армия\n",
      "602 класс\n",
      "603 представитель\n",
      "604 участие\n",
      "605 девочка\n",
      "606 политика\n",
      "607 сначала\n",
      "608 герой\n",
      "609 картина\n",
      "610 широкий\n",
      "611 доллар\n",
      "612 спина\n",
      "613 территория\n",
      "614 мировой\n",
      "615 пол\n",
      "616 тяжелый\n",
      "617 довольно\n",
      "618 поле\n",
      "619 ж\n",
      "620 изменение\n",
      "621 умереть\n",
      "622 более\n",
      "623 направление\n",
      "624 рисунок\n",
      "625 течение\n",
      "626 возможный\n",
      "627 церковь\n",
      "628 банк\n",
      "629 отдельный\n",
      "630 средний\n",
      "631 красивый\n",
      "632 сцена\n",
      "633 население\n",
      "634 большинство\n",
      "635 сесть\n",
      "636 двадцать\n",
      "637 случиться\n",
      "638 музыка\n",
      "639 короткий\n",
      "640 правда\n",
      "641 проходить\n",
      "642 составлять\n",
      "643 свобода\n",
      "644 память\n",
      "645 приходиться\n",
      "646 причем\n",
      "647 команда\n",
      "648 установить\n",
      "649 союз\n",
      "650 будто\n",
      "651 поднять\n",
      "652 врач\n",
      "653 серьезный\n",
      "654 договор\n",
      "655 стараться\n",
      "656 уметь\n",
      "657 встать\n",
      "658 дерево\n",
      "659 интересный\n",
      "660 факт\n",
      "661 добрый\n",
      "662 всего\n",
      "663 хозяин\n",
      "664 национальный\n",
      "665 однажды\n",
      "666 длинный\n",
      "667 природа\n",
      "668 домой\n",
      "669 страшный\n",
      "670 прошлый\n",
      "671 будто\n",
      "672 общественный\n",
      "673 угол\n",
      "674 чтоб\n",
      "675 телефон\n",
      "676 позиция\n",
      "677 проводить\n",
      "678 скоро\n",
      "679 наиболее\n",
      "680 двор\n",
      "681 обычно\n",
      "682 бросить\n",
      "683 разве\n",
      "684 писатель\n",
      "685 самолет\n",
      "686 объем\n",
      "687 далеко\n",
      "688 род\n",
      "689 солнце\n",
      "690 вера\n",
      "691 берег\n",
      "692 спектакль\n",
      "693 фирма\n",
      "694 способ\n",
      "695 завод\n",
      "696 цвет\n",
      "697 трудно\n",
      "698 журнал\n",
      "699 руководитель\n",
      "700 специалист\n",
      "701 возможно\n",
      "702 детский\n",
      "703 точно\n",
      "704 объяснить\n",
      "705 оценка\n",
      "706 единый\n",
      "707 снять\n",
      "708 определенный\n",
      "709 низкий\n",
      "710 нравиться\n",
      "711 услышать\n",
      "712 регион\n",
      "713 связать\n",
      "714 песня\n",
      "715 процент\n",
      "716 родитель\n",
      "717 позволить\n",
      "718 чужой\n",
      "719 море\n",
      "720 странный\n",
      "721 требование\n",
      "722 чистый\n",
      "723 весьма\n",
      "724 какой-нибудь\n",
      "725 основание\n",
      "726 половина\n",
      "727 поехать\n",
      "728 положить\n",
      "729 входить\n",
      "730 легко\n",
      "731 поздний\n",
      "732 роман\n",
      "733 круг\n",
      "734 анализ\n",
      "735 стихи\n",
      "736 автомобиль\n",
      "737 специальный\n",
      "738 экономика\n",
      "739 литература\n",
      "740 бумага\n",
      "741 вместо\n",
      "742 впервые\n",
      "743 видно\n",
      "744 научный\n",
      "745 оказываться\n",
      "746 поэт\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747 показывать\n",
      "748 степень\n",
      "749 вызвать\n",
      "750 касаться\n",
      "751 господин\n",
      "752 надежда\n",
      "753 сложный\n",
      "754 вокруг\n",
      "755 предмет\n",
      "756 отметить\n",
      "757 заявить\n",
      "758 вариант\n",
      "759 министр\n",
      "760 откуда\n",
      "761 реальный\n",
      "762 граница\n",
      "763 действовать\n",
      "764 дух\n",
      "765 модель\n",
      "766 операция\n",
      "767 пара\n",
      "768 сон\n",
      "769 немного\n",
      "770 название\n",
      "771 ум\n",
      "772 повод\n",
      "773 старик\n",
      "774 способный\n",
      "775 мало\n",
      "776 миллион\n",
      "777 малый\n",
      "778 старший\n",
      "779 успех\n",
      "780 практически\n",
      "781 получиться\n",
      "782 личный\n",
      "783 счастье\n",
      "784 необходимо\n",
      "785 свободный\n",
      "786 ребята\n",
      "787 обычный\n",
      "788 кабинет\n",
      "789 прекрасный\n",
      "790 высший\n",
      "791 кричать\n",
      "792 прежде\n",
      "793 магазин\n",
      "794 пространство\n",
      "795 выход\n",
      "796 остановиться\n",
      "797 удар\n",
      "798 база\n",
      "799 знание\n",
      "800 текст\n",
      "801 сюда\n",
      "802 темный\n",
      "803 защита\n",
      "804 предлагать\n",
      "805 руководство\n",
      "806 вовсе\n",
      "807 площадь\n",
      "808 сознание\n",
      "809 гражданский\n",
      "810 убить\n",
      "811 возраст\n",
      "812 молчать\n",
      "813 согласиться\n",
      "814 участник\n",
      "815 участок\n",
      "816 рано\n",
      "817 пункт\n",
      "818 несмотря\n",
      "819 сильно\n",
      "820 столь\n",
      "821 сообщить\n",
      "822 линия\n",
      "823 бежать\n",
      "824 желание\n",
      "825 папа\n",
      "826 кажется\n",
      "827 петь\n",
      "828 доктор\n",
      "829 губа\n",
      "830 известно\n",
      "831 дома\n",
      "832 вызывать\n",
      "833 дочь\n",
      "834 показаться\n",
      "835 среда\n",
      "836 председатель\n",
      "837 представление\n",
      "838 солдат\n",
      "839 художник\n",
      "840 принести\n",
      "841 волос\n",
      "842 оружие\n",
      "843 выглядеть\n",
      "844 соответствие\n",
      "845 никак\n",
      "846 ветер\n",
      "847 внешний\n",
      "848 парень\n",
      "849 служить\n",
      "850 зрение\n",
      "851 попросить\n",
      "852 генерал\n",
      "853 состоять\n",
      "854 огонь\n",
      "855 отдать\n",
      "856 боевой\n",
      "857 понятие\n",
      "858 строительство\n",
      "859 ухо\n",
      "860 выступать\n",
      "861 грудь\n",
      "862 нос\n",
      "863 ставить\n",
      "864 завтра\n",
      "865 возникать\n",
      "866 когда\n",
      "867 страх\n",
      "868 услуга\n",
      "869 рабочий\n",
      "870 что-нибудь\n",
      "871 глубокий\n",
      "872 содержание\n",
      "873 радость\n",
      "874 безопасность\n",
      "875 надеяться\n",
      "876 продукт\n",
      "877 видимо\n",
      "878 комплекс\n",
      "879 бизнес\n",
      "880 подняться\n",
      "881 вспоминать\n",
      "882 мало\n",
      "883 сад\n",
      "884 долгий\n",
      "885 одновременно\n",
      "886 называться\n",
      "887 сотрудник\n",
      "888 лето\n",
      "889 тихо\n",
      "890 зато\n",
      "891 прямой\n",
      "892 курс\n",
      "893 помогать\n",
      "894 предложение\n",
      "895 финансовый\n",
      "896 открытый\n",
      "897 почему-то\n",
      "898 значить\n",
      "899 возникнуть\n",
      "900 рот\n",
      "901 где-то\n",
      "902 технология\n",
      "903 знакомый\n",
      "904 недавно\n",
      "905 реформа\n",
      "906 отсутствие\n",
      "907 нынешний\n",
      "908 собака\n",
      "909 камень\n",
      "910 будущее\n",
      "911 звать\n",
      "912 рассказ\n",
      "913 контроль\n",
      "914 позвонить\n",
      "915 река\n",
      "916 хватать\n",
      "917 продукция\n",
      "918 сумма\n",
      "919 техника\n",
      "920 исторический\n",
      "921 вновь\n",
      "922 народный\n",
      "923 прямо\n",
      "924 ибо\n",
      "925 выпить\n",
      "926 здание\n",
      "927 сфера\n",
      "928 знаменитый\n",
      "929 иначе\n",
      "930 потерять\n",
      "931 необходимость\n",
      "932 больший\n",
      "933 фонд\n",
      "934 иметься\n",
      "935 вперед\n",
      "936 подготовка\n",
      "937 вчера\n",
      "938 лист\n",
      "939 пустой\n",
      "940 очередной\n",
      "941 республика\n",
      "942 хозяйство\n",
      "943 полностью\n",
      "944 получаться\n",
      "945 учиться\n",
      "946 плохо\n",
      "947 воля\n",
      "948 судебный\n",
      "949 бюджет\n",
      "950 возвращаться\n",
      "951 расти\n",
      "952 снег\n",
      "953 деревня\n",
      "954 обнаружить\n",
      "955 мужик\n",
      "956 постоянно\n",
      "957 зеленый\n",
      "958 элемент\n",
      "959 обстоятельство\n",
      "960 почувствовать\n",
      "961 немец\n",
      "962 многое\n",
      "963 победа\n",
      "964 источник\n",
      "965 немецкий\n",
      "966 золотой\n",
      "967 передать\n",
      "968 технический\n",
      "969 нормальный\n",
      "970 едва\n",
      "971 желать\n",
      "972 ожидать\n",
      "973 некий\n",
      "974 звезда\n",
      "975 городской\n",
      "976 выбор\n",
      "977 соответствующий\n",
      "978 масса\n",
      "979 составить\n",
      "980 итог\n",
      "981 сестра\n",
      "982 что\n",
      "983 шесть\n",
      "984 ясно\n",
      "985 практика\n",
      "986 сто\n",
      "987 нести\n",
      "988 определить\n",
      "989 проведение\n",
      "990 карман\n",
      "991 любимый\n",
      "992 родной\n",
      "993 западный\n",
      "994 обязательно\n",
      "995 слава\n",
      "996 кухня\n",
      "997 определение\n",
      "998 пользоваться\n",
      "999 быстрый\n",
      "1000 функция\n",
      "1001 войско\n",
      "1002 комиссия\n",
      "1003 применение\n",
      "1004 капитан\n",
      "1005 работник\n",
      "1006 улыбнуться\n",
      "1007 холодный\n",
      "1008 обеспечение\n",
      "1009 офицер\n",
      "1010 появляться\n",
      "1011 конкретный\n",
      "1012 фамилия\n",
      "1013 предел\n",
      "1014 прямо\n",
      "1015 смеяться\n",
      "1016 выборы\n",
      "1017 иностранный\n",
      "1018 уехать\n",
      "1019 ученый\n",
      "1020 вроде\n",
      "1021 левый\n",
      "1022 счастливый\n",
      "1023 бутылка\n",
      "1024 бой\n",
      "1025 подходить\n",
      "1026 судить\n",
      "1027 родиться\n",
      "1028 теория\n",
      "1029 зона\n",
      "1030 отдел\n",
      "1031 зуб\n",
      "1032 разработка\n",
      "1033 отказаться\n",
      "1034 святой\n",
      "1035 считаться\n",
      "1036 точный\n",
      "1037 занять\n",
      "1038 личность\n",
      "1039 гора\n",
      "1040 добавить\n",
      "1041 товар\n",
      "1042 звонить\n",
      "1043 медленно\n",
      "1044 носить\n",
      "1045 метр\n",
      "1046 начинаться\n",
      "1047 зависеть\n",
      "1048 праздник\n",
      "1049 влияние\n",
      "1050 построить\n",
      "1051 читатель\n",
      "1052 частый\n",
      "1053 удовольствие\n",
      "1054 актер\n",
      "1055 слеза\n",
      "1056 создавать\n",
      "1057 значительный\n",
      "1058 ответственность\n",
      "1059 учитель\n",
      "1060 акт\n",
      "1061 встретить\n",
      "1062 принадлежать\n",
      "1063 произнести\n",
      "1064 боль\n",
      "1065 множество\n",
      "1066 связанный\n",
      "1067 особенность\n",
      "1068 участвовать\n",
      "1069 показатель\n",
      "1070 занимать\n",
      "1071 корабль\n",
      "1072 уверенный\n",
      "1073 звук\n",
      "1074 тонкий\n",
      "1075 центральный\n",
      "1076 впечатление\n",
      "1077 спокойно\n",
      "1078 частность\n",
      "1079 детство\n",
      "1080 вывод\n",
      "1081 профессор\n",
      "1082 будущий\n",
      "1083 доля\n",
      "1084 норма\n",
      "1085 улыбаться\n",
      "1086 прошлое\n",
      "1087 возле\n",
      "1088 командир\n",
      "1089 коридор\n",
      "1090 поддержка\n",
      "1091 рамка\n",
      "1092 вскоре\n",
      "1093 лучше\n",
      "1094 сквозь\n",
      "1095 враг\n",
      "1096 ладно\n",
      "1097 этап\n",
      "1098 черт\n",
      "1099 дед\n",
      "1100 направить\n",
      "1101 собрание\n",
      "1102 прием\n",
      "1103 физический\n",
      "1104 болезнь\n",
      "1105 клетка\n",
      "1106 кожа\n",
      "1107 заявление\n",
      "1108 ради\n",
      "1109 попытка\n",
      "1110 сравнение\n",
      "1111 только\n",
      "1112 расчет\n",
      "1113 когда-то\n",
      "1114 депутат\n",
      "1115 то\n",
      "1116 частный\n",
      "1117 обратиться\n",
      "1118 мелкий\n",
      "1119 невозможно\n",
      "1120 английский\n",
      "1121 постоянный\n",
      "1122 комитет\n",
      "1123 знак\n",
      "1124 выбрать\n",
      "1125 примерно\n",
      "1126 бить\n",
      "1127 дядя\n",
      "1128 учет\n",
      "1129 хлеб\n",
      "1130 тихий\n",
      "1131 хватить\n",
      "1132 обещать\n",
      "1133 ли\n",
      "1134 встречаться\n",
      "1135 чай\n",
      "1136 режим\n",
      "1137 целое\n",
      "1138 вирус\n",
      "1139 гораздо\n",
      "1140 тридцать\n",
      "1141 выражение\n",
      "1142 напоминать\n",
      "1143 уж\n",
      "1144 неожиданно\n",
      "1145 здоровье\n",
      "1146 зима\n",
      "1147 упасть\n",
      "1148 перестать\n",
      "1149 десяток\n",
      "1150 глубина\n",
      "1151 сеть\n",
      "1152 студент\n",
      "1153 обладать\n",
      "1154 секунда\n",
      "1155 скорость\n",
      "1156 поиск\n",
      "1157 европейский\n",
      "1158 суть\n",
      "1159 налог\n",
      "1160 ошибка\n",
      "1161 ближайший\n",
      "1162 отечественный\n",
      "1163 теплый\n",
      "1164 плакать\n",
      "1165 духовный\n",
      "1166 доход\n",
      "1167 прежний\n",
      "1168 режиссер\n",
      "1169 поверхность\n",
      "1170 ощущение\n",
      "1171 состояться\n",
      "1172 карта\n",
      "1173 клуб\n",
      "1174 семь\n",
      "1175 станция\n",
      "1176 революция\n",
      "1177 колено\n",
      "1178 министерство\n",
      "1179 стекло\n",
      "1180 этаж\n",
      "1181 остальной\n",
      "1182 высота\n",
      "1183 наоборот\n",
      "1184 бабушка\n",
      "1185 двое\n",
      "1186 поверить\n",
      "1187 трубка\n",
      "1188 собрать\n",
      "1189 профессиональный\n",
      "1190 французский\n",
      "1191 женский\n",
      "1192 крайний\n",
      "1193 простить\n",
      "1194 газ\n",
      "1195 естественно\n",
      "1196 мастер\n",
      "1197 вниз\n",
      "1198 главное\n",
      "1199 поведение\n",
      "1200 рассматривать\n",
      "1201 перейти\n",
      "1202 мешать\n",
      "1203 давай\n",
      "1204 столица\n",
      "1205 механизм\n",
      "1206 передача\n",
      "1207 божий\n",
      "1208 исчезнуть\n",
      "1209 способность\n",
      "1210 подход\n",
      "1211 разумеется\n",
      "1212 столько\n",
      "1213 энергия\n",
      "1214 дальнейший\n",
      "1215 существование\n",
      "1216 исполнение\n",
      "1217 сорок\n",
      "1218 кино\n",
      "1219 сожаление\n",
      "1220 заместитель\n",
      "1221 мол\n",
      "1222 объявить\n",
      "1223 отличаться\n",
      "1224 естественный\n",
      "1225 ресурс\n",
      "1226 обращаться\n",
      "1227 акция\n",
      "1228 информационный\n",
      "1229 рождение\n",
      "1230 снимать\n",
      "1231 явно\n",
      "1232 администрация\n",
      "1233 железный\n",
      "1234 пригласить\n",
      "1235 соответствовать\n",
      "1236 стоимость\n",
      "1237 улыбка\n",
      "1238 артист\n",
      "1239 горячий\n",
      "1240 закрыть\n",
      "1241 придумать\n",
      "1242 пожалуйста\n",
      "1243 попробовать\n",
      "1244 приводить\n",
      "1245 сосед\n",
      "1246 фраза\n",
      "1247 веселый\n",
      "1248 фигура\n",
      "1249 достигнуть\n",
      "1250 субъект\n",
      "1251 утверждать\n",
      "1252 реакция\n",
      "1253 список\n",
      "1254 фотография\n",
      "1255 журналист\n",
      "1256 май\n",
      "1257 означать\n",
      "1258 платить\n",
      "1259 нарушение\n",
      "1260 заседание\n",
      "1261 толпа\n",
      "1262 больница\n",
      "1263 существо\n",
      "1264 решать\n",
      "1265 интересно\n",
      "1266 официальный\n",
      "1267 свойство\n",
      "1268 долг\n",
      "1269 поколение\n",
      "1270 серый\n",
      "1271 животное\n",
      "1272 схема\n",
      "1273 усилие\n",
      "1274 отличие\n",
      "1275 опасный\n",
      "1276 определять\n",
      "1277 остров\n",
      "1278 наблюдать\n",
      "1279 противник\n",
      "1280 волна\n",
      "1281 погибнуть\n",
      "1282 разговаривать\n",
      "1283 прочий\n",
      "1284 реализация\n",
      "1285 страница\n",
      "1286 формирование\n",
      "1287 житель\n",
      "1288 устроить\n",
      "1289 есть\n",
      "1290 красота\n",
      "1291 правильно\n",
      "1292 благодаря\n",
      "1293 птица\n",
      "1294 собраться\n",
      "1295 достать\n",
      "1296 растение\n",
      "1297 тень\n",
      "1298 явление\n",
      "1299 храм\n",
      "1300 запах\n",
      "1301 слабый\n",
      "1302 водка\n",
      "1303 наличие\n",
      "1304 пожалуй\n",
      "1305 яркий\n",
      "1306 ужас\n",
      "1307 одежда\n",
      "1308 ездить\n",
      "1309 кресло\n",
      "1310 больной\n",
      "1311 поезд\n",
      "1312 университет\n",
      "1313 летний\n",
      "1314 дополнительный\n",
      "1315 понравиться\n",
      "1316 традиция\n",
      "1317 адрес\n",
      "1318 декабрь\n",
      "1319 ладонь\n",
      "1320 поздно\n",
      "1321 сведение\n",
      "1322 правильный\n",
      "1323 цветок\n",
      "1324 выполнять\n",
      "1325 лесной\n",
      "1326 лидер\n",
      "1327 октябрь\n",
      "1328 занятие\n",
      "1329 заставить\n",
      "1330 объяснять\n",
      "1331 сентябрь\n",
      "1332 помещение\n",
      "1333 прочее\n",
      "1334 согласно\n",
      "1335 январь\n",
      "1336 выполнить\n",
      "1337 зритель\n",
      "1338 постепенно\n",
      "1339 резко\n",
      "1340 редакция\n",
      "1341 указать\n",
      "1342 умный\n",
      "1343 стиль\n",
      "1344 весна\n",
      "1345 северный\n",
      "1346 фактор\n",
      "1347 август\n",
      "1348 известие\n",
      "1349 зависимость\n",
      "1350 охрана\n",
      "1351 ясный\n",
      "1352 милый\n",
      "1353 оборудование\n",
      "1354 светлый\n",
      "1355 концерт\n",
      "1356 отделение\n",
      "1357 расход\n",
      "1358 редкий\n",
      "1359 выставка\n",
      "1360 милиция\n",
      "1361 верный\n",
      "1362 вздохнуть\n",
      "1363 юридический\n",
      "1364 находить\n",
      "1365 переход\n",
      "1366 закончить\n",
      "1367 эпоха\n",
      "1368 запад\n",
      "1369 признать\n",
      "1370 произведение\n",
      "1371 родина\n",
      "1372 собственность\n",
      "1373 тайна\n",
      "1374 хотя\n",
      "1375 четвертый\n",
      "1376 административный\n",
      "1377 трава\n",
      "1378 дойти\n",
      "1379 лагерь\n",
      "1380 во-первых\n",
      "1381 имущество\n",
      "1382 кивнуть\n",
      "1383 кровать\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1384 понятно\n",
      "1385 настолько\n",
      "1386 обратить\n",
      "1387 узкий\n",
      "1388 абсолютно\n",
      "1389 аппарат\n",
      "1390 несколько\n",
      "1391 очевидно\n",
      "1392 середина\n",
      "1393 узнавать\n",
      "1394 встретиться\n",
      "1395 март\n",
      "1396 художественный\n",
      "1397 клиент\n",
      "1398 лично\n",
      "1399 дама\n",
      "1400 обратно\n",
      "1401 предусмотреть\n",
      "1402 фронт\n",
      "1403 древний\n",
      "1404 отрасль\n",
      "1405 стул\n",
      "1406 беседа\n",
      "1407 массовый\n",
      "1408 обеспечивать\n",
      "1409 генеральный\n",
      "1410 замечательный\n",
      "1411 хоть\n",
      "1412 двигаться\n",
      "1413 законодательство\n",
      "1414 продажа\n",
      "1415 повышение\n",
      "1416 содержать\n",
      "1417 страшно\n",
      "1418 прежде\n",
      "1419 музей\n",
      "1420 задний\n",
      "1421 региональный\n",
      "1422 след\n",
      "1423 из-под\n",
      "1424 полковник\n",
      "1425 приезжать\n",
      "1426 сомнение\n",
      "1427 понимание\n",
      "1428 здоровый\n",
      "1429 держаться\n",
      "1430 обеспечить\n",
      "1431 слегка\n",
      "1432 апрель\n",
      "1433 князь\n",
      "1434 поступить\n",
      "1435 рыба\n",
      "1436 привыкнуть\n",
      "1437 активный\n",
      "1438 литературный\n",
      "1439 открывать\n",
      "1440 собственно\n",
      "1441 дума\n",
      "1442 еще\n",
      "1443 неужели\n",
      "1444 кодекс\n",
      "1445 сутки\n",
      "1446 чудо\n",
      "1447 вырасти\n",
      "1448 шея\n",
      "1449 зайти\n",
      "1450 судья\n",
      "1451 острый\n",
      "1452 посвятить\n",
      "1453 стремиться\n",
      "1454 богатый\n",
      "1455 крыша\n",
      "1456 настроение\n",
      "1457 отсюда\n",
      "1458 творческий\n",
      "1459 нечто\n",
      "1460 поток\n",
      "1461 мягкий\n",
      "1462 ночной\n",
      "1463 должность\n",
      "1464 преступление\n",
      "1465 измениться\n",
      "1466 мозг\n",
      "1467 налоговый\n",
      "1468 толстый\n",
      "1469 честь\n",
      "1470 пост\n",
      "1471 удивиться\n",
      "1472 падать\n",
      "1473 еврей\n",
      "1474 звучать\n",
      "1475 бедный\n",
      "1476 июнь\n",
      "1477 много\n",
      "1478 сотня\n",
      "1479 верхний\n",
      "1480 суметь\n",
      "1481 вечный\n",
      "1482 восемь\n",
      "1483 лишний\n",
      "1484 морской\n",
      "1485 разработать\n",
      "1486 нижний\n",
      "1487 спокойный\n",
      "1488 поговорить\n",
      "1489 дождь\n",
      "1490 меньше\n",
      "1491 лестница\n",
      "1492 сухой\n",
      "1493 ах\n",
      "1494 лететь\n",
      "1495 совершить\n",
      "1496 дача\n",
      "1497 синий\n",
      "1498 просто\n",
      "1499 установка\n",
      "1500 появление\n",
      "1501 получение\n",
      "1502 сегодняшний\n",
      "1503 строить\n",
      "1504 образец\n",
      "1505 труба\n",
      "1506 главное\n",
      "1507 кончиться\n",
      "1508 медицинский\n",
      "1509 привезти\n",
      "1510 многие\n",
      "1511 осень\n",
      "1512 вряд\n",
      "1513 сложиться\n",
      "1514 оставлять\n",
      "1515 полагать\n",
      "1516 висеть\n",
      "1517 костюм\n",
      "1518 свежий\n",
      "1519 трудный\n",
      "1520 уголовный\n",
      "1521 баба\n",
      "1522 ценность\n",
      "1523 обязанность\n",
      "1524 пьеса\n",
      "1525 чей\n",
      "1526 таблица\n",
      "1527 вино\n",
      "1528 воспоминание\n",
      "1529 лошадь\n",
      "1530 повторить\n",
      "1531 кто-нибудь\n",
      "1532 сыграть\n",
      "1533 коллега\n",
      "1534 организм\n",
      "1535 случайно\n",
      "1536 ученик\n",
      "1537 учреждение\n",
      "1538 высоко\n",
      "1539 открытие\n",
      "1540 спасти\n",
      "1541 том\n",
      "1542 черта\n",
      "1543 изменить\n",
      "1544 повторять\n",
      "1545 характеристика\n",
      "1546 по-прежнему\n",
      "1547 явиться\n",
      "1548 выполнение\n",
      "1549 оборона\n",
      "1550 выступление\n",
      "1551 температура\n",
      "1552 замечать\n",
      "1553 перспектива\n",
      "1554 подать\n",
      "1555 подруга\n",
      "1556 приказ\n",
      "1557 вверх\n",
      "1558 жертва\n",
      "1559 назначить\n",
      "1560 протянуть\n",
      "1561 ресторан\n",
      "1562 километр\n",
      "1563 сохранить\n",
      "1564 спор\n",
      "1565 попытаться\n",
      "1566 расположить\n",
      "1567 использоваться\n",
      "1568 вкус\n",
      "1569 насколько\n",
      "1570 признак\n",
      "1571 промышленность\n",
      "1572 странно\n",
      "1573 американец\n",
      "1574 лоб\n",
      "1575 заключение\n",
      "1576 вероятно\n",
      "1577 восток\n",
      "1578 вроде\n",
      "1579 исключение\n",
      "1580 отправиться\n",
      "1581 желтый\n",
      "1582 молча\n",
      "1583 ключ\n",
      "1584 постановление\n",
      "1585 садиться\n",
      "1586 же\n",
      "1587 немедленно\n",
      "1588 слой\n",
      "1589 бок\n",
      "1590 встречать\n",
      "1591 говориться\n",
      "1592 крикнуть\n",
      "1593 спустя\n",
      "1594 июль\n",
      "1595 мощный\n",
      "1596 перевод\n",
      "1597 секретарь\n",
      "1598 кусок\n",
      "1599 готовить\n",
      "1600 слух\n",
      "1601 учить\n",
      "1602 гореть\n",
      "1603 испытывать\n",
      "1604 польза\n",
      "1605 звонок\n",
      "1606 выделить\n",
      "1607 обстановка\n",
      "1608 оттуда\n",
      "1609 мимо\n",
      "1610 поддерживать\n",
      "1611 подниматься\n",
      "1612 чиновник\n",
      "1613 следить\n",
      "1614 соглашение\n",
      "1615 деталь\n",
      "1616 русский\n",
      "1617 деревянный\n",
      "1618 тишина\n",
      "1619 зарплата\n",
      "1620 требоваться\n",
      "1621 билет\n",
      "1622 включать\n",
      "1623 подарок\n",
      "1624 тюрьма\n",
      "1625 ящик\n",
      "1626 конкурс\n",
      "1627 полезный\n",
      "1628 книжка\n",
      "1629 собирать\n",
      "1630 изучение\n",
      "1631 дальний\n",
      "1632 менять\n",
      "1633 скажем\n",
      "1634 делаться\n",
      "1635 просьба\n",
      "1636 царь\n",
      "1637 публика\n",
      "1638 смех\n",
      "1639 покупать\n",
      "1640 сообщение\n",
      "1641 угроза\n",
      "1642 беда\n",
      "1643 домашний\n",
      "1644 должно\n",
      "1645 предполагать\n",
      "1646 традиционный\n",
      "1647 терять\n",
      "1648 специально\n",
      "1649 блок\n",
      "1650 достижение\n",
      "1651 назначение\n",
      "1652 реклама\n",
      "1653 жесткий\n",
      "1654 крепкий\n",
      "1655 портрет\n",
      "1656 послать\n",
      "1657 буквально\n",
      "1658 виноватый\n",
      "1659 допустить\n",
      "1660 значительно\n",
      "1661 масло\n",
      "1662 культурный\n",
      "1663 стакан\n",
      "1664 вокруг\n",
      "1665 приятный\n",
      "1666 прочитать\n",
      "1667 урок\n",
      "1668 присутствовать\n",
      "1669 часы\n",
      "1670 взглянуть\n",
      "1671 крик\n",
      "1672 мечтать\n",
      "1673 подписать\n",
      "1674 во-вторых\n",
      "1675 творчество\n",
      "1676 телевизор\n",
      "1677 осуществлять\n",
      "1678 инструмент\n",
      "1679 поступать\n",
      "1680 концепция\n",
      "1681 круглый\n",
      "1682 лейтенант\n",
      "1683 экран\n",
      "1684 дно\n",
      "1685 реальность\n",
      "1686 понятный\n",
      "1687 голубой\n",
      "1688 канал\n",
      "1689 удивительный\n",
      "1690 мясо\n",
      "1691 знакомый\n",
      "1692 щека\n",
      "1693 мужской\n",
      "1694 о\n",
      "1695 правовой\n",
      "1696 конфликт\n",
      "1697 переговоры\n",
      "1698 пятьдесят\n",
      "1699 больной\n",
      "1700 запись\n",
      "1701 пора\n",
      "1702 вагон\n",
      "1703 готовиться\n",
      "1704 мертвый\n",
      "1705 площадка\n",
      "1706 последствие\n",
      "1707 пятый\n",
      "1708 сотрудничество\n",
      "1709 б\n",
      "1710 зеркало\n",
      "1711 тон\n",
      "1712 захотеть\n",
      "1713 совместный\n",
      "1714 академия\n",
      "1715 бороться\n",
      "1716 отдавать\n",
      "1717 семейный\n",
      "1718 тяжело\n",
      "1719 остановить\n",
      "1720 палата\n",
      "1721 потребность\n",
      "1722 приобрести\n",
      "1723 включить\n",
      "1724 ноябрь\n",
      "1725 увеличение\n",
      "1726 продолжаться\n",
      "1727 дурак\n",
      "1728 осторожно\n",
      "1729 поездка\n",
      "1730 обед\n",
      "1731 подтвердить\n",
      "1732 потеря\n",
      "1733 природный\n",
      "1734 спешить\n",
      "1735 февраль\n",
      "1736 добиться\n",
      "1737 мероприятие\n",
      "1738 парк\n",
      "1739 принятие\n",
      "1740 устройство\n",
      "1741 вещество\n",
      "1742 впереди\n",
      "1743 навсегда\n",
      "1744 отправить\n",
      "1745 повернуться\n",
      "1746 категория\n",
      "1747 православный\n",
      "1748 сезон\n",
      "1749 учебный\n",
      "1750 вставать\n",
      "1751 подготовить\n",
      "1752 исходить\n",
      "1753 гостиница\n",
      "1754 издание\n",
      "1755 эффективный\n",
      "1756 нечего\n",
      "1757 свидетельствовать\n",
      "1758 ввести\n",
      "1759 взяться\n",
      "1760 объединение\n",
      "1761 прочесть\n",
      "1762 темнота\n",
      "1763 человечество\n",
      "1764 болеть\n",
      "1765 вернуть\n",
      "1766 тянуть\n",
      "1767 колесо\n",
      "1768 опасность\n",
      "1769 продать\n",
      "1770 разрешение\n",
      "1771 воздействие\n",
      "1772 коллектив\n",
      "1773 камера\n",
      "1774 внимательно\n",
      "1775 запас\n",
      "1776 представляться\n",
      "1777 следствие\n",
      "1778 длина\n",
      "1779 материальный\n",
      "1780 невозможный\n",
      "1781 крыло\n",
      "1782 округ\n",
      "1783 произвести\n",
      "1784 фон\n",
      "1785 кандидат\n",
      "1786 родственник\n",
      "1787 полтора\n",
      "1788 прекрасно\n",
      "1789 выступить\n",
      "1790 давление\n",
      "1791 пахнуть\n",
      "1792 познакомиться\n",
      "1793 присутствие\n",
      "1794 взаимодействие\n",
      "1795 громко\n",
      "1796 доска\n",
      "1797 наступить\n",
      "1798 партнер\n",
      "1799 двигатель\n",
      "1800 шум\n",
      "1801 достоинство\n",
      "1802 предстоять\n",
      "1803 вдоль\n",
      "1804 грех\n",
      "1805 господи\n",
      "1806 нож\n",
      "1807 полет\n",
      "1808 производить\n",
      "1809 ранее\n",
      "1810 страсть\n",
      "1811 перевести\n",
      "1812 разрешить\n",
      "1813 соседний\n",
      "1814 психологический\n",
      "1815 испытание\n",
      "1816 проверить\n",
      "1817 истина\n",
      "1818 меняться\n",
      "1819 оплата\n",
      "1820 разница\n",
      "1821 соответственно\n",
      "1822 водитель\n",
      "1823 музыкальный\n",
      "1824 куда-то\n",
      "1825 пакет\n",
      "1826 снижение\n",
      "1827 выдержать\n",
      "1828 формула\n",
      "1829 важно\n",
      "1830 живот\n",
      "1831 капитал\n",
      "1832 учитывать\n",
      "1833 курить\n",
      "1834 голый\n",
      "1835 забывать\n",
      "1836 заключаться\n",
      "1837 мост\n",
      "1838 обязательный\n",
      "1839 сверху\n",
      "1840 новость\n",
      "1841 эффект\n",
      "1842 вход\n",
      "1843 выбирать\n",
      "1844 губернатор\n",
      "1845 исполнительный\n",
      "1846 какой-либо\n",
      "1847 напомнить\n",
      "1848 партийный\n",
      "1849 доклад\n",
      "1850 закричать\n",
      "1851 организовать\n",
      "1852 смена\n",
      "1853 убийство\n",
      "1854 эксперт\n",
      "1855 вон\n",
      "1856 доказать\n",
      "1857 раз\n",
      "1858 редко\n",
      "1859 существенный\n",
      "1860 приносить\n",
      "1861 автобус\n",
      "1862 платье\n",
      "1863 осуществляться\n",
      "1864 честно\n",
      "1865 помимо\n",
      "1866 кадр\n",
      "1867 ой\n",
      "1868 тетя\n",
      "1869 восточный\n",
      "1870 дышать\n",
      "1871 общение\n",
      "1872 описать\n",
      "1873 психология\n",
      "1874 лев\n",
      "1875 таков\n",
      "1876 порог\n",
      "1877 проверка\n",
      "1878 прожить\n",
      "1879 процедура\n",
      "1880 рабочий\n",
      "1881 ремонт\n",
      "1882 сельский\n",
      "1883 характерный\n",
      "1884 обращение\n",
      "1885 обучение\n",
      "1886 неожиданный\n",
      "1887 ожидание\n",
      "1888 оценить\n",
      "1889 широко\n",
      "1890 рассмотреть\n",
      "1891 памятник\n",
      "1892 корень\n",
      "1893 наблюдение\n",
      "1894 проводиться\n",
      "1895 буква\n",
      "1896 видный\n",
      "1897 доказательство\n",
      "1898 лечь\n",
      "1899 превратиться\n",
      "1900 признание\n",
      "1901 внутри\n",
      "1902 выпустить\n",
      "1903 постель\n",
      "1904 честный\n",
      "1905 штаб\n",
      "1906 ударить\n",
      "1907 владелец\n",
      "1908 компьютер\n",
      "1909 окончательно\n",
      "1910 резкий\n",
      "1911 инженер\n",
      "1912 младший\n",
      "1913 проснуться\n",
      "1914 заранее\n",
      "1915 итак\n",
      "1916 открыться\n",
      "1917 старуха\n",
      "1918 лодка\n",
      "1919 ракета\n",
      "1920 трудовой\n",
      "1921 серия\n",
      "1922 строгий\n",
      "1923 шутка\n",
      "1924 вершина\n",
      "1925 строго\n",
      "1926 выпуск\n",
      "1927 кулак\n",
      "1928 лед\n",
      "1929 способствовать\n",
      "1930 торговля\n",
      "1931 южный\n",
      "1932 практический\n",
      "1933 многочисленный\n",
      "1934 нефть\n",
      "1935 согласный\n",
      "1936 молодежь\n",
      "1937 цифра\n",
      "1938 корпус\n",
      "1939 научиться\n",
      "1940 недостаток\n",
      "1941 наверно\n",
      "1942 сапог\n",
      "1943 спортивный\n",
      "1944 сущность\n",
      "1945 талант\n",
      "1946 умирать\n",
      "1947 истинный\n",
      "1948 эффективность\n",
      "1949 похоже\n",
      "1950 стрелять\n",
      "1951 кофе\n",
      "1952 обойтись\n",
      "1953 полоса\n",
      "1954 серьезно\n",
      "1955 записать\n",
      "1956 злой\n",
      "1957 обо\n",
      "1958 определяться\n",
      "1959 основное\n",
      "1960 трое\n",
      "1961 индивидуальный\n",
      "1962 подарить\n",
      "1963 рассмотрение\n",
      "1964 давайте\n",
      "1965 мокрый\n",
      "1966 приняться\n",
      "1967 сбор\n",
      "1968 штат\n",
      "1969 дикий\n",
      "1970 следователь\n",
      "1971 жилье\n",
      "1972 мешок\n",
      "1973 заставлять\n",
      "1974 описание\n",
      "1975 рад\n",
      "1976 куст\n",
      "1977 отказ\n",
      "1978 схватить\n",
      "1979 замок\n",
      "1980 пропасть\n",
      "1981 коммерческий\n",
      "1982 редактор\n",
      "1983 театральный\n",
      "1984 дворец\n",
      "1985 забота\n",
      "1986 выдать\n",
      "1987 пиво\n",
      "1988 воздушный\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989 дешевый\n",
      "1990 диван\n",
      "1991 извинить\n",
      "1992 разобраться\n",
      "1993 пьяный\n",
      "1994 столик\n",
      "1995 насчет\n",
      "1996 опустить\n",
      "1997 эксперимент\n",
      "1998 страдать\n",
      "1999 заходить\n",
      "2000 областной\n",
      "2001 печать\n",
      "2002 побежать\n",
      "2003 броситься\n",
      "2004 гулять\n",
      "2005 кольцо\n",
      "2006 твердый\n",
      "2007 вне\n",
      "2008 вооруженный\n",
      "2009 пистолет\n",
      "2010 религиозный\n",
      "2011 воспитание\n",
      "2012 начальство\n",
      "2013 промышленный\n",
      "2014 профессия\n",
      "2015 бегать\n",
      "2016 весело\n",
      "2017 ворота\n",
      "2018 добро\n",
      "2019 дружба\n",
      "2020 покой\n",
      "2021 пятнадцать\n",
      "2022 риск\n",
      "2023 засмеяться\n",
      "2024 окончание\n",
      "2025 денежный\n",
      "2026 дым\n",
      "2027 найтись\n",
      "2028 приказать\n",
      "2029 вслед\n",
      "2030 брак\n",
      "2031 величина\n",
      "2032 включая\n",
      "2033 записка\n",
      "2034 инициатива\n",
      "2035 совесть\n",
      "2036 устать\n",
      "2037 активность\n",
      "2038 кость\n",
      "2039 повезти\n",
      "2040 спорт\n",
      "2041 глубоко\n",
      "2042 китайский\n",
      "2043 последующий\n",
      "2044 грязный\n",
      "2045 земной\n",
      "2046 классический\n",
      "2047 кредит\n",
      "2048 особо\n",
      "2049 рассчитывать\n",
      "2050 господь\n",
      "2051 майор\n",
      "2052 опубликовать\n",
      "2053 конференция\n",
      "2054 неизвестный\n",
      "2055 потолок\n",
      "2056 радоваться\n",
      "2057 торговый\n",
      "2058 библиотека\n",
      "2059 выразить\n",
      "2060 закончиться\n",
      "2061 обернуться\n",
      "2062 помощник\n",
      "2063 конструкция\n",
      "2064 отдых\n",
      "2065 отпустить\n",
      "2066 ручка\n",
      "2067 заговорить\n",
      "2068 металл\n",
      "2069 внести\n",
      "2070 зря\n",
      "2071 молоко\n",
      "2072 прокурор\n",
      "2073 транспорт\n",
      "2074 устраивать\n",
      "2075 поэзия\n",
      "2076 соединение\n",
      "2077 выясниться\n",
      "2078 догадаться\n",
      "2079 краска\n",
      "2080 привычный\n",
      "2081 расстояние\n",
      "2082 глупый\n",
      "2083 изучать\n",
      "2084 интересовать\n",
      "2085 мечта\n",
      "2086 обратный\n",
      "2087 село\n",
      "2088 еда\n",
      "2089 поднимать\n",
      "2090 навстречу\n",
      "2091 развиваться\n",
      "2092 транспортный\n",
      "2093 зло\n",
      "2094 подразделение\n",
      "2095 достойный\n",
      "2096 обращать\n",
      "2097 подождать\n",
      "2098 сюжет\n",
      "2099 рубеж\n",
      "2100 сигнал\n",
      "2101 атмосфера\n",
      "2102 крест\n",
      "2103 удобный\n",
      "2104 вес\n",
      "2105 взрыв\n",
      "2106 контакт\n",
      "2107 продавать\n",
      "2108 сигарета\n",
      "2109 бросать\n",
      "2110 восторг\n",
      "2111 золото\n",
      "2112 конечный\n",
      "2113 крайне\n",
      "2114 поддержать\n",
      "2115 почва\n",
      "2116 премия\n",
      "2117 чисто\n",
      "2118 запретить\n",
      "2119 король\n",
      "2120 подъезд\n",
      "2121 шанс\n",
      "2122 автомат\n",
      "2123 заказ\n",
      "2124 мальчишка\n",
      "2125 отмечать\n",
      "2126 очки\n",
      "2127 производственный\n",
      "2128 миг\n",
      "2129 отойти\n",
      "2130 ощущать\n",
      "2131 штука\n",
      "2132 фактически\n",
      "2133 чтение\n",
      "2134 школьный\n",
      "2135 поселок\n",
      "2136 прибыть\n",
      "2137 свидетель\n",
      "2138 ставка\n",
      "2139 больно\n",
      "2140 ныне\n",
      "2141 передний\n",
      "2142 каменный\n",
      "2143 случаться\n",
      "2144 сумка\n",
      "2145 удивление\n",
      "2146 ценный\n",
      "2147 сойти\n",
      "2148 хвост\n",
      "2149 песок\n",
      "2150 поворот\n",
      "2151 предыдущий\n",
      "2152 возвращение\n",
      "2153 поймать\n",
      "2154 солнечный\n",
      "2155 жизненный\n",
      "2156 заключить\n",
      "2157 мгновение\n",
      "2158 признаться\n",
      "2159 статус\n",
      "2160 смешной\n",
      "2161 сомневаться\n",
      "2162 усмехнуться\n",
      "2163 напротив\n",
      "2164 несчастный\n",
      "2165 озеро\n",
      "2166 арбитражный\n",
      "2167 договориться\n",
      "2168 случайный\n",
      "2169 строй\n",
      "2170 наверняка\n",
      "2171 параметр\n",
      "2172 предоставить\n",
      "2173 сказка\n",
      "2174 тенденция\n",
      "2175 вина\n",
      "2176 дыхание\n",
      "2177 обязанный\n",
      "2178 версия\n",
      "2179 жалко\n",
      "2180 масштаб\n",
      "2181 горный\n",
      "2182 столько\n",
      "2183 удаваться\n",
      "2184 внезапно\n",
      "2185 монастырь\n",
      "2186 сходить\n",
      "2187 хозяйка\n",
      "2188 дочка\n",
      "2189 попадать\n",
      "2190 пустить\n",
      "2191 танец\n",
      "2192 увы\n",
      "2193 зарубежный\n",
      "2194 указывать\n",
      "2195 эксплуатация\n",
      "2196 коммунист\n",
      "2197 пенсия\n",
      "2198 приятель\n",
      "2199 юный\n",
      "2200 положительный\n",
      "2201 терпеть\n",
      "2202 девять\n",
      "2203 объяснение\n",
      "2204 сдать\n",
      "2205 набор\n",
      "2206 производитель\n",
      "2207 пыль\n",
      "2208 философия\n",
      "2209 вывести\n",
      "2210 выпускать\n",
      "2211 довольный\n",
      "2212 спасибо\n",
      "2213 мощность\n",
      "2214 никуда\n",
      "2215 обязательство\n",
      "2216 телефонный\n",
      "2217 уход\n",
      "2218 чего\n",
      "2219 горло\n",
      "2220 кризис\n",
      "2221 японский\n",
      "2222 вступить\n",
      "2223 спорить\n",
      "2224 указание\n",
      "2225 указанный\n",
      "2226 вытащить\n",
      "2227 деловой\n",
      "2228 плата\n",
      "2229 яблоко\n",
      "2230 победить\n",
      "2231 посадить\n",
      "2232 препарат\n",
      "2233 хорошо\n",
      "2234 действительность\n",
      "2235 москвич\n",
      "2236 обсуждать\n",
      "2237 остаток\n",
      "2238 заняться\n",
      "2239 изображение\n",
      "2240 минимальный\n",
      "2241 сделка\n",
      "2242 сочинение\n",
      "2243 активно\n",
      "2244 говорят\n",
      "2245 переходить\n",
      "2246 покупатель\n",
      "2247 танк\n",
      "2248 торопиться\n",
      "2249 затрата\n",
      "2250 строка\n",
      "2251 единица\n",
      "2252 обработка\n",
      "2253 чемпионат\n",
      "2254 электронный\n",
      "2255 выиграть\n",
      "2256 одинаковый\n",
      "2257 лаборатория\n",
      "2258 химический\n",
      "2259 милиционер\n",
      "2260 надеть\n",
      "2261 регистрация\n",
      "2262 жаль\n",
      "2263 изделие\n",
      "2264 кормить\n",
      "2265 молитва\n",
      "2266 там\n",
      "2267 погода\n",
      "2268 съезд\n",
      "2269 телевидение\n",
      "2270 введение\n",
      "2271 переживать\n",
      "2272 потребовать\n",
      "2273 временной\n",
      "2274 пресса\n",
      "2275 цепь\n",
      "2276 жалеть\n",
      "2277 корреспондент\n",
      "2278 планета\n",
      "2279 сохраниться\n",
      "2280 вынести\n",
      "2281 минимум\n",
      "2282 обсуждение\n",
      "2283 полк\n",
      "2284 еврейский\n",
      "2285 немало\n",
      "2286 отказываться\n",
      "2287 окружающий\n",
      "2288 опытный\n",
      "2289 вокзал\n",
      "2290 гибель\n",
      "2291 заглянуть\n",
      "2292 защищать\n",
      "2293 космический\n",
      "2294 основать\n",
      "2295 прокуратура\n",
      "2296 согласие\n",
      "2297 конь\n",
      "2298 лишить\n",
      "2299 меньший\n",
      "2300 могила\n",
      "2301 непосредственно\n",
      "2302 пожать\n",
      "2303 сколько\n",
      "2304 стенка\n",
      "2305 тайный\n",
      "2306 тревога\n",
      "2307 закрытый\n",
      "2308 напряжение\n",
      "2309 отличный\n",
      "2310 уезжать\n",
      "2311 логика\n",
      "2312 неизвестно\n",
      "2313 приятно\n",
      "2314 путем\n",
      "2315 распоряжение\n",
      "2316 воскликнуть\n",
      "2317 дрожать\n",
      "2318 задание\n",
      "2319 ведущий\n",
      "2320 кошка\n",
      "2321 распределение\n",
      "2322 верно\n",
      "2323 сообщать\n",
      "2324 крепко\n",
      "2325 сценарий\n",
      "2326 бригада\n",
      "2327 пятно\n",
      "2328 гроб\n",
      "2329 жениться\n",
      "2330 лезть\n",
      "2331 ограничение\n",
      "2332 верховный\n",
      "2333 волноваться\n",
      "2334 надпись\n",
      "2335 поразить\n",
      "2336 следовательно\n",
      "2337 термин\n",
      "2338 ткань\n",
      "2339 уникальный\n",
      "2340 велеть\n",
      "2341 визит\n",
      "2342 каков\n",
      "2343 океан\n",
      "2344 убивать\n",
      "2345 популярный\n",
      "2346 предприниматель\n",
      "2347 прибор\n",
      "2348 решиться\n",
      "2349 уважение\n",
      "2350 ведомство\n",
      "2351 добраться\n",
      "2352 другое\n",
      "2353 задуматься\n",
      "2354 паспорт\n",
      "2355 пауза\n",
      "2356 взрослый\n",
      "2357 дата\n",
      "2358 нуждаться\n",
      "2359 позвать\n",
      "2360 постановка\n",
      "2361 поступок\n",
      "2362 ствол\n",
      "2363 готовность\n",
      "2364 остальное\n",
      "2365 тепло\n",
      "2366 удивляться\n",
      "2367 адвокат\n",
      "2368 здравствовать\n",
      "2369 контракт\n",
      "2370 передавать\n",
      "2371 радио\n",
      "2372 розовый\n",
      "2373 скрывать\n",
      "2374 академик\n",
      "2375 запомнить\n",
      "2376 кампания\n",
      "2377 оборот\n",
      "2378 скромный\n",
      "2379 технологический\n",
      "2380 агентство\n",
      "2381 зверь\n",
      "2382 нация\n",
      "2383 потребитель\n",
      "2384 старинный\n",
      "2385 банка\n",
      "2386 коробка\n",
      "2387 осуществление\n",
      "2388 подавать\n",
      "2389 покинуть\n",
      "2390 послушать\n",
      "2391 секрет\n",
      "2392 темп\n",
      "2393 четко\n",
      "2394 метро\n",
      "2395 пережить\n",
      "2396 дедушка\n",
      "2397 инвестиция\n",
      "2398 непонятный\n",
      "2399 продолжить\n",
      "2400 раздаться\n",
      "2401 бесконечный\n",
      "2402 десятилетие\n",
      "2403 независимый\n",
      "2404 преимущество\n",
      "2405 публикация\n",
      "2406 стихотворение\n",
      "2407 везде\n",
      "2408 относительно\n",
      "2409 отчет\n",
      "2410 пальто\n",
      "2411 узел\n",
      "2412 нежный\n",
      "2413 обмен\n",
      "2414 порода\n",
      "2415 прибыль\n",
      "2416 решительно\n",
      "2417 тоска\n",
      "2418 заболевание\n",
      "2419 стремление\n",
      "2420 фестиваль\n",
      "2421 шкаф\n",
      "2422 горе\n",
      "2423 забор\n",
      "2424 оттого\n",
      "2425 вооружение\n",
      "2426 зимний\n",
      "2427 мебель\n",
      "2428 мороз\n",
      "2429 оказывать\n",
      "2430 превышать\n",
      "2431 талантливый\n",
      "2432 мирный\n",
      "2433 перемена\n",
      "2434 костер\n",
      "2435 ловить\n",
      "2436 марка\n",
      "2437 забрать\n",
      "2438 протокол\n",
      "2439 ужасный\n",
      "2440 испугаться\n",
      "2441 утвердить\n",
      "2442 впоследствии\n",
      "2443 квадратный\n",
      "2444 привычка\n",
      "2445 применять\n",
      "2446 трудность\n",
      "2447 убедиться\n",
      "2448 заменить\n",
      "2449 грязь\n",
      "2450 матч\n",
      "2451 незнакомый\n",
      "2452 плод\n",
      "2453 приглашать\n",
      "2454 спрос\n",
      "2455 строительный\n",
      "2456 крупнейший\n",
      "2457 пассажир\n",
      "2458 привлечь\n",
      "2459 стандарт\n",
      "2460 финансирование\n",
      "2461 мотор\n",
      "2462 стадия\n",
      "2463 густой\n",
      "2464 действующий\n",
      "2465 звание\n",
      "2466 надежный\n",
      "2467 утверждение\n",
      "2468 критерий\n",
      "2469 очевидный\n",
      "2470 пожилой\n",
      "2471 везти\n",
      "2472 север\n",
      "2473 убрать\n",
      "2474 борт\n",
      "2475 наказание\n",
      "2476 предположить\n",
      "2477 раздел\n",
      "2478 аналогичный\n",
      "2479 законный\n",
      "2480 конституция\n",
      "2481 сектор\n",
      "2482 склад\n",
      "2483 сохранение\n",
      "2484 таковой\n",
      "2485 учение\n",
      "2486 карандаш\n",
      "2487 летать\n",
      "2488 мотив\n",
      "2489 муниципальный\n",
      "2490 распространение\n",
      "2491 арест\n",
      "2492 знакомство\n",
      "2493 максимальный\n",
      "2494 неприятный\n",
      "2495 успешно\n",
      "2496 мэр\n",
      "2497 остальные\n",
      "2498 признавать\n",
      "2499 символ\n",
      "2500 повести\n",
      "2501 подчеркнуть\n",
      "2502 покрыть\n",
      "2503 полномочие\n",
      "2504 предпочитать\n",
      "2505 прислать\n",
      "2506 уверенность\n",
      "2507 безусловно\n",
      "2508 близко\n",
      "2509 отряд\n",
      "2510 жаловаться\n",
      "2511 разведка\n",
      "2512 решаться\n",
      "2513 успокоиться\n",
      "2514 исключить\n",
      "2515 лечение\n",
      "2516 мода\n",
      "2517 особенный\n",
      "2518 прозрачный\n",
      "2519 церковный\n",
      "2520 громкий\n",
      "2521 отсутствовать\n",
      "2522 поражение\n",
      "2523 рубашка\n",
      "2524 луна\n",
      "2525 нужда\n",
      "2526 привет\n",
      "2527 собор\n",
      "2528 съемка\n",
      "2529 владеть\n",
      "2530 груз\n",
      "2531 подробность\n",
      "2532 трагедия\n",
      "2533 самостоятельный\n",
      "2534 сзади\n",
      "2535 политик\n",
      "2536 торчать\n",
      "2537 луч\n",
      "2538 спасение\n",
      "2539 экзамен\n",
      "2540 внизу\n",
      "2541 добыча\n",
      "2542 проявление\n",
      "2543 пуля\n",
      "2544 жест\n",
      "2545 постараться\n",
      "2546 соединить\n",
      "2547 убедить\n",
      "2548 электрический\n",
      "2549 задавать\n",
      "2550 свидетельство\n",
      "2551 заложить\n",
      "2552 нервный\n",
      "2553 отлично\n",
      "2554 ассоциация\n",
      "2555 салон\n",
      "2556 заметный\n",
      "2557 корова\n",
      "2558 молчание\n",
      "2559 отпуск\n",
      "2560 питание\n",
      "2561 реализовать\n",
      "2562 девчонка\n",
      "2563 капля\n",
      "2564 важнейший\n",
      "2565 выяснить\n",
      "2566 стратегический\n",
      "2567 исполнять\n",
      "2568 общаться\n",
      "2569 одинокий\n",
      "2570 повернуть\n",
      "2571 бюджетный\n",
      "2572 останавливаться\n",
      "2573 дар\n",
      "2574 поставка\n",
      "2575 оркестр\n",
      "2576 совершать\n",
      "2577 воевать\n",
      "2578 выдавать\n",
      "2579 задать\n",
      "2580 ненавидеть\n",
      "2581 родить\n",
      "2582 интервью\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2583 критика\n",
      "2584 наступать\n",
      "2585 двенадцать\n",
      "2586 миллиард\n",
      "2587 ответственный\n",
      "2588 спасибо\n",
      "2589 выявить\n",
      "2590 пожар\n",
      "2591 предупредить\n",
      "2592 рыночный\n",
      "2593 набрать\n",
      "2594 предназначить\n",
      "2595 тщательно\n",
      "2596 холод\n",
      "2597 шар\n",
      "2598 компонент\n",
      "2599 статистика\n",
      "2600 тетка\n",
      "2601 уничтожить\n",
      "2602 учесть\n",
      "2603 цикл\n",
      "2604 чрезвычайно\n",
      "2605 освободить\n",
      "2606 отнюдь\n",
      "2607 стыдно\n",
      "2608 эпизод\n",
      "2609 якобы\n",
      "2610 взрослый\n",
      "2611 воспринимать\n",
      "2612 крутой\n",
      "2613 обида\n",
      "2614 обслуживание\n",
      "2615 потенциал\n",
      "2616 прекратить\n",
      "2617 противоположный\n",
      "2618 ненависть\n",
      "2619 нередко\n",
      "2620 персонаж\n",
      "2621 руль\n",
      "2622 совещание\n",
      "2623 увеличить\n",
      "2624 наблюдаться\n",
      "2625 непременно\n",
      "2626 объединить\n",
      "2627 подозревать\n",
      "2628 религия\n",
      "2629 рыжий\n",
      "2630 справиться\n",
      "2631 съесть\n",
      "2632 текущий\n",
      "2633 вестись\n",
      "2634 молодость\n",
      "2635 отнести\n",
      "2636 различие\n",
      "2637 упомянуть\n",
      "2638 ядерный\n",
      "2639 вклад\n",
      "2640 карьера\n",
      "2641 кладбище\n",
      "2642 облако\n",
      "2643 обыкновенный\n",
      "2644 гонка\n",
      "2645 отдыхать\n",
      "2646 отчего\n",
      "2647 проверять\n",
      "2648 рукав\n",
      "2649 сокращение\n",
      "2650 туман\n",
      "2651 шофер\n",
      "2652 бандит\n",
      "2653 врать\n",
      "2654 подлинный\n",
      "2655 чемодан\n",
      "2656 атака\n",
      "2657 вынужденный\n",
      "2658 заработать\n",
      "2659 превращаться\n",
      "2660 роза\n",
      "2661 указ\n",
      "2662 восстановление\n",
      "2663 грубый\n",
      "2664 сложность\n",
      "2665 создаваться\n",
      "2666 игрок\n",
      "2667 плыть\n",
      "2668 побывать\n",
      "2669 построение\n",
      "2670 продолжение\n",
      "2671 скандал\n",
      "2672 труп\n",
      "2673 кое-что\n",
      "2674 металлический\n",
      "2675 происхождение\n",
      "2676 путешествие\n",
      "2677 справедливость\n",
      "2678 тонна\n",
      "2679 абсолютный\n",
      "2680 гарантия\n",
      "2681 мгновенно\n",
      "2682 вождь\n",
      "2683 месторождение\n",
      "2684 мина\n",
      "2685 орден\n",
      "2686 пластинка\n",
      "2687 рассматриваться\n",
      "2688 уважать\n",
      "2689 выскочить\n",
      "2690 крестьянин\n",
      "2691 образоваться\n",
      "2692 проговорить\n",
      "2693 хранить\n",
      "2694 юноша\n",
      "2695 бабка\n",
      "2696 вызов\n",
      "2697 издательство\n",
      "2698 существенно\n",
      "2699 интеллектуальный\n",
      "2700 полка\n",
      "2701 статистический\n",
      "2702 шестой\n",
      "2703 дитя\n",
      "2704 необычный\n",
      "2705 обрадоваться\n",
      "2706 покупка\n",
      "2707 пропустить\n",
      "2708 ровно\n",
      "2709 танцевать\n",
      "2710 бровь\n",
      "2711 доверие\n",
      "2712 дождаться\n",
      "2713 избрать\n",
      "2714 колонна\n",
      "2715 недавний\n",
      "2716 падение\n",
      "2717 рекламный\n",
      "2718 стратегия\n",
      "2719 боец\n",
      "2720 завести\n",
      "2721 захватить\n",
      "2722 оглянуться\n",
      "2723 описывать\n",
      "2724 сунуть\n",
      "2725 интернет\n",
      "2726 исчезать\n",
      "2727 разделить\n",
      "2728 складываться\n",
      "2729 ведение\n",
      "2730 тарелка\n",
      "2731 удача\n",
      "2732 деятель\n",
      "2733 иначе\n",
      "2734 последовать\n",
      "2735 служебный\n",
      "2736 выстрел\n",
      "2737 отражать\n",
      "2738 полгода\n",
      "2739 куртка\n",
      "2740 письменный\n",
      "2741 приближаться\n",
      "2742 флот\n",
      "2743 бытие\n",
      "2744 вступать\n",
      "2745 единство\n",
      "2746 итальянский\n",
      "2747 надоесть\n",
      "2748 оператор\n",
      "2749 половой\n",
      "2750 физика\n",
      "2751 интересоваться\n",
      "2752 мышление\n",
      "2753 подлежать\n",
      "2754 приход\n",
      "2755 произносить\n",
      "2756 раскрыть\n",
      "2757 твердо\n",
      "2758 шеф\n",
      "2759 арестовать\n",
      "2760 глухой\n",
      "2761 одиночество\n",
      "2762 предварительный\n",
      "2763 целовать\n",
      "2764 чеченский\n",
      "2765 экологический\n",
      "2766 длительный\n",
      "2767 кой\n",
      "2768 орать\n",
      "2769 отвести\n",
      "2770 тянуться\n",
      "2771 шапка\n",
      "2772 достаться\n",
      "2773 ложка\n",
      "2774 подпись\n",
      "2775 полагаться\n",
      "2776 страховой\n",
      "2777 актриса\n",
      "2778 внутри\n",
      "2779 всеобщий\n",
      "2780 демократический\n",
      "2781 когда-нибудь\n",
      "2782 колхоз\n",
      "2783 куча\n",
      "2784 открываться\n",
      "2785 прогноз\n",
      "2786 сохранять\n",
      "2787 цивилизация\n",
      "2788 белок\n",
      "2789 вернее\n",
      "2790 воспользоваться\n",
      "2791 заметно\n",
      "2792 кот\n",
      "2793 остановка\n",
      "2794 платок\n",
      "2795 радостно\n",
      "2796 ага\n",
      "2797 локоть\n",
      "2798 махнуть\n",
      "2799 методика\n",
      "2800 мука\n",
      "2801 яйцо\n",
      "2802 голод\n",
      "2803 душевный\n",
      "2804 жалоба\n",
      "2805 концентрация\n",
      "2806 музыкант\n",
      "2807 нигде\n",
      "2808 охота\n",
      "2809 приобретать\n",
      "2810 сложить\n",
      "2811 вскочить\n",
      "2812 выражать\n",
      "2813 повесть\n",
      "2814 понадобиться\n",
      "2815 глупость\n",
      "2816 картошка\n",
      "2817 переулок\n",
      "2818 печальный\n",
      "2819 поглядеть\n",
      "2820 сделаться\n",
      "2821 домик\n",
      "2822 замуж\n",
      "2823 исполнитель\n",
      "2824 поинтересоваться\n",
      "2825 страдание\n",
      "2826 ветка\n",
      "2827 заказчик\n",
      "2828 лапа\n",
      "2829 пенсионный\n",
      "2830 признаваться\n",
      "2831 священник\n",
      "2832 восприятие\n",
      "2833 высказать\n",
      "2834 дважды\n",
      "2835 заведение\n",
      "2836 лекарство\n",
      "2837 мелочь\n",
      "2838 объективный\n",
      "2839 пища\n",
      "2840 свадьба\n",
      "2841 ложиться\n",
      "2842 подушка\n",
      "2843 проявить\n",
      "2844 справка\n",
      "2845 спуститься\n",
      "2846 теоретический\n",
      "2847 тьма\n",
      "2848 юг\n",
      "2849 башня\n",
      "2850 влиять\n",
      "2851 довести\n",
      "2852 нету\n",
      "2853 обвинение\n",
      "2854 соль\n",
      "2855 тариф\n",
      "2856 умение\n",
      "2857 содержаться\n",
      "2858 агент\n",
      "2859 гений\n",
      "2860 иск\n",
      "2861 лекция\n",
      "2862 моральный\n",
      "2863 нагрузка\n",
      "2864 намерение\n",
      "2865 подтверждать\n",
      "2866 хранение\n",
      "2867 ботинок\n",
      "2868 защитить\n",
      "2869 инвестиционный\n",
      "2870 исполнить\n",
      "2871 подвиг\n",
      "2872 воскресенье\n",
      "2873 чей-то\n",
      "2874 заплатить\n",
      "2875 земельный\n",
      "2876 молодец\n",
      "2877 управлять\n",
      "2878 авиация\n",
      "2879 дневник\n",
      "2880 летчик\n",
      "2881 невероятный\n",
      "2882 одеяло\n",
      "2883 спрятать\n",
      "2884 вертолет\n",
      "2885 вправе\n",
      "2886 законодательный\n",
      "2887 привлекать\n",
      "2888 приговор\n",
      "2889 протяжение\n",
      "2890 вечерний\n",
      "2891 внук\n",
      "2892 идеальный\n",
      "2893 исследовать\n",
      "2894 непосредственный\n",
      "2895 президентский\n",
      "2896 сочетание\n",
      "2897 столичный\n",
      "2898 хозяйственный\n",
      "2899 баня\n",
      "2900 демократия\n",
      "2901 нанести\n",
      "2902 приготовить\n",
      "2903 прыгать\n",
      "2904 вовремя\n",
      "2905 диалог\n",
      "2906 сладкий\n",
      "2907 водный\n",
      "2908 вынудить\n",
      "2909 гриб\n",
      "2910 пояснить\n",
      "2911 расширение\n",
      "2912 волнение\n",
      "2913 доступный\n",
      "2914 контролировать\n",
      "2915 полиция\n",
      "2916 применяться\n",
      "2917 руководить\n",
      "2918 строиться\n",
      "2919 богатство\n",
      "2920 измерение\n",
      "2921 отчаяние\n",
      "2922 пиджак\n",
      "2923 рассчитать\n",
      "2924 сахар\n",
      "2925 столетие\n",
      "2926 уважаемый\n",
      "2927 цирк\n",
      "2928 шутить\n",
      "2929 банковский\n",
      "2930 благо\n",
      "2931 молиться\n",
      "2932 пользование\n",
      "2933 точность\n",
      "2934 коллекция\n",
      "2935 манера\n",
      "2936 полчаса\n",
      "2937 сперва\n",
      "2938 цветной\n",
      "2939 цех\n",
      "2940 бумажка\n",
      "2941 восстановить\n",
      "2942 вынуть\n",
      "2943 жилой\n",
      "2944 подъем\n",
      "2945 свидание\n",
      "2946 смесь\n",
      "2947 страхование\n",
      "2948 империя\n",
      "2949 красавица\n",
      "2950 оперативный\n",
      "2951 отдельно\n",
      "2952 христианский\n",
      "2953 разнообразный\n",
      "2954 разум\n",
      "2955 тесный\n",
      "2956 блестящий\n",
      "2957 гордость\n",
      "2958 динамика\n",
      "2959 дон\n",
      "2960 жестокий\n",
      "2961 плотный\n",
      "2962 рисовать\n",
      "2963 четкий\n",
      "2964 ох\n",
      "2965 подробно\n",
      "2966 публичный\n",
      "2967 рекомендовать\n",
      "2968 седьмой\n",
      "2969 студия\n",
      "2970 двести\n",
      "2971 плита\n",
      "2972 пояс\n",
      "2973 приниматься\n",
      "2974 суббота\n",
      "2975 аэропорт\n",
      "2976 брюки\n",
      "2977 настаивать\n",
      "2978 рукопись\n",
      "2979 авторитет\n",
      "2980 граф\n",
      "2981 дорожка\n",
      "2982 исследователь\n",
      "2983 историк\n",
      "2984 исходный\n",
      "2985 кафе\n",
      "2986 по-видимому\n",
      "2987 придавать\n",
      "2988 социалистический\n",
      "2989 тренер\n",
      "2990 глянуть\n",
      "2991 доставить\n",
      "2992 замереть\n",
      "2993 мышь\n",
      "2994 оказать\n",
      "2995 окружение\n",
      "2996 замечание\n",
      "2997 замысел\n",
      "2998 модный\n",
      "2999 мышца\n",
      "3000 продавец\n",
      "3001 ровный\n",
      "3002 нравственный\n",
      "3003 планировать\n",
      "3004 своеобразный\n",
      "3005 соотношение\n",
      "3006 успешный\n",
      "3007 благородный\n",
      "3008 вечно\n",
      "3009 карточка\n",
      "3010 осуществить\n",
      "3011 отозваться\n",
      "3012 разбить\n",
      "3013 разойтись\n",
      "3014 священный\n",
      "3015 фабрика\n",
      "3016 явный\n",
      "3017 мимо\n",
      "3018 перенести\n",
      "3019 поначалу\n",
      "3020 посол\n",
      "3021 суровый\n",
      "3022 существующий\n",
      "3023 бледный\n",
      "3024 всерьез\n",
      "3025 испытать\n",
      "3026 катастрофа\n",
      "3027 пачка\n",
      "3028 столовая\n",
      "3029 ужин\n",
      "3030 установление\n",
      "3031 закрывать\n",
      "3032 окончить\n",
      "3033 оценивать\n",
      "3034 училище\n",
      "3035 шоссе\n",
      "3036 акционер\n",
      "3037 городок\n",
      "3038 картинка\n",
      "3039 легенда\n",
      "3040 ленинградский\n",
      "3041 соображение\n",
      "3042 сообщество\n",
      "3043 икона\n",
      "3044 коньяк\n",
      "3045 посетитель\n",
      "3046 собеседник\n",
      "3047 удивительно\n",
      "3048 волк\n",
      "3049 сопротивление\n",
      "3050 срочно\n",
      "3051 халат\n",
      "3052 вуз\n",
      "3053 жанр\n",
      "3054 идеал\n",
      "3055 ключевой\n",
      "3056 неплохо\n",
      "3057 поправка\n",
      "3058 юность\n",
      "3059 божественный\n",
      "3060 лента\n",
      "3061 нарушить\n",
      "3062 ощутить\n",
      "3063 частица\n",
      "3064 бомба\n",
      "3065 композитор\n",
      "3066 крыльцо\n",
      "3067 научить\n",
      "3068 пациент\n",
      "3069 сок\n",
      "3070 сопровождать\n",
      "3071 тяжесть\n",
      "3072 штамм\n",
      "3073 замена\n",
      "3074 искусственный\n",
      "3075 кусочек\n",
      "3076 намерен\n",
      "3077 однако\n",
      "3078 победитель\n",
      "3079 приезд\n",
      "3080 пробовать\n",
      "3081 стучать\n",
      "3082 сумасшедший\n",
      "3083 устойчивый\n",
      "3084 экспедиция\n",
      "3085 аспект\n",
      "3086 вчерашний\n",
      "3087 еле\n",
      "3088 интеллигенция\n",
      "3089 коммунистический\n",
      "3090 независимо\n",
      "3091 окончательный\n",
      "3092 противоречие\n",
      "3093 взаимный\n",
      "3094 военный\n",
      "3095 выставить\n",
      "3096 напечатать\n",
      "3097 преступник\n",
      "3098 прикрыть\n",
      "3099 пускать\n",
      "3100 развитой\n",
      "3101 сиять\n",
      "3102 строение\n",
      "3103 ущерб\n",
      "3104 делиться\n",
      "3105 идеология\n",
      "3106 подросток\n",
      "3107 правление\n",
      "3108 проживать\n",
      "3109 чемпион\n",
      "3110 архив\n",
      "3111 вслух\n",
      "3112 дискуссия\n",
      "3113 изобразить\n",
      "3114 изучить\n",
      "3115 мягко\n",
      "3116 немножко\n",
      "3117 освобождение\n",
      "3118 подвести\n",
      "3119 призвать\n",
      "3120 производиться\n",
      "3121 самостоятельно\n",
      "3122 сооружение\n",
      "3123 достигать\n",
      "3124 качественный\n",
      "3125 копейка\n",
      "3126 коротко\n",
      "3127 допускать\n",
      "3128 нерв\n",
      "3129 посылать\n",
      "3130 приличный\n",
      "3131 раствор\n",
      "3132 туалет\n",
      "3133 утратить\n",
      "3134 хор\n",
      "3135 анекдот\n",
      "3136 захотеться\n",
      "3137 класть\n",
      "3138 несомненно\n",
      "3139 слышно\n",
      "3140 сырье\n",
      "3141 царский\n",
      "3142 численность\n",
      "3143 штаны\n",
      "3144 возразить\n",
      "3145 грозить\n",
      "3146 железнодорожный\n",
      "3147 изо\n",
      "3148 искренне\n",
      "3149 пленка\n",
      "3150 подобрать\n",
      "3151 пребывание\n",
      "3152 репетиция\n",
      "3153 образовывать\n",
      "3154 отражение\n",
      "3155 предполагаться\n",
      "3156 проявлять\n",
      "3157 серебряный\n",
      "3158 удовлетворение\n",
      "3159 устанавливать\n",
      "3160 экипаж\n",
      "3161 актуальный\n",
      "3162 водить\n",
      "3163 награда\n",
      "3164 непонятно\n",
      "3165 поход\n",
      "3166 сплошной\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3167 выдающийся\n",
      "3168 помолчать\n",
      "3169 украинский\n",
      "3170 худой\n",
      "3171 газовый\n",
      "3172 иностранец\n",
      "3173 морда\n",
      "3174 перо\n",
      "3175 претензия\n",
      "3176 разумный\n",
      "3177 россиянин\n",
      "3178 должностной\n",
      "3179 постоять\n",
      "3180 проза\n",
      "3181 сдавать\n",
      "3182 справа\n",
      "3183 четверть\n",
      "3184 архитектура\n",
      "3185 демонстрировать\n",
      "3186 любопытство\n",
      "3187 маска\n",
      "3188 опера\n",
      "3189 посидеть\n",
      "3190 распространить\n",
      "3191 спускаться\n",
      "3192 благодарность\n",
      "3193 великолепный\n",
      "3194 госпиталь\n",
      "3195 догадываться\n",
      "3196 изображать\n",
      "3197 исключительно\n",
      "3198 маршрут\n",
      "3199 незаметно\n",
      "3200 сержант\n",
      "3201 точно\n",
      "3202 шляпа\n",
      "3203 экземпляр\n",
      "3204 белье\n",
      "3205 бродить\n",
      "3206 ведро\n",
      "3207 возникновение\n",
      "3208 мастерская\n",
      "3209 невидимый\n",
      "3210 нормативный\n",
      "3211 офис\n",
      "3212 положенный\n",
      "3213 по-настоящему\n",
      "3214 седой\n",
      "3215 слабость\n",
      "3216 ссылка\n",
      "3217 холодно\n",
      "3218 автомобильный\n",
      "3219 быт\n",
      "3220 лампа\n",
      "3221 опираться\n",
      "3222 посоветовать\n",
      "3223 разглядывать\n",
      "3224 толк\n",
      "3225 убийца\n",
      "3226 фантазия\n",
      "3227 вселенная\n",
      "3228 де\n",
      "3229 задержать\n",
      "3230 любитель\n",
      "3231 малыш\n",
      "3232 нарисовать\n",
      "3233 одеть\n",
      "3234 повышенный\n",
      "3235 призыв\n",
      "3236 располагаться\n",
      "3237 справедливый\n",
      "3238 беседовать\n",
      "3239 гигантский\n",
      "3240 заболеть\n",
      "3241 конституционный\n",
      "3242 облик\n",
      "3243 подземный\n",
      "3244 превратить\n",
      "3245 преподаватель\n",
      "3246 сайт\n",
      "3247 слева\n",
      "3248 горизонт\n",
      "3249 давний\n",
      "3250 дивизия\n",
      "3251 доверять\n",
      "3252 изба\n",
      "3253 копия\n",
      "3254 налить\n",
      "3255 небесный\n",
      "3256 отдохнуть\n",
      "3257 покачать\n",
      "3258 регулирование\n",
      "3259 течь\n",
      "3260 вплоть\n",
      "3261 гнать\n",
      "3262 натура\n",
      "3263 нефтяной\n",
      "3264 обусловить\n",
      "3265 голодный\n",
      "3266 доступ\n",
      "3267 законопроект\n",
      "3268 избирательный\n",
      "3269 компьютерный\n",
      "3270 подвал\n",
      "3271 порт\n",
      "3272 связывать\n",
      "3273 уголь\n",
      "3274 удивить\n",
      "3275 укрепление\n",
      "3276 устав\n",
      "3277 философский\n",
      "3278 бассейн\n",
      "3279 биться\n",
      "3280 двойной\n",
      "3281 здорово\n",
      "3282 инстанция\n",
      "3283 медведь\n",
      "3284 нынче\n",
      "3285 отъезд\n",
      "3286 процессуальный\n",
      "3287 тотчас\n",
      "3288 архитектор\n",
      "3289 браться\n",
      "3290 космос\n",
      "3291 меч\n",
      "3292 охранник\n",
      "3293 присесть\n",
      "3294 психический\n",
      "3295 судно\n",
      "3296 тратить\n",
      "3297 чашка\n",
      "3298 разрушить\n",
      "3299 волновать\n",
      "3300 воображение\n",
      "3301 квартал\n",
      "3302 курица\n",
      "3303 невольно\n",
      "3304 окружить\n",
      "3305 плавать\n",
      "3306 преобразование\n",
      "3307 развивать\n",
      "3308 спасать\n",
      "3309 топливо\n",
      "3310 элита\n",
      "3311 ветвь\n",
      "3312 видеться\n",
      "3313 возглавлять\n",
      "3314 глобальный\n",
      "3315 девица\n",
      "3316 инвестор\n",
      "3317 инструкция\n",
      "3318 кнопка\n",
      "3319 обязать\n",
      "3320 польский\n",
      "3321 потенциальный\n",
      "3322 почта\n",
      "3323 юмор\n",
      "3324 вначале\n",
      "3325 гордиться\n",
      "3326 доказывать\n",
      "3327 палка\n",
      "3328 проявляться\n",
      "3329 пустота\n",
      "3330 сообразить\n",
      "3331 фонарь\n",
      "3332 заказать\n",
      "3333 коллективный\n",
      "3334 наркотик\n",
      "3335 премьер\n",
      "3336 трогать\n",
      "3337 актив\n",
      "3338 завершить\n",
      "3339 пользователь\n",
      "3340 посреди\n",
      "3341 соревнование\n",
      "3342 столб\n",
      "3343 француз\n",
      "3344 холм\n",
      "3345 аккуратно\n",
      "3346 большевик\n",
      "3347 вдвоем\n",
      "3348 отменить\n",
      "3349 печь\n",
      "3350 попасться\n",
      "3351 поцеловать\n",
      "3352 пугать\n",
      "3353 сиденье\n",
      "3354 выплата\n",
      "3355 избежать\n",
      "3356 наибольший\n",
      "3357 отставка\n",
      "3358 перестройка\n",
      "3359 подхватить\n",
      "3360 потрясти\n",
      "3361 предоставлять\n",
      "3362 словом\n",
      "3363 советовать\n",
      "3364 сорт\n",
      "3365 стеклянный\n",
      "3366 трасса\n",
      "3367 ангел\n",
      "3368 атомный\n",
      "3369 выбросить\n",
      "3370 доложить\n",
      "3371 лифт\n",
      "3372 мрачный\n",
      "3373 объясняться\n",
      "3374 профессионал\n",
      "3375 рекомендация\n",
      "3376 скрыть\n",
      "3377 градус\n",
      "3378 запрос\n",
      "3379 кабина\n",
      "3380 обидеться\n",
      "3381 отказать\n",
      "3382 повесить\n",
      "3383 посетить\n",
      "3384 приобретение\n",
      "3385 разбираться\n",
      "3386 террорист\n",
      "3387 штраф\n",
      "3388 двинуться\n",
      "3389 достаточный\n",
      "3390 замолчать\n",
      "3391 медаль\n",
      "3392 окружать\n",
      "3393 отрицательный\n",
      "3394 последовательность\n",
      "3395 приглашение\n",
      "3396 пусть\n",
      "3397 уголок\n",
      "3398 успевать\n",
      "3399 фото\n",
      "3400 головной\n",
      "3401 обрести\n",
      "3402 перерыв\n",
      "3403 подчеркивать\n",
      "3404 разрыв\n",
      "3405 угодно\n",
      "3406 бытовой\n",
      "3407 горький\n",
      "3408 департамент\n",
      "3409 комментарий\n",
      "3410 орудие\n",
      "3411 отель\n",
      "3412 переводить\n",
      "3413 полезть\n",
      "3414 радостный\n",
      "3415 храниться\n",
      "3416 эмоция\n",
      "3417 аудитория\n",
      "3418 жидкость\n",
      "3419 коэффициент\n",
      "3420 мышка\n",
      "3421 ножка\n",
      "3422 оригинальный\n",
      "3423 революционный\n",
      "3424 спутник\n",
      "3425 типичный\n",
      "3426 трагический\n",
      "3427 утренний\n",
      "3428 веревка\n",
      "3429 взаимоотношения\n",
      "3430 вырваться\n",
      "3431 заинтересовать\n",
      "3432 издать\n",
      "3433 помешать\n",
      "3434 посольство\n",
      "3435 свободно\n",
      "3436 сексуальный\n",
      "3437 старушка\n",
      "3438 стать\n",
      "3439 ступень\n",
      "3440 ценить\n",
      "3441 борода\n",
      "3442 дисциплина\n",
      "3443 затылок\n",
      "3444 невеста\n",
      "3445 сравнить\n",
      "3446 факультет\n",
      "3447 группировка\n",
      "3448 дыра\n",
      "3449 император\n",
      "3450 свеча\n",
      "3451 таинственный\n",
      "3452 таможенный\n",
      "3453 тащить\n",
      "3454 вероятность\n",
      "3455 плюс\n",
      "3456 принципиальный\n",
      "3457 совпадать\n",
      "3458 благодарить\n",
      "3459 вот-вот\n",
      "3460 направиться\n",
      "3461 пообещать\n",
      "3462 развернуть\n",
      "3463 снизу\n",
      "3464 удачный\n",
      "3465 чудесный\n",
      "3466 блюдо\n",
      "3467 грань\n",
      "3468 критик\n",
      "3469 организатор\n",
      "3470 парламент\n",
      "3471 посадка\n",
      "3472 посуда\n",
      "3473 прозвучать\n",
      "3474 противный\n",
      "3475 себе\n",
      "3476 соглашаться\n",
      "3477 уверенно\n",
      "3478 царство\n",
      "3479 экспорт\n",
      "3480 боевик\n",
      "3481 вредный\n",
      "3482 доставать\n",
      "3483 зарегистрировать\n",
      "3484 книжный\n",
      "3485 начальный\n",
      "3486 неприятность\n",
      "3487 обмануть\n",
      "3488 обнять\n",
      "3489 оглядываться\n",
      "3490 опасаться\n",
      "3491 портфель\n",
      "3492 почетный\n",
      "3493 правительственный\n",
      "3494 сменить\n",
      "3495 воинский\n",
      "3496 дурной\n",
      "3497 кожаный\n",
      "3498 конкуренция\n",
      "3499 перспективный\n",
      "3500 рассуждать\n",
      "3501 сторонник\n",
      "3502 супруг\n",
      "3503 украсть\n",
      "3504 целиком\n",
      "3505 вообще-то\n",
      "3506 заявлять\n",
      "3507 ошибиться\n",
      "3508 персонал\n",
      "3509 повысить\n",
      "3510 показание\n",
      "3511 по-русски\n",
      "3512 поручить\n",
      "3513 послание\n",
      "3514 предоставление\n",
      "3515 профиль\n",
      "3516 учебник\n",
      "3517 ближний\n",
      "3518 выгодный\n",
      "3519 заполнить\n",
      "3520 игрушка\n",
      "3521 критический\n",
      "3522 крышка\n",
      "3523 наступление\n",
      "3524 опуститься\n",
      "3525 оформление\n",
      "3526 развести\n",
      "3527 экспериментальный\n",
      "3528 заплакать\n",
      "3529 заслужить\n",
      "3530 засыпать\n",
      "3531 наряду\n",
      "3532 недостаточно\n",
      "3533 понедельник\n",
      "3534 премьера\n",
      "3535 преодолеть\n",
      "3536 телеграмма\n",
      "3537 трудиться\n",
      "3538 эх\n",
      "3539 высказывание\n",
      "3540 конкурент\n",
      "3541 официально\n",
      "3542 пес\n",
      "3543 подряд\n",
      "3544 пожалеть\n",
      "3545 скала\n",
      "3546 торжественный\n",
      "3547 ложь\n",
      "3548 грузовик\n",
      "3549 грустный\n",
      "3550 комплексный\n",
      "3551 лечить\n",
      "3552 неплохой\n",
      "3553 перечень\n",
      "3554 ритм\n",
      "3555 такси\n",
      "3556 улучшение\n",
      "3557 философ\n",
      "3558 валяться\n",
      "3559 воин\n",
      "3560 жара\n",
      "3561 зарабатывать\n",
      "3562 олигарх\n",
      "3563 охватить\n",
      "3564 предусматривать\n",
      "3565 строчка\n",
      "3566 фрагмент\n",
      "3567 бюро\n",
      "3568 выражаться\n",
      "3569 доходить\n",
      "3570 жалкий\n",
      "3571 обидеть\n",
      "3572 обойти\n",
      "3573 посторонний\n",
      "3574 проспект\n",
      "3575 самоуправление\n",
      "3576 сборная\n",
      "3577 сломать\n",
      "3578 тогдашний\n",
      "3579 вытянуть\n",
      "3580 даваться\n",
      "3581 зерно\n",
      "3582 ледяной\n",
      "3583 отвернуться\n",
      "3584 платеж\n",
      "3585 потребление\n",
      "3586 прощать\n",
      "3587 рухнуть\n",
      "3588 свернуть\n",
      "3589 стесняться\n",
      "3590 возражать\n",
      "3591 вред\n",
      "3592 выделяться\n",
      "3593 кафедра\n",
      "3594 напиток\n",
      "3595 осветить\n",
      "3596 приступить\n",
      "3597 пробормотать\n",
      "3598 структурный\n",
      "3599 яма\n",
      "3600 англичанин\n",
      "3601 длиться\n",
      "3602 занятый\n",
      "3603 изложить\n",
      "3604 кругом\n",
      "3605 лицензия\n",
      "3606 обозначить\n",
      "3607 полюбить\n",
      "3608 пот\n",
      "3609 проиграть\n",
      "3610 пятница\n",
      "3611 распахнуть\n",
      "3612 рота\n",
      "3613 семейство\n",
      "3614 сосна\n",
      "3615 убеждение\n",
      "3616 форум\n",
      "3617 шампанское\n",
      "3618 могучий\n",
      "3619 оттенок\n",
      "3620 провожать\n",
      "3621 реагировать\n",
      "3622 рисковать\n",
      "3623 устроиться\n",
      "3624 громадный\n",
      "3625 подобно\n",
      "3626 пустыня\n",
      "3627 сборник\n",
      "3628 словно\n",
      "3629 сталинский\n",
      "3630 увеличиться\n",
      "3631 военнослужащий\n",
      "3632 кончить\n",
      "3633 надолго\n",
      "3634 объявление\n",
      "3635 поза\n",
      "3636 сельскохозяйственный\n",
      "3637 столкнуться\n",
      "3638 блеск\n",
      "3639 заснуть\n",
      "3640 папка\n",
      "3641 размышление\n",
      "3642 регулярно\n",
      "3643 свести\n",
      "3644 смешно\n",
      "3645 современник\n",
      "3646 авария\n",
      "3647 отправляться\n",
      "3648 прогулка\n",
      "3649 сбить\n",
      "3650 секс\n",
      "3651 славный\n",
      "3652 среднее\n",
      "3653 степь\n",
      "3654 бизнесмен\n",
      "3655 британский\n",
      "3656 дура\n",
      "3657 ковер\n",
      "3658 кончаться\n",
      "3659 кредитный\n",
      "3660 любопытный\n",
      "3661 нарушать\n",
      "3662 пламя\n",
      "3663 реально\n",
      "3664 старость\n",
      "3665 стрельба\n",
      "3666 верх\n",
      "3667 внедрение\n",
      "3668 вступление\n",
      "3669 выпасть\n",
      "3670 добиваться\n",
      "3671 накануне\n",
      "3672 оптимальный\n",
      "3673 предупреждать\n",
      "3674 прервать\n",
      "3675 районный\n",
      "3676 рана\n",
      "3677 стандартный\n",
      "3678 счесть\n",
      "3679 треть\n",
      "3680 ус\n",
      "3681 флаг\n",
      "3682 чистота\n",
      "3683 варить\n",
      "3684 крепость\n",
      "3685 некоторые\n",
      "3686 полететь\n",
      "3687 призывать\n",
      "3688 психолог\n",
      "3689 расположение\n",
      "3690 фаза\n",
      "3691 чуть-чуть\n",
      "3692 выбраться\n",
      "3693 выделять\n",
      "3694 намного\n",
      "3695 недалеко\n",
      "3696 немалый\n",
      "3697 охотно\n",
      "3698 расстрелять\n",
      "3699 совместно\n",
      "3700 асфальт\n",
      "3701 бессмысленный\n",
      "3702 валюта\n",
      "3703 натуральный\n",
      "3704 негативный\n",
      "3705 откровенно\n",
      "3706 палатка\n",
      "3707 перевозка\n",
      "3708 плоский\n",
      "3709 разглядеть\n",
      "3710 стойка\n",
      "3711 успокоить\n",
      "3712 холодильник\n",
      "3713 ветеран\n",
      "3714 вор\n",
      "3715 выделение\n",
      "3716 где-нибудь\n",
      "3717 кинуться\n",
      "3718 листок\n",
      "3719 переставать\n",
      "3720 предок\n",
      "3721 расследование\n",
      "3722 решетка\n",
      "3723 сибирский\n",
      "3724 скамейка\n",
      "3725 слабо\n",
      "3726 торжество\n",
      "3727 экспертиза\n",
      "3728 боковой\n",
      "3729 делегация\n",
      "3730 дорожный\n",
      "3731 миф\n",
      "3732 соблюдение\n",
      "3733 ступенька\n",
      "3734 турнир\n",
      "3735 формироваться\n",
      "3736 щель\n",
      "3737 гнев\n",
      "3738 заглядывать\n",
      "3739 задумываться\n",
      "3740 командовать\n",
      "3741 льгота\n",
      "3742 математический\n",
      "3743 менеджер\n",
      "3744 мыть\n",
      "3745 немного\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3746 отобрать\n",
      "3747 предположение\n",
      "3748 сложно\n",
      "3749 хохотать\n",
      "3750 батарея\n",
      "3751 идеологический\n",
      "3752 контекст\n",
      "3753 незаконный\n",
      "3754 познание\n",
      "3755 скрыться\n",
      "3756 авиационный\n",
      "3757 видать\n",
      "3758 выжить\n",
      "3759 выносить\n",
      "3760 железо\n",
      "3761 заодно\n",
      "3762 записывать\n",
      "3763 избиратель\n",
      "3764 некуда\n",
      "3765 перебить\n",
      "3766 программный\n",
      "3767 рейтинг\n",
      "3768 самарский\n",
      "3769 скважина\n",
      "3770 специальность\n",
      "3771 тронуть\n",
      "3772 аргумент\n",
      "3773 дверца\n",
      "3774 огонек\n",
      "3775 прогресс\n",
      "3776 строитель\n",
      "3777 угодно\n",
      "3778 шестьдесят\n",
      "3779 базовый\n",
      "3780 биологический\n",
      "3781 ген\n",
      "3782 гениальный\n",
      "3783 деревенский\n",
      "3784 загадочный\n",
      "3785 певец\n",
      "3786 прятаться\n",
      "3787 размышлять\n",
      "3788 ремень\n",
      "3789 соперник\n",
      "3790 соседка\n",
      "3791 грозный\n",
      "3792 завтрак\n",
      "3793 отчасти\n",
      "3794 подозрение\n",
      "3795 проклятый\n",
      "3796 располагать\n",
      "3797 ружье\n",
      "3798 следом\n",
      "3799 стремительно\n",
      "3800 балкон\n",
      "3801 волшебный\n",
      "3802 заслуга\n",
      "3803 зачастую\n",
      "3804 изготовление\n",
      "3805 контора\n",
      "3806 ломать\n",
      "3807 огород\n",
      "3808 подводный\n",
      "3809 приложение\n",
      "3810 рваться\n",
      "3811 речка\n",
      "3812 социализм\n",
      "3813 сырой\n",
      "3814 терроризм\n",
      "3815 уничтожение\n",
      "3816 эра\n",
      "3817 беспокоиться\n",
      "3818 заканчиваться\n",
      "3819 оформить\n",
      "3820 первичный\n",
      "3821 предстоящий\n",
      "3822 трамвай\n",
      "3823 финал\n",
      "3824 шептать\n",
      "3825 восьмой\n",
      "3826 галстук\n",
      "3827 колбаса\n",
      "3828 математика\n",
      "3829 миновать\n",
      "3830 независимость\n",
      "3831 нелепый\n",
      "3832 патриарх\n",
      "3833 разделять\n",
      "3834 реконструкция\n",
      "3835 сформулировать\n",
      "3836 набережная\n",
      "3837 наполнить\n",
      "3838 недовольный\n",
      "3839 недра\n",
      "3840 переживание\n",
      "3841 поздравлять\n",
      "3842 покидать\n",
      "3843 баланс\n",
      "3844 блестеть\n",
      "3845 вносить\n",
      "3846 девка\n",
      "3847 знамя\n",
      "3848 коснуться\n",
      "3849 медицина\n",
      "3850 осенний\n",
      "3851 отчетливо\n",
      "3852 потребоваться\n",
      "3853 пушкинский\n",
      "3854 ужасно\n",
      "3855 юбилей\n",
      "3856 вложить\n",
      "3857 греческий\n",
      "3858 задумчиво\n",
      "3859 кирпич\n",
      "3860 несчастье\n",
      "3861 плащ\n",
      "3862 понести\n",
      "3863 похороны\n",
      "3864 прошептать\n",
      "3865 рассмеяться\n",
      "3866 рюмка\n",
      "3867 совершенствование\n",
      "3868 солидный\n",
      "3869 творить\n",
      "3870 энергетический\n",
      "3871 ярко\n",
      "3872 всемирный\n",
      "3873 исход\n",
      "3874 контрольный\n",
      "3875 ликвидация\n",
      "3876 оболочка\n",
      "3877 общее\n",
      "3878 планироваться\n",
      "3879 поступление\n",
      "3880 поэтический\n",
      "3881 симпатичный\n",
      "3882 усталость\n",
      "3883 уступать\n",
      "3884 школьник\n",
      "3885 аренда\n",
      "3886 ежедневно\n",
      "3887 комбинат\n",
      "3888 малейший\n",
      "3889 местность\n",
      "3890 нападение\n",
      "3891 обсудить\n",
      "3892 оторвать\n",
      "3893 специфический\n",
      "3894 убежать\n",
      "3895 биография\n",
      "3896 бурный\n",
      "3897 добавлять\n",
      "3898 допрос\n",
      "3899 звено\n",
      "3900 лишение\n",
      "3901 модернизация\n",
      "3902 поделиться\n",
      "3903 потянуться\n",
      "3904 футбол\n",
      "3905 весенний\n",
      "3906 выслушать\n",
      "3907 грипп\n",
      "3908 коммунальный\n",
      "3909 набирать\n",
      "3910 отрезать\n",
      "3911 роскошный\n",
      "3912 территориальный\n",
      "3913 удобно\n",
      "3914 заботиться\n",
      "3915 запрет\n",
      "3916 командировка\n",
      "3917 неизбежный\n",
      "3918 общественность\n",
      "3919 почитать\n",
      "3920 протест\n",
      "3921 суп\n",
      "3922 авторский\n",
      "3923 вводить\n",
      "3924 каша\n",
      "3925 командование\n",
      "3926 муха\n",
      "3927 педагог\n",
      "3928 пожелать\n",
      "3929 посещать\n",
      "3930 потянуть\n",
      "3931 походить\n",
      "3932 прижать\n",
      "3933 прислушиваться\n",
      "3934 совершенный\n",
      "3935 торговать\n",
      "3936 видение\n",
      "3937 гарантировать\n",
      "3938 избавиться\n",
      "3939 интонация\n",
      "3940 напряженный\n",
      "3941 общежитие\n",
      "3942 печка\n",
      "3943 рассуждение\n",
      "3944 рождаться\n",
      "3945 семинар\n",
      "3946 собственник\n",
      "3947 спектр\n",
      "3948 турист\n",
      "3949 шепот\n",
      "3950 возрасти\n",
      "3951 молния\n",
      "3952 ограничить\n",
      "3953 охотник\n",
      "3954 пилот\n",
      "3955 плоть\n",
      "3956 предлагаться\n",
      "3957 предъявить\n",
      "3958 прятать\n",
      "3959 семя\n",
      "3960 завершение\n",
      "3961 композиция\n",
      "3962 краткий\n",
      "3963 крутить\n",
      "3964 нежели\n",
      "3965 нормально\n",
      "3966 праздничный\n",
      "3967 разобрать\n",
      "3968 ранить\n",
      "3969 самец\n",
      "3970 фракция\n",
      "3971 череп\n",
      "3972 дружить\n",
      "3973 неоднократно\n",
      "3974 подача\n",
      "3975 по-другому\n",
      "3976 подходящий\n",
      "3977 разрушение\n",
      "3978 расстаться\n",
      "3979 уставиться\n",
      "3980 бочка\n",
      "3981 гараж\n",
      "3982 закурить\n",
      "3983 коммунизм\n",
      "3984 неправильный\n",
      "3985 носитель\n",
      "3986 обсуждаться\n",
      "3987 поглядывать\n",
      "3988 подтверждение\n",
      "3989 совокупность\n",
      "3990 тренировка\n",
      "3991 алгоритм\n",
      "3992 глазок\n",
      "3993 дожидаться\n",
      "3994 кивать\n",
      "3995 корпорация\n",
      "3996 насилие\n",
      "3997 президиум\n",
      "3998 принадлежность\n",
      "3999 провод\n",
      "4000 сбросить\n",
      "4001 уснуть\n",
      "4002 близость\n",
      "4003 возрождение\n",
      "4004 заключенный\n",
      "4005 кружка\n",
      "4006 мяч\n",
      "4007 неведомый\n",
      "4008 референдум\n",
      "4009 сниться\n",
      "4010 сосуд\n",
      "4011 спальня\n",
      "4012 бесплатный\n",
      "4013 бормотать\n",
      "4014 диск\n",
      "4015 мудрый\n",
      "4016 переехать\n",
      "4017 послышаться\n",
      "4018 поэма\n",
      "4019 принципиально\n",
      "4020 противоречить\n",
      "4021 размещение\n",
      "4022 расширить\n",
      "4023 свойственный\n",
      "4024 силовой\n",
      "4025 склон\n",
      "4026 уточнить\n",
      "4027 юбка\n",
      "4028 акцент\n",
      "4029 ванная\n",
      "4030 вкусный\n",
      "4031 инвалид\n",
      "4032 лавка\n",
      "4033 механический\n",
      "4034 мучить\n",
      "4035 ограниченный\n",
      "4036 пар\n",
      "4037 платформа\n",
      "4038 сниматься\n",
      "4039 триста\n",
      "4040 уверять\n",
      "4041 финансы\n",
      "4042 цепочка\n",
      "4043 бокал\n",
      "4044 бросаться\n",
      "4045 грустно\n",
      "4046 дескать\n",
      "4047 жуткий\n",
      "4048 кисть\n",
      "4049 отложить\n",
      "4050 отмечаться\n",
      "4051 подбородок\n",
      "4052 разбудить\n",
      "4053 распространяться\n",
      "4054 бар\n",
      "4055 вопреки\n",
      "4056 голосование\n",
      "4057 идиот\n",
      "4058 инфекция\n",
      "4059 килограмм\n",
      "4060 койка\n",
      "4061 облегчение\n",
      "4062 петербургский\n",
      "4063 привлечение\n",
      "4064 рай\n",
      "4065 смелый\n",
      "4066 трибуна\n",
      "4067 тяжкий\n",
      "4068 удержаться\n",
      "4069 жаркий\n",
      "4070 заявка\n",
      "4071 медленный\n",
      "4072 обычай\n",
      "4073 пострадать\n",
      "4074 резерв\n",
      "4075 сократить\n",
      "4076 тесно\n",
      "4077 точно\n",
      "4078 тур\n",
      "4079 якорь\n",
      "4080 диплом\n",
      "4081 дрова\n",
      "4082 живопись\n",
      "4083 красиво\n",
      "4084 ошибаться\n",
      "4085 продаваться\n",
      "4086 прощаться\n",
      "4087 такой-то\n",
      "4088 учительница\n",
      "4089 ядро\n",
      "4090 ворот\n",
      "4091 годовой\n",
      "4092 загадка\n",
      "4093 заметка\n",
      "4094 недолго\n",
      "4095 неподалеку\n",
      "4096 окошко\n",
      "4097 опора\n",
      "4098 приватизация\n",
      "4099 просыпаться\n",
      "4100 сметь\n",
      "4101 сорвать\n",
      "4102 универсальный\n",
      "4103 учеба\n",
      "4104 христов\n",
      "4105 шинель\n",
      "4106 запереть\n",
      "4107 исключать\n",
      "4108 конструктор\n",
      "4109 личной\n",
      "4110 наметить\n",
      "4111 ноготь\n",
      "4112 предупреждение\n",
      "4113 преподобный\n",
      "4114 приложить\n",
      "4115 сохраняться\n",
      "4116 формальный\n",
      "4117 выехать\n",
      "4118 годиться\n",
      "4119 залить\n",
      "4120 коричневый\n",
      "4121 кровавый\n",
      "4122 либеральный\n",
      "4123 наивный\n",
      "4124 национальность\n",
      "4125 отечество\n",
      "4126 топор\n",
      "4127 физик\n",
      "4128 филиал\n",
      "4129 барон\n",
      "4130 владыка\n",
      "4131 диаметр\n",
      "4132 жирный\n",
      "4133 застать\n",
      "4134 конверт\n",
      "4135 митрополит\n",
      "4136 одобрить\n",
      "4137 осознать\n",
      "4138 пляж\n",
      "4139 покрытие\n",
      "4140 светиться\n",
      "4141 снежный\n",
      "4142 спортсмен\n",
      "4143 тест\n",
      "4144 усесться\n",
      "4145 эмоциональный\n",
      "4146 барак\n",
      "4147 болото\n",
      "4148 девятый\n",
      "4149 десятый\n",
      "4150 евангелие\n",
      "4151 искренний\n",
      "4152 кукла\n",
      "4153 отпускать\n",
      "4154 поправить\n",
      "4155 прекращение\n",
      "4156 семьдесят\n",
      "4157 совершение\n",
      "4158 старшина\n",
      "4159 устанавливаться\n",
      "4160 эволюция\n",
      "4161 выводить\n",
      "4162 германский\n",
      "4163 жених\n",
      "4164 задумать\n",
      "4165 исключительно\n",
      "4166 лозунг\n",
      "4167 носок\n",
      "4168 охранять\n",
      "4169 патрон\n",
      "4170 поручение\n",
      "4171 сыворотка\n",
      "4172 медный\n",
      "4173 неудача\n",
      "4174 одиннадцать\n",
      "4175 отнять\n",
      "4176 пермский\n",
      "4177 послужить\n",
      "4178 продемонстрировать\n",
      "4179 рассвет\n",
      "4180 сволочь\n",
      "4181 стабильность\n",
      "4182 телевизионный\n",
      "4183 эфир\n",
      "4184 всюду\n",
      "4185 мелодия\n",
      "4186 обувь\n",
      "4187 по-своему\n",
      "4188 преследовать\n",
      "4189 приветствовать\n",
      "4190 римский\n",
      "4191 секретный\n",
      "4192 сталкиваться\n",
      "4193 ширина\n",
      "4194 благоприятный\n",
      "4195 гастроли\n",
      "4196 ежегодно\n",
      "4197 заново\n",
      "4198 намек\n",
      "4199 первоначальный\n",
      "4200 поместить\n",
      "4201 раб\n",
      "4202 раздражение\n",
      "4203 раненый\n",
      "4204 внимательный\n",
      "4205 запустить\n",
      "4206 котел\n",
      "4207 кремлевский\n",
      "4208 мастерство\n",
      "4209 освоение\n",
      "4210 полнота\n",
      "4211 принц\n",
      "4212 присущий\n",
      "4213 пруд\n",
      "4214 развернуться\n",
      "4215 стальной\n",
      "4216 колебание\n",
      "4217 ловко\n",
      "4218 рядовой\n",
      "4219 снаряд\n",
      "4220 сформировать\n",
      "4221 давить\n",
      "4222 зелень\n",
      "4223 индивид\n",
      "4224 лук\n",
      "4225 некогда\n",
      "4226 оправдать\n",
      "4227 печатать\n",
      "4228 подчиняться\n",
      "4229 популярность\n",
      "4230 поражать\n",
      "4231 предвыборный\n",
      "4232 применить\n",
      "4233 пушка\n",
      "4234 свое\n",
      "4235 скрытый\n",
      "4236 ток\n",
      "4237 угу\n",
      "4238 фантастический\n",
      "4239 безумный\n",
      "4240 благодарный\n",
      "4241 вылезти\n",
      "4242 закрепить\n",
      "4243 крем\n",
      "4244 направляться\n",
      "4245 одинаково\n",
      "4246 пароход\n",
      "4247 сверкать\n",
      "4248 снизить\n",
      "4249 сравнивать\n",
      "4250 вздрогнуть\n",
      "4251 воспринять\n",
      "4252 драгоценный\n",
      "4253 забить\n",
      "4254 звон\n",
      "4255 инфраструктура\n",
      "4256 машинка\n",
      "4257 обещание\n",
      "4258 препятствие\n",
      "4259 приблизиться\n",
      "4260 придать\n",
      "4261 прилететь\n",
      "4262 слушатель\n",
      "4263 супруга\n",
      "4264 уложить\n",
      "4265 бедро\n",
      "4266 иллюзия\n",
      "4267 максимально\n",
      "4268 накрыть\n",
      "4269 наслаждение\n",
      "4270 обожать\n",
      "4271 осторожный\n",
      "4272 пейзаж\n",
      "4273 передо\n",
      "4274 поделать\n",
      "4275 разделение\n",
      "4276 упражнение\n",
      "4277 внешне\n",
      "4278 внешность\n",
      "4279 гвоздь\n",
      "4280 гордый\n",
      "4281 гостиная\n",
      "4282 недоумение\n",
      "4283 ночевать\n",
      "4284 обширный\n",
      "4285 отыскать\n",
      "4286 свыше\n",
      "4287 частично\n",
      "4288 эй\n",
      "4289 восприниматься\n",
      "4290 выдвинуть\n",
      "4291 ласковый\n",
      "4292 одетый\n",
      "4293 порыв\n",
      "4294 пребывать\n",
      "4295 сетка\n",
      "4296 союзник\n",
      "4297 студенческий\n",
      "4298 автоматический\n",
      "4299 безопасный\n",
      "4300 возрастать\n",
      "4301 вольный\n",
      "4302 вследствие\n",
      "4303 мобильный\n",
      "4304 невысокий\n",
      "4305 подсказать\n",
      "4306 поставщик\n",
      "4307 проход\n",
      "4308 решительный\n",
      "4309 советник\n",
      "4310 что-либо\n",
      "4311 бесконечно\n",
      "4312 влажный\n",
      "4313 вручить\n",
      "4314 гладкий\n",
      "4315 дурацкий\n",
      "4316 квалификация\n",
      "4317 колодец\n",
      "4318 пенсионер\n",
      "4319 прочный\n",
      "4320 раздражать\n",
      "4321 реплика\n",
      "4322 сарай\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4323 словарь\n",
      "4324 туча\n",
      "4325 увеличиваться\n",
      "4326 шуметь\n",
      "4327 возить\n",
      "4328 изнутри\n",
      "4329 мудрость\n",
      "4330 опрос\n",
      "4331 подполковник\n",
      "4332 попросту\n",
      "4333 провинция\n",
      "4334 простор\n",
      "4335 прочь\n",
      "4336 слон\n",
      "4337 чин\n",
      "4338 ад\n",
      "4339 альбом\n",
      "4340 вена\n",
      "4341 направлять\n",
      "4342 обследование\n",
      "4343 святой\n",
      "4344 старт\n",
      "4345 тепло\n",
      "4346 шкура\n",
      "4347 антитело\n",
      "4348 бесплатно\n",
      "4349 близкие\n",
      "4350 вспышка\n",
      "4351 драка\n",
      "4352 ласково\n",
      "4353 младенец\n",
      "4354 нажать\n",
      "4355 нестись\n",
      "4356 нота\n",
      "4357 оппозиция\n",
      "4358 пособие\n",
      "4359 предпринять\n",
      "4360 происшествие\n",
      "4361 растеряться\n",
      "4362 сводить\n",
      "4363 сравнительно\n",
      "4364 торопливо\n",
      "4365 украсить\n",
      "4366 формировать\n",
      "4367 функциональный\n",
      "4368 взор\n",
      "4369 вставить\n",
      "4370 жалость\n",
      "4371 защитник\n",
      "4372 посещение\n",
      "4373 постройка\n",
      "4374 проба\n",
      "4375 решающий\n",
      "4376 снимок\n",
      "4377 стук\n",
      "4378 тетрадь\n",
      "4379 японец\n",
      "4380 беречь\n",
      "4381 заработный\n",
      "4382 казак\n",
      "4383 кислота\n",
      "4384 мусор\n",
      "4385 мыслить\n",
      "4386 отверстие\n",
      "4387 педагогический\n",
      "4388 плотно\n",
      "4389 правонарушение\n",
      "4390 скрываться\n",
      "4391 скучно\n",
      "4392 хитрый\n",
      "4393 христианин\n",
      "4394 армейский\n",
      "4395 влечь\n",
      "4396 геологический\n",
      "4397 дефицит\n",
      "4398 застынуть\n",
      "4399 кран\n",
      "4400 ложный\n",
      "4401 нежность\n",
      "4402 переводчик\n",
      "4403 преступный\n",
      "4404 проехать\n",
      "4405 смертный\n",
      "4406 спасибо\n",
      "4407 удержать\n",
      "4408 условный\n",
      "4409 вылететь\n",
      "4410 галерея\n",
      "4411 держава\n",
      "4412 жилищный\n",
      "4413 зависть\n",
      "4414 моряк\n",
      "4415 напротив\n",
      "4416 обижаться\n",
      "4417 повышать\n",
      "4418 похоронить\n",
      "4419 претендовать\n",
      "4420 просторный\n",
      "4421 прохожий\n",
      "4422 рог\n",
      "4423 ругать\n",
      "4424 самка\n",
      "4425 туфля\n",
      "4426 угадать\n",
      "4427 химия\n",
      "4428 шагать\n",
      "4429 элементарный\n",
      "4430 велосипед\n",
      "4431 вечность\n",
      "4432 внезапный\n",
      "4433 деться\n",
      "4434 ерунда\n",
      "4435 инспектор\n",
      "4436 кататься\n",
      "4437 мадам\n",
      "4438 объединять\n",
      "4439 племя\n",
      "4440 привлекательный\n",
      "4441 свинья\n",
      "4442 тротуар\n",
      "4443 тупой\n",
      "4444 функционирование\n",
      "4445 хлопнуть\n",
      "4446 хрен\n",
      "4447 четверо\n",
      "4448 батальон\n",
      "4449 жидкий\n",
      "4450 изготовить\n",
      "4451 коррупция\n",
      "4452 кубок\n",
      "4453 покойный\n",
      "4454 полно\n",
      "4455 привязать\n",
      "4456 резать\n",
      "4457 родные\n",
      "4458 стрелка\n",
      "4459 усталый\n",
      "4460 аромат\n",
      "4461 возбудить\n",
      "4462 заканчивать\n",
      "4463 коренной\n",
      "4464 мясной\n",
      "4465 напрасно\n",
      "4466 неловко\n",
      "4467 неожиданность\n",
      "4468 подавлять\n",
      "4469 поклонник\n",
      "4470 потратить\n",
      "4471 преимущественно\n",
      "4472 сорваться\n",
      "4473 трактор\n",
      "4474 усиление\n",
      "4475 характеризовать\n",
      "4476 ягода\n",
      "4477 актерский\n",
      "4478 битва\n",
      "4479 головка\n",
      "4480 голосовать\n",
      "4481 зрелище\n",
      "4482 изредка\n",
      "4483 монах\n",
      "4484 наружу\n",
      "4485 открыто\n",
      "4486 отходить\n",
      "4487 по-разному\n",
      "4488 приоритет\n",
      "4489 скучный\n",
      "4490 тряпка\n",
      "4491 удовлетворить\n",
      "4492 выгнать\n",
      "4493 грамм\n",
      "4494 дырка\n",
      "4495 заорать\n",
      "4496 ил\n",
      "4497 исключительный\n",
      "4498 комедия\n",
      "4499 минувший\n",
      "4500 мысленно\n",
      "4501 наверх\n",
      "4502 отмена\n",
      "4503 отправлять\n",
      "4504 побег\n",
      "4505 ползти\n",
      "4506 провал\n",
      "4507 разряд\n",
      "4508 ракетный\n",
      "4509 сходство\n",
      "4510 тыл\n",
      "4511 упустить\n",
      "4512 ученый\n",
      "4513 аж\n",
      "4514 базар\n",
      "4515 болтать\n",
      "4516 бревно\n",
      "4517 вспыхнуть\n",
      "4518 дежурный\n",
      "4519 драма\n",
      "4520 климат\n",
      "4521 комсомольский\n",
      "4522 кончать\n",
      "4523 набить\n",
      "4524 наследник\n",
      "4525 наследство\n",
      "4526 недвижимость\n",
      "4527 ненужный\n",
      "4528 нить\n",
      "4529 опоздать\n",
      "4530 переработка\n",
      "4531 полевой\n",
      "4532 пропаганда\n",
      "4533 равновесие\n",
      "4534 разрабатывать\n",
      "4535 синтез\n",
      "4536 спинка\n",
      "4537 угрожать\n",
      "4538 делить\n",
      "4539 должник\n",
      "4540 ленинский\n",
      "4541 надевать\n",
      "4542 попадаться\n",
      "4543 почтовый\n",
      "4544 правоохранительный\n",
      "4545 ранг\n",
      "4546 слепой\n",
      "4547 стыд\n",
      "4548 управляющий\n",
      "4549 христианство\n",
      "4550 встречный\n",
      "4551 выявление\n",
      "4552 график\n",
      "4553 доза\n",
      "4554 забавный\n",
      "4555 заслуживать\n",
      "4556 интерьер\n",
      "4557 как-нибудь\n",
      "4558 королева\n",
      "4559 кредитор\n",
      "4560 логический\n",
      "4561 настать\n",
      "4562 непрерывный\n",
      "4563 обидно\n",
      "4564 обходиться\n",
      "4565 отбор\n",
      "4566 отчаянный\n",
      "4567 пешком\n",
      "4568 приз\n",
      "4569 пропускать\n",
      "4570 сбежать\n",
      "4571 уменьшение\n",
      "4572 урожай\n",
      "4573 чуждый\n",
      "4574 барьер\n",
      "4575 вежливо\n",
      "4576 дарить\n",
      "4577 духи\n",
      "4578 елка\n",
      "4579 захват\n",
      "4580 клиника\n",
      "4581 корпоративный\n",
      "4582 ладно\n",
      "4583 надзор\n",
      "4584 обвинять\n",
      "4585 ругаться\n",
      "4586 собачий\n",
      "4587 торжественно\n",
      "4588 убеждать\n",
      "4589 частота\n",
      "4590 чувствоваться\n",
      "4591 чудовищный\n",
      "4592 бык\n",
      "4593 гитара\n",
      "4594 испортить\n",
      "4595 лужа\n",
      "4596 махать\n",
      "4597 меж\n",
      "4598 плен\n",
      "4599 разрешать\n",
      "4600 рак\n",
      "4601 рвать\n",
      "4602 спирт\n",
      "4603 автономный\n",
      "4604 извлечь\n",
      "4605 изменять\n",
      "4606 интеллигентный\n",
      "4607 кузов\n",
      "4608 материя\n",
      "4609 матрос\n",
      "4610 мелькнуть\n",
      "4611 переносить\n",
      "4612 развод\n",
      "4613 разместить\n",
      "4614 сантиметр\n",
      "4615 соблюдать\n",
      "4616 создатель\n",
      "4617 хирург\n",
      "4618 целевой\n",
      "4619 бензин\n",
      "4620 ванна\n",
      "4621 государь\n",
      "4622 драматический\n",
      "4623 желудок\n",
      "4624 изобретение\n",
      "4625 любовный\n",
      "4626 миссия\n",
      "4627 мучительный\n",
      "4628 наносить\n",
      "4629 непростой\n",
      "4630 рейс\n",
      "4631 сводиться\n",
      "4632 сердиться\n",
      "4633 специализированный\n",
      "4634 терпение\n",
      "4635 товарный\n",
      "4636 употреблять\n",
      "4637 бумажный\n",
      "4638 грохот\n",
      "4639 грузинский\n",
      "4640 жир\n",
      "4641 избегать\n",
      "4642 кадровый\n",
      "4643 канон\n",
      "4644 компенсация\n",
      "4645 осмотреть\n",
      "4646 откровенный\n",
      "4647 представительство\n",
      "4648 репутация\n",
      "4649 рыбак\n",
      "4650 стройный\n",
      "4651 татарский\n",
      "4652 устойчивость\n",
      "4653 щит\n",
      "4654 апостол\n",
      "4655 бульвар\n",
      "4656 выдача\n",
      "4657 двадцатый\n",
      "4658 действительный\n",
      "4659 драться\n",
      "4660 забирать\n",
      "4661 значимый\n",
      "4662 израильский\n",
      "4663 оборачиваться\n",
      "4664 повторяться\n",
      "4665 прошедший\n",
      "4666 уговаривать\n",
      "4667 уравнение\n",
      "4668 четверг\n",
      "4669 энергетика\n",
      "4670 ансамбль\n",
      "4671 беспокоить\n",
      "4672 диссертация\n",
      "4673 заяц\n",
      "4674 капуста\n",
      "4675 комиссар\n",
      "4676 консультация\n",
      "4677 крохотный\n",
      "4678 лампочка\n",
      "4679 олимпийский\n",
      "4680 организационный\n",
      "4681 откуда-то\n",
      "4682 подоконник\n",
      "4683 проникнуть\n",
      "4684 ребро\n",
      "4685 столкновение\n",
      "4686 фактический\n",
      "4687 было\n",
      "4688 доноситься\n",
      "4689 завидовать\n",
      "4690 мамин\n",
      "4691 необыкновенный\n",
      "4692 охватывать\n",
      "4693 приключение\n",
      "4694 простота\n",
      "4695 сжечь\n",
      "4696 склонный\n",
      "4697 сочинять\n",
      "4698 установленный\n",
      "4699 фрукт\n",
      "4700 вдова\n",
      "4701 взятка\n",
      "4702 включение\n",
      "4703 гармония\n",
      "4704 грубо\n",
      "4705 община\n",
      "4706 осудить\n",
      "4707 ось\n",
      "4708 пулемет\n",
      "4709 транслит\n",
      "4710 цитата\n",
      "4711 чайник\n",
      "4712 шагнуть\n",
      "4713 балет\n",
      "4714 весть\n",
      "4715 восемьдесят\n",
      "4716 казнь\n",
      "4717 командующий\n",
      "4718 недаром\n",
      "4719 образовать\n",
      "4720 окраина\n",
      "4721 освободиться\n",
      "4722 пророк\n",
      "4723 спаситель\n",
      "4724 бабочка\n",
      "4725 дневной\n",
      "4726 навык\n",
      "4727 пение\n",
      "4728 посредством\n",
      "4729 пробка\n",
      "4730 рациональный\n",
      "4731 ручей\n",
      "4732 сажать\n",
      "4733 светский\n",
      "4734 сэр\n",
      "4735 уютный\n",
      "4736 бред\n",
      "4737 вздыхать\n",
      "4738 изящный\n",
      "4739 легкость\n",
      "4740 молекула\n",
      "4741 наверху\n",
      "4742 незначительный\n",
      "4743 отнестись\n",
      "4744 оторваться\n",
      "4745 отрицать\n",
      "4746 перечислить\n",
      "4747 разведчик\n",
      "4748 рама\n",
      "4749 рубаха\n",
      "4750 свалиться\n",
      "4751 таблетка\n",
      "4752 архитектурный\n",
      "4753 валютный\n",
      "4754 взвод\n",
      "4755 всевозможный\n",
      "4756 вырвать\n",
      "4757 дистанция\n",
      "4758 запомниться\n",
      "4759 испанский\n",
      "4760 кислород\n",
      "4761 наклониться\n",
      "4762 неизбежно\n",
      "4763 палочка\n",
      "4764 поцелуй\n",
      "4765 прихожая\n",
      "4766 пропадать\n",
      "4767 светить\n",
      "4768 сессия\n",
      "4769 служащий\n",
      "4770 спеть\n",
      "4771 тихонько\n",
      "4772 тревожный\n",
      "4773 убыток\n",
      "4774 увезти\n",
      "4775 увлечение\n",
      "4776 уступить\n",
      "4777 коллегия\n",
      "4778 магнитный\n",
      "4779 милицейский\n",
      "4780 окружающее\n",
      "4781 регулировать\n",
      "4782 соображать\n",
      "4783 сумерки\n",
      "4784 ярость\n",
      "4785 банкротство\n",
      "4786 догнать\n",
      "4787 докладывать\n",
      "4788 касса\n",
      "4789 лауреат\n",
      "4790 прыжок\n",
      "4791 тройка\n",
      "4792 фундаментальный\n",
      "4793 чрезвычайный\n",
      "4794 щенок\n",
      "4795 анализировать\n",
      "4796 вздох\n",
      "4797 воспитывать\n",
      "4798 выходной\n",
      "4799 гнездо\n",
      "4800 демонстрация\n",
      "4801 колебаться\n",
      "4802 конечно\n",
      "4803 негромко\n",
      "4804 парижский\n",
      "4805 поддаваться\n",
      "4806 романтический\n",
      "4807 слышаться\n",
      "4808 удерживать\n",
      "4809 феномен\n",
      "4810 юрист\n",
      "4811 возбуждение\n",
      "4812 возвращать\n",
      "4813 героиня\n",
      "4814 дополнение\n",
      "4815 ирония\n",
      "4816 королевский\n",
      "4817 молодежный\n",
      "4818 наружный\n",
      "4819 новенький\n",
      "4820 официант\n",
      "4821 погодить\n",
      "4822 потихоньку\n",
      "4823 представиться\n",
      "4824 сгореть\n",
      "4825 специфика\n",
      "4826 стрела\n",
      "4827 чеченец\n",
      "4828 шахта\n",
      "4829 шевелиться\n",
      "4830 этнический\n",
      "4831 вирусный\n",
      "4832 воплощение\n",
      "4833 выгода\n",
      "4834 дизайн\n",
      "4835 зафиксировать\n",
      "4836 милость\n",
      "4837 относительно\n",
      "4838 очко\n",
      "4839 подробный\n",
      "4840 потомок\n",
      "4841 рецепт\n",
      "4842 социально-экономический\n",
      "4843 удивленно\n",
      "4844 арабский\n",
      "4845 атом\n",
      "4846 букет\n",
      "4847 верность\n",
      "4848 защитный\n",
      "4849 змея\n",
      "4850 китаец\n",
      "4851 мораль\n",
      "4852 наладить\n",
      "4853 оказание\n",
      "4854 поверхностный\n",
      "4855 подъехать\n",
      "4856 покончить\n",
      "4857 полотенце\n",
      "4858 провалиться\n",
      "4859 сопровождение\n",
      "4860 средневековый\n",
      "4861 суждение\n",
      "4862 тираж\n",
      "4863 уволить\n",
      "4864 шпион\n",
      "4865 алкоголь\n",
      "4866 возмутиться\n",
      "4867 доставлять\n",
      "4868 жилец\n",
      "4869 звездный\n",
      "4870 накопить\n",
      "4871 настроить\n",
      "4872 объявлять\n",
      "4873 осколок\n",
      "4874 палуба\n",
      "4875 превращение\n",
      "4876 прибавить\n",
      "4877 равнодушный\n",
      "4878 спокойствие\n",
      "4879 тезис\n",
      "4880 электроэнергия\n",
      "4881 береза\n",
      "4882 важность\n",
      "4883 веко\n",
      "4884 вытекать\n",
      "4885 задолженность\n",
      "4886 залог\n",
      "4887 испуганно\n",
      "4888 конкретно\n",
      "4889 накопление\n",
      "4890 организовывать\n",
      "4891 осознавать\n",
      "4892 очистить\n",
      "4893 передовой\n",
      "4894 пещера\n",
      "4895 приступ\n",
      "4896 проектирование\n",
      "4897 сердечный\n",
      "4898 сопровождаться\n",
      "4899 спичка\n",
      "4900 струя\n",
      "4901 тактика\n",
      "4902 таскать\n",
      "4903 удачно\n",
      "4904 унести\n",
      "4905 уста\n",
      "4906 внесение\n",
      "4907 здравоохранение\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4908 категорически\n",
      "4909 мужество\n",
      "4910 мчаться\n",
      "4911 наименование\n",
      "4912 наказать\n",
      "4913 обнимать\n",
      "4914 остро\n",
      "4915 плакат\n",
      "4916 предать\n",
      "4917 принятый\n",
      "4918 психика\n",
      "4919 солдатский\n",
      "4920 упорно\n",
      "4921 хлопать\n",
      "4922 электричество\n",
      "4923 буря\n",
      "4924 выразиться\n",
      "4925 забросить\n",
      "4926 закономерность\n",
      "4927 здешний\n",
      "4928 исполниться\n",
      "4929 мелькать\n",
      "4930 многолетний\n",
      "4931 очерк\n",
      "4932 передаваться\n",
      "4933 поверх\n",
      "4934 производительность\n",
      "4935 сдерживать\n",
      "4936 церемония\n",
      "4937 автоматически\n",
      "4938 аэродром\n",
      "4939 буфет\n",
      "4940 винтовка\n",
      "4941 жажда\n",
      "4942 метаться\n",
      "4943 надежность\n",
      "4944 одеваться\n",
      "4945 плоскость\n",
      "4946 плотность\n",
      "4947 позади\n",
      "4948 сдача\n",
      "4949 сжать\n",
      "4950 скот\n",
      "4951 смело\n",
      "4952 творение\n",
      "4953 тем\n",
      "4954 толкнуть\n",
      "4955 убирать\n",
      "4956 выработка\n",
      "4957 вырезать\n",
      "4958 гипотеза\n",
      "4959 добыть\n",
      "4960 зад\n",
      "4961 заложник\n",
      "4962 инстинкт\n",
      "4963 кружок\n",
      "4964 максимум\n",
      "4965 наградить\n",
      "4966 ничуть\n",
      "4967 овощи\n",
      "4968 отвезти\n",
      "4969 пасть\n",
      "4970 полдень\n",
      "4971 радовать\n",
      "4972 расставить\n",
      "4973 совпадение\n",
      "4974 срочный\n",
      "4975 а\n",
      "4976 альтернативный\n",
      "4977 возглавить\n",
      "4978 жарко\n",
      "4979 животный\n",
      "4980 интерпретация\n",
      "4981 классификация\n",
      "4982 конгресс\n",
      "4983 кончик\n",
      "4984 крестьянский\n",
      "4985 молчаливый\n",
      "4986 новейший\n",
      "4987 отстать\n",
      "4988 перчатка\n",
      "4989 поддержание\n",
      "4990 пригодиться\n",
      "4991 пропасть\n",
      "4992 пуговица\n",
      "4993 раздаваться\n",
      "4994 толщина\n",
      "4995 царить\n",
      "4996 диапазон\n",
      "4997 допускаться\n",
      "4998 заинтересованный\n",
      "4999 криминальный\n",
      "5000 наблюдатель\n",
      "5001 нитка\n",
      "5002 орел\n",
      "5003 поляна\n",
      "5004 проволока\n",
      "5005 разом\n",
      "5006 рояль\n",
      "5007 уличный\n",
      "5008 шумный\n",
      "5009 академический\n",
      "5010 аплодисменты\n",
      "5011 болезненный\n",
      "5012 выбить\n",
      "5013 грандиозный\n",
      "5014 гуманитарный\n",
      "5015 дабы\n",
      "5016 конфета\n",
      "5017 легкое\n",
      "5018 лошадиный\n",
      "5019 любоваться\n",
      "5020 образовательный\n",
      "5021 освоить\n",
      "5022 очнуться\n",
      "5023 пацан\n",
      "5024 перевернуть\n",
      "5025 придерживаться\n",
      "5026 суета\n",
      "5027 травма\n",
      "5028 украшение\n",
      "5029 физически\n",
      "5030 худший\n",
      "5031 видимость\n",
      "5032 выезжать\n",
      "5033 выработать\n",
      "5034 дружеский\n",
      "5035 завернуть\n",
      "5036 задыхаться\n",
      "5037 козел\n",
      "5038 лопата\n",
      "5039 наряд\n",
      "5040 недостаточный\n",
      "5041 отступать\n",
      "5042 пустяк\n",
      "5043 сочинить\n",
      "5044 стабильный\n",
      "5045 сыр\n",
      "5046 тайга\n",
      "5047 вмешательство\n",
      "5048 возиться\n",
      "5049 выпускник\n",
      "5050 дальнейшее\n",
      "5051 декорация\n",
      "5052 джинсы\n",
      "5053 излучение\n",
      "5054 корзина\n",
      "5055 невозможность\n",
      "5056 неизменный\n",
      "5057 образованный\n",
      "5058 октябрьский\n",
      "5059 ориентация\n",
      "5060 отражаться\n",
      "5061 петля\n",
      "5062 печаль\n",
      "5063 повсюду\n",
      "5064 полотно\n",
      "5065 поработать\n",
      "5066 поселиться\n",
      "5067 прелесть\n",
      "5068 разнообразие\n",
      "5069 регулярный\n",
      "5070 скучать\n",
      "5071 старательно\n",
      "5072 традиционно\n",
      "5073 уверить\n",
      "5074 упор\n",
      "5075 э\n",
      "5076 владение\n",
      "5077 вторник\n",
      "5078 дьявол\n",
      "5079 обнаруживать\n",
      "5080 относительный\n",
      "5081 парламентский\n",
      "5082 поспешно\n",
      "5083 разноцветный\n",
      "5084 сбоку\n",
      "5085 темно\n",
      "5086 толком\n",
      "5087 увеличивать\n",
      "5088 всероссийский\n",
      "5089 генетический\n",
      "5090 гудеть\n",
      "5091 епископ\n",
      "5092 изначально\n",
      "5093 интенсивный\n",
      "5094 пласт\n",
      "5095 подружка\n",
      "5096 полоска\n",
      "5097 поразительный\n",
      "5098 пресс-конференция\n",
      "5099 пропуск\n",
      "5100 редкость\n",
      "5101 сопротивляться\n",
      "5102 твориться\n",
      "5103 бригадир\n",
      "5104 гладить\n",
      "5105 дипломат\n",
      "5106 колония\n",
      "5107 коса\n",
      "5108 литератор\n",
      "5109 обман\n",
      "5110 отходы\n",
      "5111 печатный\n",
      "5112 печень\n",
      "5113 позитивный\n",
      "5114 потерпеть\n",
      "5115 премьер-министр\n",
      "5116 славянский\n",
      "5117 спрятаться\n",
      "5118 эстетический\n",
      "5119 величайший\n",
      "5120 витрина\n",
      "5121 госпожа\n",
      "5122 дружно\n",
      "5123 кинотеатр\n",
      "5124 код\n",
      "5125 неясный\n",
      "5126 плюс\n",
      "5127 приподнять\n",
      "5128 пускай\n",
      "5129 разорвать\n",
      "5130 снаружи\n",
      "5131 трястись\n",
      "5132 убежденный\n",
      "5133 шарик\n",
      "5134 шахматы\n",
      "5135 батюшка\n",
      "5136 бешеный\n",
      "5137 диагноз\n",
      "5138 долина\n",
      "5139 дуть\n",
      "5140 женатый\n",
      "5141 занести\n",
      "5142 кипеть\n",
      "5143 обнаружение\n",
      "5144 огурец\n",
      "5145 ориентировать\n",
      "5146 открытка\n",
      "5147 поворачиваться\n",
      "5148 предварительно\n",
      "5149 прощение\n",
      "5150 роковой\n",
      "5151 рыцарь\n",
      "5152 рычаг\n",
      "5153 симпатия\n",
      "5154 сойтись\n",
      "5155 стихия\n",
      "5156 уцелеть\n",
      "5157 влюбиться\n",
      "5158 воспитать\n",
      "5159 выстроить\n",
      "5160 газетный\n",
      "5161 горечь\n",
      "5162 горячо\n",
      "5163 завершиться\n",
      "5164 злоба\n",
      "5165 кора\n",
      "5166 любовник\n",
      "5167 мороженое\n",
      "5168 неподвижный\n",
      "5169 новогодний\n",
      "5170 отставать\n",
      "5171 посчитать\n",
      "5172 садовый\n",
      "5173 секретарша\n",
      "5174 трещина\n",
      "5175 лишиться\n",
      "5176 локальный\n",
      "5177 марш\n",
      "5178 нарочно\n",
      "5179 нуль\n",
      "5180 обедать\n",
      "5181 ограда\n",
      "5182 песнь\n",
      "5183 печально\n",
      "5184 политбюро\n",
      "5185 постучать\n",
      "5186 предпочтение\n",
      "5187 придумывать\n",
      "5188 резиновый\n",
      "5189 реформирование\n",
      "5190 ссылаться\n",
      "5191 уловить\n",
      "5192 умолять\n",
      "5193 чаша\n",
      "5194 шуба\n",
      "5195 аппаратура\n",
      "5196 ведать\n",
      "5197 витамин\n",
      "5198 вон\n",
      "5199 горько\n",
      "5200 доставка\n",
      "5201 заработок\n",
      "5202 кавказский\n",
      "5203 мент\n",
      "5204 нежно\n",
      "5205 неправда\n",
      "5206 повлиять\n",
      "5207 подвергаться\n",
      "5208 престижный\n",
      "5209 прощание\n",
      "5210 сердито\n",
      "5211 содействие\n",
      "5212 стадо\n",
      "5213 съездить\n",
      "5214 толчок\n",
      "5215 турецкий\n",
      "5216 цитировать\n",
      "5217 агрегат\n",
      "5218 бедность\n",
      "5219 беспокойство\n",
      "5220 именовать\n",
      "5221 исправить\n",
      "5222 казенный\n",
      "5223 калитка\n",
      "5224 куда-нибудь\n",
      "5225 мед\n",
      "5226 окраска\n",
      "5227 опускаться\n",
      "5228 повреждение\n",
      "5229 проникать\n",
      "5230 протягивать\n",
      "5231 разбирать\n",
      "5232 расставаться\n",
      "5233 саратовский\n",
      "5234 совершенство\n",
      "5235 татарин\n",
      "5236 толкать\n",
      "5237 упоминать\n",
      "5238 бесполезный\n",
      "5239 вакцина\n",
      "5240 вдвое\n",
      "5241 вкладывать\n",
      "5242 впрямь\n",
      "5243 глина\n",
      "5244 заведовать\n",
      "5245 крутиться\n",
      "5246 молочный\n",
      "5247 мотоцикл\n",
      "5248 отбросить\n",
      "5249 отступить\n",
      "5250 полицейский\n",
      "5251 поменять\n",
      "5252 руководствоваться\n",
      "5253 скрипка\n",
      "5254 сука\n",
      "5255 трезвый\n",
      "5256 уговорить\n",
      "5257 успокаивать\n",
      "5258 учащийся\n",
      "5259 фонтан\n",
      "5260 цивилизованный\n",
      "5261 бег\n",
      "5262 властный\n",
      "5263 восхищение\n",
      "5264 выезд\n",
      "5265 жевать\n",
      "5266 жестко\n",
      "5267 закат\n",
      "5268 запрещать\n",
      "5269 интеграция\n",
      "5270 иркутский\n",
      "5271 кривой\n",
      "5272 лыжа\n",
      "5273 направо\n",
      "5274 опускать\n",
      "5275 повестка\n",
      "5276 повредить\n",
      "5277 поесть\n",
      "5278 потребительский\n",
      "5279 предпочесть\n",
      "5280 предшествовать\n",
      "5281 прижаться\n",
      "5282 продвижение\n",
      "5283 распорядиться\n",
      "5284 ручной\n",
      "5285 сказаться\n",
      "5286 сомнительный\n",
      "5287 соотечественник\n",
      "5288 сочувствие\n",
      "5289 становление\n",
      "5290 улететь\n",
      "5291 восемнадцать\n",
      "5292 договоренность\n",
      "5293 дожить\n",
      "5294 думаться\n",
      "5295 зажечь\n",
      "5296 издали\n",
      "5297 отвратительный\n",
      "5298 планирование\n",
      "5299 простыня\n",
      "5300 пышный\n",
      "5301 служение\n",
      "5302 спецслужба\n",
      "5303 физиономия\n",
      "5304 характеризоваться\n",
      "5305 аналитик\n",
      "5306 аналитический\n",
      "5307 вдали\n",
      "5308 входной\n",
      "5309 жительство\n",
      "5310 задеть\n",
      "5311 интеллигент\n",
      "5312 колючий\n",
      "5313 навести\n",
      "5314 налево\n",
      "5315 неверный\n",
      "5316 нисколько\n",
      "5317 офицерский\n",
      "5318 преподавать\n",
      "5319 приготовление\n",
      "5320 прикрывать\n",
      "5321 примета\n",
      "5322 пройтись\n",
      "5323 против\n",
      "5324 прыгнуть\n",
      "5325 пыльный\n",
      "5326 радикальный\n",
      "5327 развлечение\n",
      "5328 се\n",
      "5329 укрепить\n",
      "5330 висок\n",
      "5331 гад\n",
      "5332 даль\n",
      "5333 евро\n",
      "5334 задержаться\n",
      "5335 знакомиться\n",
      "5336 индекс\n",
      "5337 кинуть\n",
      "5338 классик\n",
      "5339 купаться\n",
      "5340 маршал\n",
      "5341 немыслимый\n",
      "5342 нервничать\n",
      "5343 обзор\n",
      "5344 отчетность\n",
      "5345 параллельно\n",
      "5346 поспешить\n",
      "5347 править\n",
      "5348 пробить\n",
      "5349 проделать\n",
      "5350 путешественник\n",
      "5351 сдаваться\n",
      "5352 ступать\n",
      "5353 шахматный\n",
      "5354 дежурный\n",
      "5355 завет\n",
      "5356 искра\n",
      "5357 клясться\n",
      "5358 пестрый\n",
      "5359 питаться\n",
      "5360 пищевой\n",
      "5361 погон\n",
      "5362 потрясать\n",
      "5363 промолчать\n",
      "5364 снижать\n",
      "5365 сосредоточить\n",
      "5366 употребление\n",
      "5367 хаос\n",
      "5368 энергичный\n",
      "5369 а-а\n",
      "5370 адекватный\n",
      "5371 взнос\n",
      "5372 возврат\n",
      "5373 выключить\n",
      "5374 дуб\n",
      "5375 жар\n",
      "5376 значимость\n",
      "5377 инженерный\n",
      "5378 качать\n",
      "5379 луг\n",
      "5380 напрямую\n",
      "5381 нарастать\n",
      "5382 наслаждаться\n",
      "5383 нрав\n",
      "5384 ну-ка\n",
      "5385 обходить\n",
      "5386 одиночка\n",
      "5387 пожарный\n",
      "5388 порождать\n",
      "5389 профсоюз\n",
      "5390 слуга\n",
      "5391 случайность\n",
      "5392 телега\n",
      "5393 вглядываться\n",
      "5394 вертикальный\n",
      "5395 воротник\n",
      "5396 выполняться\n",
      "5397 затянуться\n",
      "5398 импульс\n",
      "5399 киевский\n",
      "5400 классика\n",
      "5401 крошечный\n",
      "5402 крыса\n",
      "5403 крючок\n",
      "5404 культ\n",
      "5405 минеральный\n",
      "5406 натянуть\n",
      "5407 неудобно\n",
      "5408 обвинить\n",
      "5409 объятие\n",
      "5410 отличать\n",
      "5411 переписка\n",
      "5412 подбирать\n",
      "5413 превращать\n",
      "5414 расспрашивать\n",
      "5415 санаторий\n",
      "5416 скульптура\n",
      "5417 сынок\n",
      "5418 формулировка\n",
      "5419 хата\n",
      "5420 шов\n",
      "5421 эффективно\n",
      "5422 акционерный\n",
      "5423 былой\n",
      "5424 внутрь\n",
      "5425 выдерживать\n",
      "5426 выложить\n",
      "5427 деяние\n",
      "5428 довестись\n",
      "5429 довод\n",
      "5430 договариваться\n",
      "5431 должный\n",
      "5432 издавать\n",
      "5433 издалека\n",
      "5434 кандидатура\n",
      "5435 комплект\n",
      "5436 находка\n",
      "5437 неизменно\n",
      "5438 отвращение\n",
      "5439 плевать\n",
      "5440 покраснеть\n",
      "5441 породить\n",
      "5442 приблизительно\n",
      "5443 привозить\n",
      "5444 следственный\n",
      "5445 солнышко\n",
      "5446 спуск\n",
      "5447 стадион\n",
      "5448 увести\n",
      "5449 чайка\n",
      "5450 гордо\n",
      "5451 гром\n",
      "5452 грунт\n",
      "5453 завалить\n",
      "5454 заверить\n",
      "5455 зажать\n",
      "5456 монета\n",
      "5457 невинный\n",
      "5458 обыск\n",
      "5459 овца\n",
      "5460 оснастить\n",
      "5461 особняк\n",
      "5462 повседневный\n",
      "5463 слышный\n",
      "5464 смутный\n",
      "5465 совершаться\n",
      "5466 сплошь\n",
      "5467 станок\n",
      "5468 стоянка\n",
      "5469 трясти\n",
      "5470 тут-то\n",
      "5471 тюремный\n",
      "5472 финский\n",
      "5473 десятка\n",
      "5474 завоевать\n",
      "5475 замерзнуть\n",
      "5476 злость\n",
      "5477 импортный\n",
      "5478 капитализм\n",
      "5479 клинический\n",
      "5480 кошмар\n",
      "5481 ликвидировать\n",
      "5482 наследие\n",
      "5483 обезьяна\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5484 перемещение\n",
      "5485 переспросить\n",
      "5486 поблагодарить\n",
      "5487 православие\n",
      "5488 процентный\n",
      "5489 распад\n",
      "5490 самоубийство\n",
      "5491 сражение\n",
      "5492 старичок\n",
      "5493 усадьба\n",
      "5494 цвести\n",
      "5495 благополучно\n",
      "5496 водиться\n",
      "5497 го\n",
      "5498 заря\n",
      "5499 индийский\n",
      "5500 истребитель\n",
      "5501 комбинация\n",
      "5502 мутный\n",
      "5503 нехороший\n",
      "5504 ничего\n",
      "5505 оглядеть\n",
      "5506 олимпиада\n",
      "5507 откликнуться\n",
      "5508 очаг\n",
      "5509 папироса\n",
      "5510 погладить\n",
      "5511 разводить\n",
      "5512 различать\n",
      "5513 системный\n",
      "5514 сознательно\n",
      "5515 справляться\n",
      "5516 энтузиазм\n",
      "5517 этакий\n",
      "5518 ять\n",
      "5519 величие\n",
      "5520 выписать\n",
      "5521 географический\n",
      "5522 греметь\n",
      "5523 заряд\n",
      "5524 классный\n",
      "5525 компромисс\n",
      "5526 купол\n",
      "5527 ориентироваться\n",
      "5528 отзыв\n",
      "5529 плюнуть\n",
      "5530 преодоление\n",
      "5531 протекать\n",
      "5532 репертуар\n",
      "5533 рюкзак\n",
      "5534 сено\n",
      "5535 согласование\n",
      "5536 ставиться\n",
      "5537 тверской\n",
      "5538 украшать\n",
      "5539 фундамент\n",
      "5540 жилище\n",
      "5541 заводить\n",
      "5542 заполнять\n",
      "5543 изумление\n",
      "5544 насекомое\n",
      "5545 освещение\n",
      "5546 плавание\n",
      "5547 пленум\n",
      "5548 позор\n",
      "5549 предельно\n",
      "5550 прибегать\n",
      "5551 присоединиться\n",
      "5552 промежуточный\n",
      "5553 прочность\n",
      "5554 разбойник\n",
      "5555 стройка\n",
      "5556 убегать\n",
      "5557 челюсть\n",
      "5558 шепнуть\n",
      "5559 аукцион\n",
      "5560 благополучие\n",
      "5561 вопль\n",
      "5562 гражданство\n",
      "5563 дипломатический\n",
      "5564 катер\n",
      "5565 лагерный\n",
      "5566 опасение\n",
      "5567 перебирать\n",
      "5568 полноценный\n",
      "5569 полночь\n",
      "5570 прилавок\n",
      "5571 противостоять\n",
      "5572 прохладный\n",
      "5573 скончаться\n",
      "5574 субъективный\n",
      "5575 чертеж\n",
      "5576 чистить\n",
      "5577 эмиграция\n",
      "5578 эшелон\n",
      "5579 аккуратный\n",
      "5580 возражение\n",
      "5581 интрига\n",
      "5582 квадрат\n",
      "5583 констатировать\n",
      "5584 легендарный\n",
      "5585 людской\n",
      "5586 люсин\n",
      "5587 обитатель\n",
      "5588 перехватить\n",
      "5589 пожить\n",
      "5590 порция\n",
      "5591 предельный\n",
      "5592 растерянно\n",
      "5593 секция\n",
      "5594 старец\n",
      "5595 стукнуть\n",
      "5596 угодить\n",
      "5597 цыган\n",
      "5598 шерсть\n",
      "5599 ясность\n",
      "5600 бывало\n",
      "5601 вал\n",
      "5602 вмешаться\n",
      "5603 вытереть\n",
      "5604 грамота\n",
      "5605 девяносто\n",
      "5606 доброта\n",
      "5607 документация\n",
      "5608 единственно\n",
      "5609 занятость\n",
      "5610 здравый\n",
      "5611 коляска\n",
      "5612 консерватория\n",
      "5613 насквозь\n",
      "5614 обнаружиться\n",
      "5615 органический\n",
      "5616 очутиться\n",
      "5617 порошок\n",
      "5618 порядочный\n",
      "5619 преступность\n",
      "5620 прикладной\n",
      "5621 примитивный\n",
      "5622 размах\n",
      "5623 расстрел\n",
      "5624 растительный\n",
      "5625 рвануть\n",
      "5626 составление\n",
      "5627 труппа\n",
      "5628 уплата\n",
      "5629 фашист\n",
      "5630 чайный\n",
      "5631 экономист\n",
      "5632 алмаз\n",
      "5633 влезть\n",
      "5634 возрастной\n",
      "5635 воровать\n",
      "5636 восхищаться\n",
      "5637 высказаться\n",
      "5638 долгосрочный\n",
      "5639 замечательно\n",
      "5640 изменяться\n",
      "5641 интервал\n",
      "5642 купе\n",
      "5643 литр\n",
      "5644 лысый\n",
      "5645 минус\n",
      "5646 обозначать\n",
      "5647 обряд\n",
      "5648 обслуживать\n",
      "5649 отныне\n",
      "5650 переворот\n",
      "5651 поворачивать\n",
      "5652 поклониться\n",
      "5653 поляк\n",
      "5654 помереть\n",
      "5655 предчувствие\n",
      "5656 причинить\n",
      "5657 провинциальный\n",
      "5658 смертельный\n",
      "5659 тупик\n",
      "5660 упаковка\n",
      "5661 футбольный\n",
      "5662 хрупкий\n",
      "5663 экспозиция\n",
      "5664 выпивать\n",
      "5665 дернуть\n",
      "5666 дракон\n",
      "5667 ежегодный\n",
      "5668 жаждать\n",
      "5669 заехать\n",
      "5670 импорт\n",
      "5671 инфляция\n",
      "5672 колоссальный\n",
      "5673 мыло\n",
      "5674 налогообложение\n",
      "5675 недоверие\n",
      "5676 останавливать\n",
      "5677 отчаянно\n",
      "5678 панель\n",
      "5679 подводить\n",
      "5680 разочарование\n",
      "5681 сколь\n",
      "5682 соединять\n",
      "5683 сюрприз\n",
      "5684 тропа\n",
      "5685 упираться\n",
      "5686 хвалить\n",
      "5687 беженец\n",
      "5688 вероятный\n",
      "5689 в-третьих\n",
      "5690 досада\n",
      "5691 древесина\n",
      "5692 запасной\n",
      "5693 издержки\n",
      "5694 коммуникация\n",
      "5695 любовница\n",
      "5696 модуль\n",
      "5697 нетерпение\n",
      "5698 обманывать\n",
      "5699 отразить\n",
      "5700 парадный\n",
      "5701 певица\n",
      "5702 питерский\n",
      "5703 подобие\n",
      "5704 поединок\n",
      "5705 прогрессивный\n",
      "5706 пятьсот\n",
      "5707 рельс\n",
      "5708 святитель\n",
      "5709 сжимать\n",
      "5710 участковый\n",
      "5711 яд\n",
      "5712 видимый\n",
      "5713 вмешиваться\n",
      "5714 внучка\n",
      "5715 горожанин\n",
      "5716 дилер\n",
      "5717 желающий\n",
      "5718 кое-как\n",
      "5719 кое-какой\n",
      "5720 кооператив\n",
      "5721 кружиться\n",
      "5722 митинг\n",
      "5723 моделирование\n",
      "5724 наложить\n",
      "5725 обложка\n",
      "5726 обоснование\n",
      "5727 организованный\n",
      "5728 парадокс\n",
      "5729 пограничный\n",
      "5730 прописать\n",
      "5731 ресница\n",
      "5732 рождество\n",
      "5733 сугубо\n",
      "5734 трижды\n",
      "5735 удостоверение\n",
      "5736 улучшить\n",
      "5737 ухаживать\n",
      "5738 ферма\n",
      "5739 формально\n",
      "5740 вице-премьер\n",
      "5741 временно\n",
      "5742 горка\n",
      "5743 горшок\n",
      "5744 декларация\n",
      "5745 декоративный\n",
      "5746 дизайнер\n",
      "5747 добровольный\n",
      "5748 добывать\n",
      "5749 дрогнуть\n",
      "5750 звенеть\n",
      "5751 каблук\n",
      "5752 кассета\n",
      "5753 латинский\n",
      "5754 микрофон\n",
      "5755 недовольство\n",
      "5756 недоступный\n",
      "5757 ниже\n",
      "5758 оглядеться\n",
      "5759 ограничиваться\n",
      "5760 ожидаться\n",
      "5761 осмотр\n",
      "5762 отклонение\n",
      "5763 паника\n",
      "5764 пирог\n",
      "5765 пожелание\n",
      "5766 познакомить\n",
      "5767 поистине\n",
      "5768 походка\n",
      "5769 почерк\n",
      "5770 равенство\n",
      "5771 рекорд\n",
      "5772 сознавать\n",
      "5773 сталь\n",
      "5774 табак\n",
      "5775 тяга\n",
      "5776 чересчур\n",
      "5777 шоу\n",
      "5778 вправду\n",
      "5779 грузовой\n",
      "5780 заменять\n",
      "5781 запеть\n",
      "5782 зрительный\n",
      "5783 коза\n",
      "5784 монолог\n",
      "5785 небрежно\n",
      "5786 ниша\n",
      "5787 овладеть\n",
      "5788 параллельный\n",
      "5789 побеждать\n",
      "5790 почка\n",
      "5791 предъявлять\n",
      "5792 препятствовать\n",
      "5793 пятерка\n",
      "5794 раскрывать\n",
      "5795 свод\n",
      "5796 смотреться\n",
      "5797 сознательный\n",
      "5798 страстный\n",
      "5799 тварь\n",
      "5800 увлекаться\n",
      "5801 умственный\n",
      "5802 бетонный\n",
      "5803 выдумать\n",
      "5804 душ\n",
      "5805 заготовка\n",
      "5806 залив\n",
      "5807 зло\n",
      "5808 испуг\n",
      "5809 конвенция\n",
      "5810 медсестра\n",
      "5811 мрак\n",
      "5812 мундир\n",
      "5813 напугать\n",
      "5814 нарезать\n",
      "5815 обстоять\n",
      "5816 ответный\n",
      "5817 писаться\n",
      "5818 погрузить\n",
      "5819 пузырь\n",
      "5820 расходиться\n",
      "5821 рыбный\n",
      "5822 связаться\n",
      "5823 статуя\n",
      "5824 тысячелетие\n",
      "5825 удобство\n",
      "5826 усилить\n",
      "5827 аллея\n",
      "5828 бездна\n",
      "5829 величество\n",
      "5830 ветхий\n",
      "5831 вилка\n",
      "5832 гул\n",
      "5833 иерархия\n",
      "5834 кое-кто\n",
      "5835 компетенция\n",
      "5836 лунный\n",
      "5837 матушка\n",
      "5838 молоденький\n",
      "5839 напиться\n",
      "5840 нелегкий\n",
      "5841 неудачный\n",
      "5842 ничтожный\n",
      "5843 оплатить\n",
      "5844 оппонент\n",
      "5845 отдаленный\n",
      "5846 петух\n",
      "5847 пик\n",
      "5848 пирамида\n",
      "5849 поведать\n",
      "5850 покойник\n",
      "5851 поручик\n",
      "5852 последовательный\n",
      "5853 противостояние\n",
      "5854 разбирательство\n",
      "5855 рожа\n",
      "5856 руда\n",
      "5857 связка\n",
      "5858 так-то\n",
      "5859 уничтожать\n",
      "5860 урегулирование\n",
      "5861 фирменный\n",
      "5862 фокус\n",
      "5863 шить\n",
      "5864 экспертный\n",
      "5865 абстрактный\n",
      "5866 агрессивный\n",
      "5867 аналог\n",
      "5868 вторичный\n",
      "5869 занавес\n",
      "5870 запросто\n",
      "5871 знаток\n",
      "5872 кастрюля\n",
      "5873 коли\n",
      "5874 концерн\n",
      "5875 мат\n",
      "5876 монополия\n",
      "5877 накануне\n",
      "5878 насаждение\n",
      "5879 оборонный\n",
      "5880 оборудовать\n",
      "5881 персональный\n",
      "5882 показ\n",
      "5883 пол\n",
      "5884 портить\n",
      "5885 послевоенный\n",
      "5886 продолжительность\n",
      "5887 проработать\n",
      "5888 резолюция\n",
      "5889 снижаться\n",
      "5890 стимулировать\n",
      "5891 сходиться\n",
      "5892 творец\n",
      "5893 уменьшить\n",
      "5894 щелкнуть\n",
      "5895 блаженный\n",
      "5896 вцепиться\n",
      "5897 вывезти\n",
      "5898 глоток\n",
      "5899 едва\n",
      "5900 жадно\n",
      "5901 жестокость\n",
      "5902 заключать\n",
      "5903 колокол\n",
      "5904 лекарственный\n",
      "5905 мерседес\n",
      "5906 овраг\n",
      "5907 ответчик\n",
      "5908 племянник\n",
      "5909 повиснуть\n",
      "5910 подозрительный\n",
      "5911 поздороваться\n",
      "5912 сказочный\n",
      "5913 столовый\n",
      "5914 шестнадцать\n",
      "5915 экскурсия\n",
      "5916 алюминиевый\n",
      "5917 барабан\n",
      "5918 беременность\n",
      "5919 верхушка\n",
      "5920 виза\n",
      "5921 возмещение\n",
      "5922 ворваться\n",
      "5923 выстрелить\n",
      "5924 гибкий\n",
      "5925 гонщик\n",
      "5926 гроза\n",
      "5927 забраться\n",
      "5928 заданный\n",
      "5929 занавеска\n",
      "5930 интенсивность\n",
      "5931 капитальный\n",
      "5932 кристалл\n",
      "5933 металлургический\n",
      "5934 опять-таки\n",
      "5935 орех\n",
      "5936 отстаивать\n",
      "5937 песенка\n",
      "5938 полюс\n",
      "5939 принцесса\n",
      "5940 проезд\n",
      "5941 разложить\n",
      "5942 русло\n",
      "5943 скользить\n",
      "5944 справедливо\n",
      "5945 тепловой\n",
      "5946 утрата\n",
      "5947 электричка\n",
      "5948 администратор\n",
      "5949 благополучный\n",
      "5950 будка\n",
      "5951 верста\n",
      "5952 граната\n",
      "5953 да-да\n",
      "5954 дева\n",
      "5955 заговор\n",
      "5956 застрять\n",
      "5957 известность\n",
      "5958 изобрести\n",
      "5959 интимный\n",
      "5960 материнский\n",
      "5961 мучительно\n",
      "5962 неважно\n",
      "5963 незадолго\n",
      "5964 ненадолго\n",
      "5965 обновление\n",
      "5966 окрестность\n",
      "5967 олень\n",
      "5968 оправдание\n",
      "5969 оранжевый\n",
      "5970 отвергнуть\n",
      "5971 относить\n",
      "5972 пена\n",
      "5973 писание\n",
      "5974 помниться\n",
      "5975 приближение\n",
      "5976 приоткрыть\n",
      "5977 прозвище\n",
      "5978 прохождение\n",
      "5979 рыдать\n",
      "5980 сдаться\n",
      "5981 слыхать\n",
      "5982 соленый\n",
      "5983 стража\n",
      "5984 теряться\n",
      "5985 толкование\n",
      "5986 шок\n",
      "5987 бухгалтер\n",
      "5988 ввод\n",
      "5989 возвратиться\n",
      "5990 возложить\n",
      "5991 вплотную\n",
      "5992 вытирать\n",
      "5993 догадка\n",
      "5994 зенитный\n",
      "5995 икра\n",
      "5996 кличка\n",
      "5997 комментировать\n",
      "5998 континент\n",
      "5999 линейный\n",
      "6000 модификация\n",
      "6001 напасть\n",
      "6002 наполовину\n",
      "6003 настойчиво\n",
      "6004 подписывать\n",
      "6005 поздравить\n",
      "6006 покрывать\n",
      "6007 роскошь\n",
      "6008 рубка\n",
      "6009 рыбка\n",
      "6010 сокровище\n",
      "6011 сработать\n",
      "6012 твердить\n",
      "6013 ткнуть\n",
      "6014 тропинка\n",
      "6015 трусы\n",
      "6016 формат\n",
      "6017 белорусский\n",
      "6018 биология\n",
      "6019 босой\n",
      "6020 ежедневный\n",
      "6021 зам\n",
      "6022 катиться\n",
      "6023 красавец\n",
      "6024 кушать\n",
      "6025 новинка\n",
      "6026 поднести\n",
      "6027 помидор\n",
      "6028 попрощаться\n",
      "6029 прическа\n",
      "6030 пустынный\n",
      "6031 рецензия\n",
      "6032 рубить\n",
      "6033 салат\n",
      "6034 терпеливо\n",
      "6035 хоронить\n",
      "6036 экономия\n",
      "6037 эстрада\n",
      "6038 аппетит\n",
      "6039 банда\n",
      "6040 борец\n",
      "6041 вылезать\n",
      "6042 интуиция\n",
      "6043 контур\n",
      "6044 маневр\n",
      "6045 мрачно\n",
      "6046 мучиться\n",
      "6047 наткнуться\n",
      "6048 обрыв\n",
      "6049 огненный\n",
      "6050 отделить\n",
      "6051 отметка\n",
      "6052 привыкать\n",
      "6053 проживание\n",
      "6054 разрез\n",
      "6055 разрушать\n",
      "6056 реветь\n",
      "6057 ревность\n",
      "6058 скакать\n",
      "6059 сотрудничать\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6060 сражаться\n",
      "6061 теракт\n",
      "6062 уронить\n",
      "6063 фуражка\n",
      "6064 хохот\n",
      "6065 шелковый\n",
      "6066 шина\n",
      "6067 больничный\n",
      "6068 бронзовый\n",
      "6069 валенок\n",
      "6070 ввиду\n",
      "6071 вертеться\n",
      "6072 всяческий\n",
      "6073 выкинуть\n",
      "6074 выходной\n",
      "6075 диагностика\n",
      "6076 заблуждение\n",
      "6077 заводской\n",
      "6078 заповедь\n",
      "6079 излишний\n",
      "6080 каникулы\n",
      "6081 комар\n",
      "6082 контейнер\n",
      "6083 координата\n",
      "6084 лопнуть\n",
      "6085 люк\n",
      "6086 майка\n",
      "6087 нары\n",
      "6088 небось\n",
      "6089 неправильно\n",
      "6090 отработать\n",
      "6091 парус\n",
      "6092 перец\n",
      "6093 пират\n",
      "6094 пластиковый\n",
      "6095 презирать\n",
      "6096 прибежать\n",
      "6097 расположиться\n",
      "6098 родительский\n",
      "6099 сбегать\n",
      "6100 сегмент\n",
      "6101 скромно\n",
      "6102 смущать\n",
      "6103 снизиться\n",
      "6104 стенд\n",
      "6105 тигр\n",
      "6106 убедительный\n",
      "6107 удивлять\n",
      "6108 упоминаться\n",
      "6109 устранение\n",
      "6110 аптека\n",
      "6111 бак\n",
      "6112 безумие\n",
      "6113 будить\n",
      "6114 вздрагивать\n",
      "6115 дежурство\n",
      "6116 залезть\n",
      "6117 ислам\n",
      "6118 кирпичный\n",
      "6119 кустарник\n",
      "6120 мертвый\n",
      "6121 мониторинг\n",
      "6122 ограничивать\n",
      "6123 отводить\n",
      "6124 откровение\n",
      "6125 оцениваться\n",
      "6126 павильон\n",
      "6127 подчиненный\n",
      "6128 помещаться\n",
      "6129 поплыть\n",
      "6130 проводник\n",
      "6131 пространственный\n",
      "6132 проявиться\n",
      "6133 ранение\n",
      "6134 санкция\n",
      "6135 серебро\n",
      "6136 составляющая\n",
      "6137 спустить\n",
      "6138 схватиться\n",
      "6139 табличка\n",
      "6140 тоненький\n",
      "6141 уделять\n",
      "6142 валить\n",
      "6143 взлететь\n",
      "6144 внушать\n",
      "6145 глупо\n",
      "6146 грядущий\n",
      "6147 ежели\n",
      "6148 закуска\n",
      "6149 календарь\n",
      "6150 командный\n",
      "6151 кулиса\n",
      "6152 мирно\n",
      "6153 неторопливо\n",
      "6154 опомниться\n",
      "6155 орбита\n",
      "6156 очистка\n",
      "6157 подмосковный\n",
      "6158 просвещение\n",
      "6159 публиковать\n",
      "6160 расписание\n",
      "6161 свитер\n",
      "6162 сотворить\n",
      "6163 сравнительный\n",
      "6164 сходный\n",
      "6165 терраса\n",
      "6166 укол\n",
      "6167 упрек\n",
      "6168 холдинг\n",
      "6169 цепляться\n",
      "6170 эхо\n",
      "6171 атаковать\n",
      "6172 беременный\n",
      "6173 грамотный\n",
      "6174 грусть\n",
      "6175 достоверный\n",
      "6176 злиться\n",
      "6177 количественный\n",
      "6178 конструктивный\n",
      "6179 лебедь\n",
      "6180 наводить\n",
      "6181 немногий\n",
      "6182 оправдываться\n",
      "6183 отделять\n",
      "6184 первое\n",
      "6185 поставлять\n",
      "6186 пошутить\n",
      "6187 прекратиться\n",
      "6188 призрак\n",
      "6189 работодатель\n",
      "6190 разработчик\n",
      "6191 репетировать\n",
      "6192 ритуал\n",
      "6193 сказываться\n",
      "6194 склониться\n",
      "6195 стая\n",
      "6196 схватка\n",
      "6197 террор\n",
      "6198 тревожить\n",
      "6199 ударный\n",
      "6200 упереться\n",
      "6201 хутор\n",
      "6202 биржа\n",
      "6203 взыскание\n",
      "6204 вице-президент\n",
      "6205 героический\n",
      "6206 гимн\n",
      "6207 диктовать\n",
      "6208 дремать\n",
      "6209 задержка\n",
      "6210 зарасти\n",
      "6211 исток\n",
      "6212 критиковать\n",
      "6213 лишать\n",
      "6214 мощь\n",
      "6215 налет\n",
      "6216 научно-технический\n",
      "6217 носиться\n",
      "6218 обречь\n",
      "6219 обрушиться\n",
      "6220 ограничиться\n",
      "6221 одеться\n",
      "6222 пересмотр\n",
      "6223 пионер\n",
      "6224 подставить\n",
      "6225 подчинить\n",
      "6226 прижимать\n",
      "6227 припомнить\n",
      "6228 путать\n",
      "6229 сократиться\n",
      "6230 сонный\n",
      "6231 сытый\n",
      "6232 увлечь\n",
      "6233 удаляться\n",
      "6234 бал\n",
      "6235 братец\n",
      "6236 виднеться\n",
      "6237 всячески\n",
      "6238 грек\n",
      "6239 губерния\n",
      "6240 джип\n",
      "6241 дирижер\n",
      "6242 железа\n",
      "6243 загнать\n",
      "6244 запланировать\n",
      "6245 инспекция\n",
      "6246 итальянец\n",
      "6247 неповторимый\n",
      "6248 новичок\n",
      "6249 обладатель\n",
      "6250 обочина\n",
      "6251 окоп\n",
      "6252 перебраться\n",
      "6253 плясать\n",
      "6254 побережье\n",
      "6255 погибать\n",
      "6256 поперечный\n",
      "6257 постигнуть\n",
      "6258 предвидеть\n",
      "6259 приемная\n",
      "6260 прихватить\n",
      "6261 пробежать\n",
      "6262 прорыв\n",
      "6263 разбитый\n",
      "6264 руководящий\n",
      "6265 семнадцать\n",
      "6266 смутиться\n",
      "6267 совпасть\n",
      "6268 тормоз\n",
      "6269 фасад\n",
      "6270 чувствительный\n",
      "6271 аналогия\n",
      "6272 бережно\n",
      "6273 бодрый\n",
      "6274 буржуазный\n",
      "6275 восстание\n",
      "6276 вырастать\n",
      "6277 дерьмо\n",
      "6278 добровольно\n",
      "6279 допустимый\n",
      "6280 истец\n",
      "6281 космонавт\n",
      "6282 кухонный\n",
      "6283 маг\n",
      "6284 моментально\n",
      "6285 наливать\n",
      "6286 пошлина\n",
      "6287 пытка\n",
      "6288 ржавый\n",
      "6289 сервис\n",
      "6290 скамья\n",
      "6291 смелость\n",
      "6292 стремительный\n",
      "6293 табуретка\n",
      "6294 тост\n",
      "6295 турок\n",
      "6296 тусклый\n",
      "6297 ура\n",
      "6298 фильтр\n",
      "6299 хлопоты\n",
      "6300 античный\n",
      "6301 ассортимент\n",
      "6302 возмущаться\n",
      "6303 воробей\n",
      "6304 высказывать\n",
      "6305 вяло\n",
      "6306 гимназия\n",
      "6307 гонять\n",
      "6308 донести\n",
      "6309 загрязнение\n",
      "6310 заказывать\n",
      "6311 зачем-то\n",
      "6312 котенок\n",
      "6313 мистер\n",
      "6314 много\n",
      "6315 научно-исследовательский\n",
      "6316 невыносимый\n",
      "6317 негр\n",
      "6318 нервно\n",
      "6319 низко\n",
      "6320 оборвать\n",
      "6321 пехота\n",
      "6322 плавно\n",
      "6323 презрение\n",
      "6324 преодолевать\n",
      "6325 претендент\n",
      "6326 прирост\n",
      "6327 присвоить\n",
      "6328 ребятишки\n",
      "6329 сварить\n",
      "6330 сдвинуть\n",
      "6331 согласовать\n",
      "6332 стон\n",
      "6333 сухо\n",
      "6334 треугольник\n",
      "6335 тридцатый\n",
      "6336 трудящийся\n",
      "6337 увлечься\n",
      "6338 удовлетворять\n",
      "6339 участь\n",
      "6340 альтернатива\n",
      "6341 анкета\n",
      "6342 безнадежный\n",
      "6343 бутерброд\n",
      "6344 возмущение\n",
      "6345 выбрасывать\n",
      "6346 выучить\n",
      "6347 гепатит\n",
      "6348 грудной\n",
      "6349 доехать\n",
      "6350 интеллект\n",
      "6351 невероятно\n",
      "6352 отразиться\n",
      "6353 переходный\n",
      "6354 писательский\n",
      "6355 погаснуть\n",
      "6356 подчас\n",
      "6357 последовательно\n",
      "6358 предательство\n",
      "6359 пристально\n",
      "6360 промысел\n",
      "6361 райком\n",
      "6362 сало\n",
      "6363 снести\n",
      "6364 сторож\n",
      "6365 террористический\n",
      "6366 уменьшаться\n",
      "6367 человечек\n",
      "6368 ваза\n",
      "6369 виртуальный\n",
      "6370 включаться\n",
      "6371 волокно\n",
      "6372 грузин\n",
      "6373 двигать\n",
      "6374 игла\n",
      "6375 курсант\n",
      "6376 магический\n",
      "6377 магнитофон\n",
      "6378 однозначно\n",
      "6379 определиться\n",
      "6380 оскорбить\n",
      "6381 отзываться\n",
      "6382 пальма\n",
      "6383 позабыть\n",
      "6384 прислушаться\n",
      "6385 притом\n",
      "6386 символический\n",
      "6387 складка\n",
      "6388 социологический\n",
      "6389 спохватиться\n",
      "6390 сумочка\n",
      "6391 теща\n",
      "6392 уставать\n",
      "6393 хронический\n",
      "6394 цифровой\n",
      "6395 шедевр\n",
      "6396 этика\n",
      "6397 юстиция\n",
      "6398 бес\n",
      "6399 веселье\n",
      "6400 весы\n",
      "6401 виски\n",
      "6402 гибнуть\n",
      "6403 живо\n",
      "6404 жрать\n",
      "6405 замкнутый\n",
      "6406 изъять\n",
      "6407 исчезновение\n",
      "6408 назначать\n",
      "6409 неподвижно\n",
      "6410 обком\n",
      "6411 объективно\n",
      "6412 оперный\n",
      "6413 оплачивать\n",
      "6414 персона\n",
      "6415 полярный\n",
      "6416 поморщиться\n",
      "6417 правосудие\n",
      "6418 предпосылка\n",
      "6419 проститутка\n",
      "6420 прочно\n",
      "6421 равнодушно\n",
      "6422 реализоваться\n",
      "6423 речной\n",
      "6424 рожать\n",
      "6425 тактический\n",
      "6426 торг\n",
      "6427 троллейбус\n",
      "6428 фигурка\n",
      "6429 четырнадцать\n",
      "6430 взорваться\n",
      "6431 влага\n",
      "6432 густо\n",
      "6433 деление\n",
      "6434 жечь\n",
      "6435 житейский\n",
      "6436 завтрашний\n",
      "6437 закрыться\n",
      "6438 закупка\n",
      "6439 извиняться\n",
      "6440 листва\n",
      "6441 ложа\n",
      "6442 массивный\n",
      "6443 мусульманин\n",
      "6444 низ\n",
      "6445 новое\n",
      "6446 ознакомиться\n",
      "6447 оправдывать\n",
      "6448 определенно\n",
      "6449 осуждать\n",
      "6450 партизан\n",
      "6451 повториться\n",
      "6452 подписание\n",
      "6453 проглотить\n",
      "6454 проповедь\n",
      "6455 публично\n",
      "6456 размахивать\n",
      "6457 сеанс\n",
      "6458 слияние\n",
      "6459 слушаться\n",
      "6460 совхоз\n",
      "6461 сустав\n",
      "6462 уборка\n",
      "6463 удельный\n",
      "6464 упоминание\n",
      "6465 хмыкнуть\n",
      "6466 шведский\n",
      "6467 экзотический\n",
      "6468 бессмертный\n",
      "6469 бесчисленный\n",
      "6470 болтаться\n",
      "6471 бомж\n",
      "6472 влиятельный\n",
      "6473 выраженный\n",
      "6474 динамический\n",
      "6475 завязать\n",
      "6476 законодатель\n",
      "6477 качаться\n",
      "6478 мистический\n",
      "6479 мэрия\n",
      "6480 неприятно\n",
      "6481 отрывок\n",
      "6482 палач\n",
      "6483 первенство\n",
      "6484 побить\n",
      "6485 показательный\n",
      "6486 покров\n",
      "6487 порвать\n",
      "6488 предстать\n",
      "6489 предшественник\n",
      "6490 развить\n",
      "6491 разгар\n",
      "6492 смешанный\n",
      "6493 угрюмый\n",
      "6494 удалиться\n",
      "6495 условно\n",
      "6496 функционировать\n",
      "6497 шумно\n",
      "6498 шут\n",
      "6499 водоем\n",
      "6500 вспоминаться\n",
      "6501 выигрывать\n",
      "6502 география\n",
      "6503 измена\n",
      "6504 инструктор\n",
      "6505 каталог\n",
      "6506 клоун\n",
      "6507 локомотив\n",
      "6508 нахмуриться\n",
      "6509 нахождение\n",
      "6510 непривычный\n",
      "6511 облигация\n",
      "6512 отодвинуть\n",
      "6513 отраслевой\n",
      "6514 переезд\n",
      "6515 подбор\n",
      "6516 подразумевать\n",
      "6517 покоситься\n",
      "6518 пополам\n",
      "6519 превосходить\n",
      "6520 приемный\n",
      "6521 присниться\n",
      "6522 провозгласить\n",
      "6523 раковина\n",
      "6524 расслабиться\n",
      "6525 расстегнуть\n",
      "6526 рассыпаться\n",
      "6527 связываться\n",
      "6528 скидка\n",
      "6529 смириться\n",
      "6530 такт\n",
      "6531 темнеть\n",
      "6532 треск\n",
      "6533 уральский\n",
      "6534 башка\n",
      "6535 вспомниться\n",
      "6536 выбежать\n",
      "6537 глубинный\n",
      "6538 замирать\n",
      "6539 иллюстрация\n",
      "6540 истерика\n",
      "6541 лишенный\n",
      "6542 намекать\n",
      "6543 населенный\n",
      "6544 нижегородский\n",
      "6545 общность\n",
      "6546 оптимизация\n",
      "6547 отрываться\n",
      "6548 отцовский\n",
      "6549 очаровательный\n",
      "6550 погубить\n",
      "6551 преданный\n",
      "6552 принудительный\n",
      "6553 репрессия\n",
      "6554 скрипеть\n",
      "6555 сочетаться\n",
      "6556 сплав\n",
      "6557 ссора\n",
      "6558 стирать\n",
      "6559 струна\n",
      "6560 тронуться\n",
      "6561 укладываться\n",
      "6562 утешать\n",
      "6563 шепотом\n",
      "6564 артиллерия\n",
      "6565 библия\n",
      "6566 взорвать\n",
      "6567 втроем\n",
      "6568 выглянуть\n",
      "6569 голубь\n",
      "6570 желательно\n",
      "6571 задолго\n",
      "6572 запуск\n",
      "6573 медик\n",
      "6574 наставник\n",
      "6575 отбирать\n",
      "6576 поискать\n",
      "6577 полигон\n",
      "6578 превысить\n",
      "6579 предметный\n",
      "6580 продавщица\n",
      "6581 просидеть\n",
      "6582 сливаться\n",
      "6583 соратник\n",
      "6584 спонсор\n",
      "6585 трогательный\n",
      "6586 унижение\n",
      "6587 устареть\n",
      "6588 банальный\n",
      "6589 бухгалтерский\n",
      "6590 вознаграждение\n",
      "6591 вообразить\n",
      "6592 враждебный\n",
      "6593 вымыть\n",
      "6594 вытаскивать\n",
      "6595 гусь\n",
      "6596 давность\n",
      "6597 заветный\n",
      "6598 заграничный\n",
      "6599 насос\n",
      "6600 обломок\n",
      "6601 обучать\n",
      "6602 перепись\n",
      "6603 подавить\n",
      "6604 потрясение\n",
      "6605 проанализировать\n",
      "6606 продумать\n",
      "6607 проследить\n",
      "6608 прошлогодний\n",
      "6609 птичий\n",
      "6610 раздумье\n",
      "6611 рев\n",
      "6612 розничный\n",
      "6613 сияние\n",
      "6614 склонить\n",
      "6615 скука\n",
      "6616 старина\n",
      "6617 удаление\n",
      "6618 удалить\n",
      "6619 факс\n",
      "6620 целоваться\n",
      "6621 чепуха\n",
      "6622 шкала\n",
      "6623 адмирал\n",
      "6624 арена\n",
      "6625 беспомощный\n",
      "6626 веранда\n",
      "6627 вспыхивать\n",
      "6628 выгодно\n",
      "6629 вырастить\n",
      "6630 гадать\n",
      "6631 господний\n",
      "6632 дачный\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6633 донестись\n",
      "6634 дробный\n",
      "6635 думский\n",
      "6636 затянуть\n",
      "6637 земляк\n",
      "6638 издатель\n",
      "6639 имидж\n",
      "6640 комсомол\n",
      "6641 конкурсный\n",
      "6642 крошка\n",
      "6643 ласка\n",
      "6644 ленивый\n",
      "6645 масштабный\n",
      "6646 набраться\n",
      "6647 нехорошо\n",
      "6648 обижать\n",
      "6649 обозначение\n",
      "6650 обретать\n",
      "6651 погасить\n",
      "6652 погулять\n",
      "6653 податься\n",
      "6654 подбежать\n",
      "6655 подмигнуть\n",
      "6656 подсказывать\n",
      "6657 подсудимый\n",
      "6658 пожаловаться\n",
      "6659 поп\n",
      "6660 приемлемый\n",
      "6661 прорваться\n",
      "6662 профилактика\n",
      "6663 разбросать\n",
      "6664 рассердиться\n",
      "6665 сильнейший\n",
      "6666 стонать\n",
      "6667 судопроизводство\n",
      "6668 титул\n",
      "6669 угольный\n",
      "6670 всадник\n",
      "6671 выдаваться\n",
      "6672 даром\n",
      "6673 затеять\n",
      "6674 казарма\n",
      "6675 киоск\n",
      "6676 лирический\n",
      "6677 любопытно\n",
      "6678 матрица\n",
      "6679 оптический\n",
      "6680 освещать\n",
      "6681 памятный\n",
      "6682 перекресток\n",
      "6683 пересечь\n",
      "6684 понемногу\n",
      "6685 посылка\n",
      "6686 прах\n",
      "6687 распоряжаться\n",
      "6688 свалить\n",
      "6689 складывать\n",
      "6690 скульптор\n",
      "6691 таз\n",
      "6692 чердак\n",
      "6693 эмигрант\n",
      "6694 ярмарка\n",
      "6695 араб\n",
      "6696 армянский\n",
      "6697 бедствие\n",
      "6698 безнадежно\n",
      "6699 вложение\n",
      "6700 влюбить\n",
      "6701 впадать\n",
      "6702 впереди\n",
      "6703 выяснять\n",
      "6704 генштаб\n",
      "6705 гонорар\n",
      "6706 доводить\n",
      "6707 драматург\n",
      "6708 емкость\n",
      "6709 живописный\n",
      "6710 кое-где\n",
      "6711 консультант\n",
      "6712 круто\n",
      "6713 лениво\n",
      "6714 любезный\n",
      "6715 око\n",
      "6716 отказывать\n",
      "6717 парадоксальный\n",
      "6718 парта\n",
      "6719 по-английски\n",
      "6720 повар\n",
      "6721 розыск\n",
      "6722 стаж\n",
      "6723 стебель\n",
      "6724 типовой\n",
      "6725 фальшивый\n",
      "6726 ходатайство\n",
      "6727 алый\n",
      "6728 амбиция\n",
      "6729 дворник\n",
      "6730 дорого\n",
      "6731 дошкольный\n",
      "6732 затея\n",
      "6733 калужский\n",
      "6734 копать\n",
      "6735 косметика\n",
      "6736 кредитование\n",
      "6737 массив\n",
      "6738 менеджмент\n",
      "6739 мраморный\n",
      "6740 наизусть\n",
      "6741 налогоплательщик\n",
      "6742 некрасивый\n",
      "6743 оптимизм\n",
      "6744 основываться\n",
      "6745 парад\n",
      "6746 патриот\n",
      "6747 передвижение\n",
      "6748 периодически\n",
      "6749 питать\n",
      "6750 подсчет\n",
      "6751 покачиваться\n",
      "6752 поклон\n",
      "6753 превосходство\n",
      "6754 пресловутый\n",
      "6755 проголосовать\n",
      "6756 путешествовать\n",
      "6757 пучок\n",
      "6758 разбиться\n",
      "6759 расширяться\n",
      "6760 соблазн\n",
      "6761 совать\n",
      "6762 усмешка\n",
      "6763 устранить\n",
      "6764 шлем\n",
      "6765 агрессия\n",
      "6766 балл\n",
      "6767 банкир\n",
      "6768 барышня\n",
      "6769 возвести\n",
      "6770 вращаться\n",
      "6771 газон\n",
      "6772 групповой\n",
      "6773 двусторонний\n",
      "6774 дружный\n",
      "6775 жюри\n",
      "6776 мех\n",
      "6777 миграция\n",
      "6778 нелегко\n",
      "6779 нищета\n",
      "6780 нора\n",
      "6781 обосновать\n",
      "6782 освобождать\n",
      "6783 остынуть\n",
      "6784 отпечаток\n",
      "6785 повторный\n",
      "6786 погибший\n",
      "6787 посредник\n",
      "6788 пристрастие\n",
      "6789 проектный\n",
      "6790 пятка\n",
      "6791 разворачиваться\n",
      "6792 сейф\n",
      "6793 словесный\n",
      "6794 сосредоточиться\n",
      "6795 сшить\n",
      "6796 утка\n",
      "6797 утонуть\n",
      "6798 шикарный\n",
      "6799 буркнуть\n",
      "6800 взволновать\n",
      "6801 достоверность\n",
      "6802 забегать\n",
      "6803 заражение\n",
      "6804 зрелый\n",
      "6805 изложение\n",
      "6806 имущественный\n",
      "6807 крона\n",
      "6808 лига\n",
      "6809 математик\n",
      "6810 механик\n",
      "6811 накормить\n",
      "6812 неопределенный\n",
      "6813 норовить\n",
      "6814 обвиняемый\n",
      "6815 обитать\n",
      "6816 ожить\n",
      "6817 опаздывать\n",
      "6818 отреагировать\n",
      "6819 отступление\n",
      "6820 первоначально\n",
      "6821 песчаный\n",
      "6822 погрузиться\n",
      "6823 помеха\n",
      "6824 послушно\n",
      "6825 презентация\n",
      "6826 прикосновение\n",
      "6827 промежуток\n",
      "6828 равно\n",
      "6829 растерянность\n",
      "6830 синяк\n",
      "6831 современность\n",
      "6832 усадить\n",
      "6833 цензура\n",
      "6834 энциклопедия\n",
      "6835 арка\n",
      "6836 варенье\n",
      "6837 вблизи\n",
      "6838 вправо\n",
      "6839 гимнастерка\n",
      "6840 дергать\n",
      "6841 дивный\n",
      "6842 заинтересоваться\n",
      "6843 зловещий\n",
      "6844 идейный\n",
      "6845 квалифицированный\n",
      "6846 ловушка\n",
      "6847 мамочка\n",
      "6848 местечко\n",
      "6849 наземный\n",
      "6850 недовольно\n",
      "6851 огневой\n",
      "6852 оперировать\n",
      "6853 осознание\n",
      "6854 ощущаться\n",
      "6855 полость\n",
      "6856 предоставляться\n",
      "6857 предпринимательство\n",
      "6858 престол\n",
      "6859 примечание\n",
      "6860 просмотр\n",
      "6861 противно\n",
      "6862 различаться\n",
      "6863 разрешаться\n",
      "6864 рывок\n",
      "6865 сериал\n",
      "6866 таки\n",
      "6867 умело\n",
      "6868 устало\n",
      "6869 устраиваться\n",
      "6870 фиксировать\n",
      "6871 чертов\n",
      "6872 числиться\n",
      "6873 благодать\n",
      "6874 блин\n",
      "6875 блокнот\n",
      "6876 вдохновение\n",
      "6877 вежливый\n",
      "6878 вектор\n",
      "6879 взлет\n",
      "6880 влюбленный\n",
      "6881 восстанавливать\n",
      "6882 восторженный\n",
      "6883 врезаться\n",
      "6884 документальный\n",
      "6885 закрываться\n",
      "6886 змей\n",
      "6887 зубной\n",
      "6888 игровой\n",
      "6889 исповедь\n",
      "6890 кривая\n",
      "6891 курорт\n",
      "6892 лопатка\n",
      "6893 мерцать\n",
      "6894 надо\n",
      "6895 намереваться\n",
      "6896 нарядный\n",
      "6897 негодяй\n",
      "6898 немолодой\n",
      "6899 оптовый\n",
      "6900 острота\n",
      "6901 отравить\n",
      "6902 пепел\n",
      "6903 порок\n",
      "6904 применительно\n",
      "6905 пробиться\n",
      "6906 произвол\n",
      "6907 птичка\n",
      "6908 робко\n",
      "6909 седло\n",
      "6910 убедительно\n",
      "6911 фара\n",
      "6912 штурм\n",
      "6913 юбилейный\n",
      "6914 арсенал\n",
      "6915 боеприпас\n",
      "6916 болельщик\n",
      "6917 внутренне\n",
      "6918 возвратить\n",
      "6919 въехать\n",
      "6920 вынимать\n",
      "6921 гигант\n",
      "6922 дежурить\n",
      "6923 задница\n",
      "6924 заключительный\n",
      "6925 исламский\n",
      "6926 конкурентный\n",
      "6927 концертный\n",
      "6928 купюра\n",
      "6929 лавочка\n",
      "6930 лик\n",
      "6931 наглый\n",
      "6932 неполный\n",
      "6933 парочка\n",
      "6934 патриотический\n",
      "6935 повествование\n",
      "6936 позади\n",
      "6937 полицейский\n",
      "6938 правота\n",
      "6939 предлог\n",
      "6940 прелестный\n",
      "6941 приоритетный\n",
      "6942 проем\n",
      "6943 развалиться\n",
      "6944 силуэт\n",
      "6945 скатерть\n",
      "6946 смениться\n",
      "6947 туго\n",
      "6948 уступка\n",
      "6949 фашизм\n",
      "6950 фотограф\n",
      "6951 чушь\n",
      "6952 чуять\n",
      "6953 адаптация\n",
      "6954 артиллерийский\n",
      "6955 базироваться\n",
      "6956 бодро\n",
      "6957 ворона\n",
      "6958 глагол\n",
      "6959 глотать\n",
      "6960 глухо\n",
      "6961 дополнительно\n",
      "6962 записной\n",
      "6963 коленка\n",
      "6964 литься\n",
      "6965 машинально\n",
      "6966 медь\n",
      "6967 негде\n",
      "6968 немой\n",
      "6969 необыкновенно\n",
      "6970 неопределенность\n",
      "6971 непрерывно\n",
      "6972 ноздря\n",
      "6973 пассажирский\n",
      "6974 поликлиника\n",
      "6975 прапорщик\n",
      "6976 приспособить\n",
      "6977 рискнуть\n",
      "6978 сани\n",
      "6979 сочувствовать\n",
      "6980 счастливо\n",
      "6981 торговец\n",
      "6982 трансформация\n",
      "6983 тщательный\n",
      "6984 узор\n",
      "6985 чрезмерный\n",
      "6986 аварийный\n",
      "6987 бессильный\n",
      "6988 блондинка\n",
      "6989 бокс\n",
      "6990 влево\n",
      "6991 выживание\n",
      "6992 выслать\n",
      "6993 выхватить\n",
      "6994 галактика\n",
      "6995 динамо\n",
      "6996 дрожь\n",
      "6997 закрытие\n",
      "6998 засунуть\n",
      "6999 исследовательский\n",
      "7000 каюта\n",
      "7001 кишка\n",
      "7002 комендант\n",
      "7003 краснеть\n",
      "7004 купец\n",
      "7005 лондонский\n",
      "7006 невиданный\n",
      "7007 несовершеннолетний\n",
      "7008 осматривать\n",
      "7009 попить\n",
      "7010 противодействие\n",
      "7011 разыскать\n",
      "7012 самостоятельность\n",
      "7013 сдвиг\n",
      "7014 снабдить\n",
      "7015 снятие\n",
      "7016 содержимое\n",
      "7017 сундук\n",
      "7018 теоретически\n",
      "7019 тонуть\n",
      "7020 трубопровод\n",
      "7021 увольнение\n",
      "7022 цилиндр\n",
      "7023 ядовитый\n",
      "7024 выпадать\n",
      "7025 высказываться\n",
      "7026 град\n",
      "7027 дверной\n",
      "7028 доверить\n",
      "7029 европеец\n",
      "7030 заведомо\n",
      "7031 заливать\n",
      "7032 заросль\n",
      "7033 зоопарк\n",
      "7034 избавить\n",
      "7035 избыток\n",
      "7036 колхозный\n",
      "7037 кончина\n",
      "7038 лечиться\n",
      "7039 молоток\n",
      "7040 навестить\n",
      "7041 несправедливый\n",
      "7042 облегчить\n",
      "7043 отбить\n",
      "7044 откладывать\n",
      "7045 охотничий\n",
      "7046 подвижный\n",
      "7047 поселение\n",
      "7048 преследование\n",
      "7049 приветствие\n",
      "7050 приморский\n",
      "7051 респондент\n",
      "7052 свалка\n",
      "7053 спорный\n",
      "7054 старенький\n",
      "7055 стопка\n",
      "7056 стресс\n",
      "7057 теннис\n",
      "7058 тонкость\n",
      "7059 туманный\n",
      "7060 уносить\n",
      "7061 усвоить\n",
      "7062 фиолетовый\n",
      "7063 холл\n",
      "7064 штора\n",
      "7065 ахнуть\n",
      "7066 братский\n",
      "7067 бремя\n",
      "7068 выбираться\n",
      "7069 выставлять\n",
      "7070 гадость\n",
      "7071 дальность\n",
      "7072 жареный\n",
      "7073 забытый\n",
      "7074 заклинание\n",
      "7075 законность\n",
      "7076 захватывать\n",
      "7077 избранный\n",
      "7078 картофель\n",
      "7079 красноярский\n",
      "7080 куриный\n",
      "7081 лад\n",
      "7082 мамаша\n",
      "7083 наделить\n",
      "7084 неудобный\n",
      "7085 операционный\n",
      "7086 покаяние\n",
      "7087 приводиться\n",
      "7088 пусто\n",
      "7089 развалина\n",
      "7090 родственный\n",
      "7091 санитарный\n",
      "7092 сбыт\n",
      "7093 союзный\n",
      "7094 тощий\n",
      "7095 укладывать\n",
      "7096 уменьшиться\n",
      "7097 фон\n",
      "7098 фюрер\n",
      "7099 бульон\n",
      "7100 вовсю\n",
      "7101 вскрикнуть\n",
      "7102 вычислительный\n",
      "7103 должное\n",
      "7104 достойно\n",
      "7105 дуга\n",
      "7106 игнорировать\n",
      "7107 изрядно\n",
      "7108 изысканный\n",
      "7109 клеточный\n",
      "7110 колледж\n",
      "7111 компенсировать\n",
      "7112 координация\n",
      "7113 корм\n",
      "7114 ландшафт\n",
      "7115 лечебный\n",
      "7116 мм\n",
      "7117 морщина\n",
      "7118 незаметный\n",
      "7119 необычайно\n",
      "7120 несомненный\n",
      "7121 нищий\n",
      "7122 нищий\n",
      "7123 одобрение\n",
      "7124 осужденный\n",
      "7125 партнерство\n",
      "7126 пафос\n",
      "7127 перелом\n",
      "7128 плач\n",
      "7129 подвергнуть\n",
      "7130 поделить\n",
      "7131 подлый\n",
      "7132 поиграть\n",
      "7133 помчаться\n",
      "7134 правитель\n",
      "7135 преданность\n",
      "7136 привычно\n",
      "7137 проигрывать\n",
      "7138 равнодушие\n",
      "7139 регламент\n",
      "7140 режиссерский\n",
      "7141 роща\n",
      "7142 склонность\n",
      "7143 суммарный\n",
      "7144 трюк\n",
      "7145 университетский\n",
      "7146 целостность\n",
      "7147 чекист\n",
      "7148 щедрый\n",
      "7149 авторитетный\n",
      "7150 бесконечность\n",
      "7151 ведьма\n",
      "7152 верующий\n",
      "7153 взаимосвязь\n",
      "7154 выдвигать\n",
      "7155 выслушивать\n",
      "7156 давным-давно\n",
      "7157 застройка\n",
      "7158 затихнуть\n",
      "7159 здороваться\n",
      "7160 индустрия\n",
      "7161 кепка\n",
      "7162 косой\n",
      "7163 личностный\n",
      "7164 миска\n",
      "7165 мостовая\n",
      "7166 муравей\n",
      "7167 наложение\n",
      "7168 насмешка\n",
      "7169 наутро\n",
      "7170 обидный\n",
      "7171 озаботить\n",
      "7172 ослабить\n",
      "7173 основатель\n",
      "7174 пирожок\n",
      "7175 праздновать\n",
      "7176 приблизить\n",
      "7177 прибытие\n",
      "7178 приговорить\n",
      "7179 продовольственный\n",
      "7180 раздавить\n",
      "7181 ректор\n",
      "7182 робкий\n",
      "7183 святейший\n",
      "7184 сирота\n",
      "7185 собачка\n",
      "7186 сформироваться\n",
      "7187 тумбочка\n",
      "7188 указываться\n",
      "7189 управляющий\n",
      "7190 багаж\n",
      "7191 безобразие\n",
      "7192 ветерок\n",
      "7193 вешать\n",
      "7194 выть\n",
      "7195 гласить\n",
      "7196 девичий\n",
      "7197 демократ\n",
      "7198 добираться\n",
      "7199 древность\n",
      "7200 загореться\n",
      "7201 загородный\n",
      "7202 значиться\n",
      "7203 зять\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7204 кавалер\n",
      "7205 клапан\n",
      "7206 комсомолец\n",
      "7207 конек\n",
      "7208 корточки\n",
      "7209 косточка\n",
      "7210 лестничный\n",
      "7211 логистика\n",
      "7212 манеж\n",
      "7213 месть\n",
      "7214 методология\n",
      "7215 механика\n",
      "7216 мостик\n",
      "7217 направленность\n",
      "7218 носовой\n",
      "7219 оригинал\n",
      "7220 перебивать\n",
      "7221 покорно\n",
      "7222 похвалить\n",
      "7223 преобладать\n",
      "7224 продюсер\n",
      "7225 проезжать\n",
      "7226 пролететь\n",
      "7227 путевка\n",
      "7228 разборка\n",
      "7229 ремесло\n",
      "7230 сладко\n",
      "7231 стереотип\n",
      "7232 тайно\n",
      "7233 телесный\n",
      "7234 управленческий\n",
      "7235 хрустальный\n",
      "7236 чулок\n",
      "7237 швырнуть\n",
      "7238 экспортный\n",
      "7239 эмпирический\n",
      "7240 яростно\n",
      "7241 вой\n",
      "7242 востребовать\n",
      "7243 гвардия\n",
      "7244 грешный\n",
      "7245 дрянь\n",
      "7246 желанный\n",
      "7247 звонкий\n",
      "7248 издеваться\n",
      "7249 казачий\n",
      "7250 казнить\n",
      "7251 католический\n",
      "7252 классовый\n",
      "7253 клятва\n",
      "7254 комфорт\n",
      "7255 кролик\n",
      "7256 кто-либо\n",
      "7257 кумир\n",
      "7258 монтаж\n",
      "7259 мусульманский\n",
      "7260 наплевать\n",
      "7261 наркоман\n",
      "7262 окурок\n",
      "7263 отмахнуться\n",
      "7264 поблизости\n",
      "7265 повторение\n",
      "7266 пожимать\n",
      "7267 познать\n",
      "7268 после\n",
      "7269 похитить\n",
      "7270 предпринимательский\n",
      "7271 провокация\n",
      "7272 разбор\n",
      "7273 разногласие\n",
      "7274 расширять\n",
      "7275 садик\n",
      "7276 световой\n",
      "7277 свист\n",
      "7278 сенатор\n",
      "7279 смутно\n",
      "7280 сотовый\n",
      "7281 суждено\n",
      "7282 тугой\n",
      "7283 туристический\n",
      "7284 унылый\n",
      "7285 фашистский\n",
      "7286 чудовище\n",
      "7287 элегантный\n",
      "7288 азарт\n",
      "7289 беспощадный\n",
      "7290 брести\n",
      "7291 бунт\n",
      "7292 геном\n",
      "7293 гудок\n",
      "7294 джаз\n",
      "7295 дядька\n",
      "7296 интегрировать\n",
      "7297 иракский\n",
      "7298 квота\n",
      "7299 краевой\n",
      "7300 липа\n",
      "7301 медиальный\n",
      "7302 мемуары\n",
      "7303 метафора\n",
      "7304 муза\n",
      "7305 наблюдательный\n",
      "7306 наедине\n",
      "7307 напряженно\n",
      "7308 нравственность\n",
      "7309 объемный\n",
      "7310 опросить\n",
      "7311 отклик\n",
      "7312 пасть\n",
      "7313 пионерский\n",
      "7314 подскочить\n",
      "7315 покушение\n",
      "7316 произвольный\n",
      "7317 рубрика\n",
      "7318 себестоимость\n",
      "7319 скользкий\n",
      "7320 сопоставление\n",
      "7321 справочник\n",
      "7322 сценический\n",
      "7323 таять\n",
      "7324 тринадцать\n",
      "7325 троица\n",
      "7326 удлиненный\n",
      "7327 учитываться\n",
      "7328 экология\n",
      "7329 вертеть\n",
      "7330 выручить\n",
      "7331 горизонтальный\n",
      "7332 жук\n",
      "7333 задерживаться\n",
      "7334 задрать\n",
      "7335 извиниться\n",
      "7336 иммунитет\n",
      "7337 исполняться\n",
      "7338 казино\n",
      "7339 клок\n",
      "7340 коль\n",
      "7341 комбайн\n",
      "7342 лимон\n",
      "7343 меньшинство\n",
      "7344 мощи\n",
      "7345 надежно\n",
      "7346 неинтересный\n",
      "7347 нетрудно\n",
      "7348 оскорбление\n",
      "7349 отнимать\n",
      "7350 отопление\n",
      "7351 позаботиться\n",
      "7352 предатель\n",
      "7353 пробираться\n",
      "7354 пружина\n",
      "7355 размещаться\n",
      "7356 разновидность\n",
      "7357 рекомендоваться\n",
      "7358 самовар\n",
      "7359 симптом\n",
      "7360 срезать\n",
      "7361 стопа\n",
      "7362 таиться\n",
      "7363 убогий\n",
      "7364 укреплять\n",
      "7365 хоккей\n",
      "7366 элитный\n",
      "7367 ай\n",
      "7368 артистка\n",
      "7369 африканский\n",
      "7370 белка\n",
      "7371 бешенство\n",
      "7372 богослужение\n",
      "7373 воображать\n",
      "7374 впасть\n",
      "7375 вскрыть\n",
      "7376 вырост\n",
      "7377 вялый\n",
      "7378 двоюродный\n",
      "7379 дефект\n",
      "7380 застолье\n",
      "7381 инфаркт\n",
      "7382 кидать\n",
      "7383 княгиня\n",
      "7384 конкурировать\n",
      "7385 коробочка\n",
      "7386 методический\n",
      "7387 многократно\n",
      "7388 наилучший\n",
      "7389 нанять\n",
      "7390 невский\n",
      "7391 неуверенно\n",
      "7392 норматив\n",
      "7393 обнаженный\n",
      "7394 обход\n",
      "7395 отрывать\n",
      "7396 отчество\n",
      "7397 поднос\n",
      "7398 потащить\n",
      "7399 разъяснение\n",
      "7400 рваный\n",
      "7401 ринуться\n",
      "7402 ролик\n",
      "7403 семантический\n",
      "7404 славянин\n",
      "7405 слиться\n",
      "7406 слюна\n",
      "7407 суетиться\n",
      "7408 танковый\n",
      "7409 тематика\n",
      "7410 торт\n",
      "7411 усиливаться\n",
      "7412 шевелить\n",
      "7413 щедро\n",
      "7414 яростный\n",
      "7415 банкет\n",
      "7416 возвышаться\n",
      "7417 выше\n",
      "7418 депрессия\n",
      "7419 жутко\n",
      "7420 звездочка\n",
      "7421 конюшня\n",
      "7422 лен\n",
      "7423 логичный\n",
      "7424 лопасть\n",
      "7425 мелко\n",
      "7426 металлургия\n",
      "7427 мужественный\n",
      "7428 мыслитель\n",
      "7429 наполнять\n",
      "7430 напряженность\n",
      "7431 неформальный\n",
      "7432 обилие\n",
      "7433 обрывок\n",
      "7434 очертание\n",
      "7435 патриотизм\n",
      "7436 пленный\n",
      "7437 плитка\n",
      "7438 подвеска\n",
      "7439 подолгу\n",
      "7440 ползать\n",
      "7441 посмеяться\n",
      "7442 приговаривать\n",
      "7443 пробиваться\n",
      "7444 развестись\n",
      "7445 республиканский\n",
      "7446 сахарный\n",
      "7447 сбиться\n",
      "7448 сдержать\n",
      "7449 соседство\n",
      "7450 срываться\n",
      "7451 страстно\n",
      "7452 тетрадка\n",
      "7453 упрекать\n",
      "7454 упрямо\n",
      "7455 усиливать\n",
      "7456 фунт\n",
      "7457 хулиган\n",
      "7458 шапочка\n",
      "7459 эвакуация\n",
      "7460 экономически\n",
      "7461 э-э\n",
      "7462 алкогольный\n",
      "7463 бас\n",
      "7464 водяной\n",
      "7465 вывеска\n",
      "7466 гектар\n",
      "7467 добавка\n",
      "7468 езда\n",
      "7469 жать\n",
      "7470 заразить\n",
      "7471 конвейер\n",
      "7472 кошелек\n",
      "7473 меню\n",
      "7474 обаяние\n",
      "7475 одновременный\n",
      "7476 оклад\n",
      "7477 опрокинуть\n",
      "7478 паровоз\n",
      "7479 печататься\n",
      "7480 платный\n",
      "7481 погоня\n",
      "7482 предпринимать\n",
      "7483 пресс-служба\n",
      "7484 приготовиться\n",
      "7485 притихнуть\n",
      "7486 противоречивый\n",
      "7487 путаться\n",
      "7488 пьянство\n",
      "7489 сбрасывать\n",
      "7490 смуглый\n",
      "7491 сообщаться\n",
      "7492 сосновый\n",
      "7493 спасительный\n",
      "7494 старший\n",
      "7495 товарищество\n",
      "7496 тревожно\n",
      "7497 удариться\n",
      "7498 устный\n",
      "7499 часовой\n",
      "7500 чувствительность\n",
      "7501 чуткий\n",
      "7502 бархатный\n",
      "7503 бегом\n",
      "7504 бетон\n",
      "7505 воспитательный\n",
      "7506 выпивка\n",
      "7507 достигаться\n",
      "7508 звуковой\n",
      "7509 золотистый\n",
      "7510 исторически\n",
      "7511 исчерпать\n",
      "7512 кислый\n",
      "7513 лабораторный\n",
      "7514 лезвие\n",
      "7515 мгновенный\n",
      "7516 настоящее\n",
      "7517 непостижимый\n",
      "7518 нетерпеливо\n",
      "7519 нехватка\n",
      "7520 нобелевский\n",
      "7521 обеспечиваться\n",
      "7522 осваивать\n",
      "7523 откинуть\n",
      "7524 паутина\n",
      "7525 повлечь\n",
      "7526 пронзительный\n",
      "7527 пятеро\n",
      "7528 раздеваться\n",
      "7529 расчетный\n",
      "7530 романс\n",
      "7531 салфетка\n",
      "7532 скорбь\n",
      "7533 схожий\n",
      "7534 топить\n",
      "7535 угощать\n",
      "7536 устремиться\n",
      "7537 хитрость\n",
      "7538 чудный\n",
      "7539 автоматизированный\n",
      "7540 верблюд\n",
      "7541 видать\n",
      "7542 воскресение\n",
      "7543 вычислить\n",
      "7544 двухэтажный\n",
      "7545 доцент\n",
      "7546 жадный\n",
      "7547 идентификация\n",
      "7548 изоляция\n",
      "7549 камин\n",
      "7550 ком\n",
      "7551 косвенный\n",
      "7552 котлета\n",
      "7553 лихорадка\n",
      "7554 накопиться\n",
      "7555 нападать\n",
      "7556 нырнуть\n",
      "7557 обхватить\n",
      "7558 обыватель\n",
      "7559 отвлекать\n",
      "7560 перегородка\n",
      "7561 пир\n",
      "7562 пластмассовый\n",
      "7563 побыть\n",
      "7564 попадание\n",
      "7565 правильность\n",
      "7566 предисловие\n",
      "7567 призвание\n",
      "7568 приток\n",
      "7569 продлить\n",
      "7570 прокат\n",
      "7571 проститься\n",
      "7572 пульт\n",
      "7573 разрезать\n",
      "7574 своевременный\n",
      "7575 стих\n",
      "7576 студентка\n",
      "7577 тормозить\n",
      "7578 уткнуться\n",
      "7579 хвататься\n",
      "7580 хребет\n",
      "7581 электрон\n",
      "7582 адресовать\n",
      "7583 бегство\n",
      "7584 благой\n",
      "7585 воплотить\n",
      "7586 вскинуть\n",
      "7587 гамма\n",
      "7588 деваться\n",
      "7589 епархия\n",
      "7590 затронуть\n",
      "7591 императорский\n",
      "7592 индивидуальность\n",
      "7593 испуганный\n",
      "7594 консервы\n",
      "7595 мерка\n",
      "7596 мировоззрение\n",
      "7597 непредсказуемый\n",
      "7598 неприязнь\n",
      "7599 ноль\n",
      "7600 осторожность\n",
      "7601 передумать\n",
      "7602 погружаться\n",
      "7603 подчинение\n",
      "7604 поливать\n",
      "7605 приспособление\n",
      "7606 приставать\n",
      "7607 пристальный\n",
      "7608 проникновение\n",
      "7609 пуск\n",
      "7610 пушистый\n",
      "7611 рождать\n",
      "7612 сближение\n",
      "7613 скинуть\n",
      "7614 снабжение\n",
      "7615 спастись\n",
      "7616 стереть\n",
      "7617 стыдиться\n",
      "7618 сугроб\n",
      "7619 сурово\n",
      "7620 сырьевой\n",
      "7621 титр\n",
      "7622 толковать\n",
      "7623 тотальный\n",
      "7624 траектория\n",
      "7625 тьфу\n",
      "7626 убитый\n",
      "7627 уделить\n",
      "7628 ущелье\n",
      "7629 хорошенький\n",
      "7630 хроника\n",
      "7631 чугунный\n",
      "7632 эффектный\n",
      "7633 ячейка\n",
      "7634 армянин\n",
      "7635 афиша\n",
      "7636 беззащитный\n",
      "7637 беспорядок\n",
      "7638 благотворительный\n",
      "7639 вахта\n",
      "7640 веселиться\n",
      "7641 груда\n",
      "7642 ель\n",
      "7643 забава\n",
      "7644 захлопнуть\n",
      "7645 зонтик\n",
      "7646 излагать\n",
      "7647 кипяток\n",
      "7648 коммерсант\n",
      "7649 комнатка\n",
      "7650 крестный\n",
      "7651 лгать\n",
      "7652 милосердие\n",
      "7653 молекулярный\n",
      "7654 нажимать\n",
      "7655 налицо\n",
      "7656 напоследок\n",
      "7657 недоумевать\n",
      "7658 обитель\n",
      "7659 одолеть\n",
      "7660 окликнуть\n",
      "7661 отделаться\n",
      "7662 папин\n",
      "7663 передвигаться\n",
      "7664 помахать\n",
      "7665 пониматься\n",
      "7666 поползти\n",
      "7667 похвала\n",
      "7668 профессионализм\n",
      "7669 родня\n",
      "7670 серийный\n",
      "7671 скотина\n",
      "7672 составной\n",
      "7673 спрыгнуть\n",
      "7674 сухопутный\n",
      "7675 тонко\n",
      "7676 транспортировка\n",
      "7677 тыкать\n",
      "7678 улечься\n",
      "7679 управляемый\n",
      "7680 ускорение\n",
      "7681 утешение\n",
      "7682 царица\n",
      "7683 швейцарский\n",
      "7684 юрисдикция\n",
      "7685 авиакомпания\n",
      "7686 алюминий\n",
      "7687 атрибут\n",
      "7688 безумно\n",
      "7689 библейский\n",
      "7690 бюллетень\n",
      "7691 вечеринка\n",
      "7692 выглядывать\n",
      "7693 выдохнуть\n",
      "7694 высокопоставленный\n",
      "7695 выступ\n",
      "7696 гол\n",
      "7697 донос\n",
      "7698 завещание\n",
      "7699 заявитель\n",
      "7700 инерция\n",
      "7701 инициатор\n",
      "7702 коварный\n",
      "7703 колонка\n",
      "7704 красить\n",
      "7705 летный\n",
      "7706 незнакомец\n",
      "7707 опередить\n",
      "7708 опустеть\n",
      "7709 ориентир\n",
      "7710 особа\n",
      "7711 отстранить\n",
      "7712 подошва\n",
      "7713 посметь\n",
      "7714 пристань\n",
      "7715 приступать\n",
      "7716 притча\n",
      "7717 профессионально\n",
      "7718 пылать\n",
      "7719 развал\n",
      "7720 раздеться\n",
      "7721 реорганизация\n",
      "7722 списать\n",
      "7723 средневековье\n",
      "7724 ссориться\n",
      "7725 таить\n",
      "7726 темперамент\n",
      "7727 теоретик\n",
      "7728 тот-то\n",
      "7729 трактовка\n",
      "7730 увидеться\n",
      "7731 устоять\n",
      "7732 шоколад\n",
      "7733 шорох\n",
      "7734 штамп\n",
      "7735 юношеский\n",
      "7736 безработица\n",
      "7737 благословение\n",
      "7738 боярин\n",
      "7739 вдобавок\n",
      "7740 восклицать\n",
      "7741 выброс\n",
      "7742 выразительный\n",
      "7743 выручка\n",
      "7744 греть\n",
      "7745 дивизион\n",
      "7746 дополнить\n",
      "7747 дореволюционный\n",
      "7748 достояние\n",
      "7749 древесный\n",
      "7750 дружка\n",
      "7751 ежик\n",
      "7752 забыться\n",
      "7753 кланяться\n",
      "7754 нарком\n",
      "7755 неважный\n",
      "7756 некто\n",
      "7757 нехотя\n",
      "7758 отвергать\n",
      "7759 откинуться\n",
      "7760 отрицательно\n",
      "7761 ощутимый\n",
      "7762 перенос\n",
      "7763 пересмотреть\n",
      "7764 перечислять\n",
      "7765 поздравление\n",
      "7766 посмеиваться\n",
      "7767 потерпевший\n",
      "7768 приемник\n",
      "7769 притворяться\n",
      "7770 пронестись\n",
      "7771 пьяница\n",
      "7772 раздумывать\n",
      "7773 распахнуться\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7774 раствориться\n",
      "7775 револьвер\n",
      "7776 ростовский\n",
      "7777 сломаться\n",
      "7778 смутить\n",
      "7779 соус\n",
      "7780 стимул\n",
      "7781 страховщик\n",
      "7782 тупо\n",
      "7783 улетать\n",
      "7784 утверждаться\n",
      "7785 хмурый\n",
      "7786 частенько\n",
      "7787 безусловный\n",
      "7788 бланк\n",
      "7789 бор\n",
      "7790 бородатый\n",
      "7791 брюхо\n",
      "7792 виновато\n",
      "7793 воздействовать\n",
      "7794 вращение\n",
      "7795 вторжение\n",
      "7796 выпуклый\n",
      "7797 деловито\n",
      "7798 детектив\n",
      "7799 жалобно\n",
      "7800 задерживать\n",
      "7801 зажигалка\n",
      "7802 запутаться\n",
      "7803 затрагивать\n",
      "7804 злобный\n",
      "7805 значок\n",
      "7806 казанский\n",
      "7807 кассационный\n",
      "7808 кинематограф\n",
      "7809 кит\n",
      "7810 клочок\n",
      "7811 копыто\n",
      "7812 крах\n",
      "7813 крокодил\n",
      "7814 монография\n",
      "7815 мотивация\n",
      "7816 насмешливо\n",
      "7817 небывалый\n",
      "7818 нейтральный\n",
      "7819 нечистый\n",
      "7820 обновить\n",
      "7821 обрабатывать\n",
      "7822 оживиться\n",
      "7823 пан\n",
      "7824 подаваться\n",
      "7825 подвергнуться\n",
      "7826 превосходный\n",
      "7827 предание\n",
      "7828 предсказать\n",
      "7829 привилегия\n",
      "7830 приказывать\n",
      "7831 расстройство\n",
      "7832 ревновать\n",
      "7833 резиденция\n",
      "7834 санитар\n",
      "7835 свекровь\n",
      "7836 сострадание\n",
      "7837 тосковать\n",
      "7838 трещать\n",
      "7839 упругий\n",
      "7840 шрам\n",
      "7841 этический\n",
      "7842 абонент\n",
      "7843 бесшумно\n",
      "7844 бинокль\n",
      "7845 близ\n",
      "7846 близнец\n",
      "7847 вертикаль\n",
      "7848 вестибюль\n",
      "7849 военно-морской\n",
      "7850 вооружить\n",
      "7851 ворчать\n",
      "7852 выдержка\n",
      "7853 высочайший\n",
      "7854 груша\n",
      "7855 гусеница\n",
      "7856 демон\n",
      "7857 депутатский\n",
      "7858 дирекция\n",
      "7859 дымиться\n",
      "7860 египетский\n",
      "7861 задействовать\n",
      "7862 звучание\n",
      "7863 знаменитость\n",
      "7864 издательский\n",
      "7865 ископаемое\n",
      "7866 катание\n",
      "7867 качественно\n",
      "7868 комплимент\n",
      "7869 косить\n",
      "7870 крайность\n",
      "7871 крымский\n",
      "7872 логистический\n",
      "7873 магия\n",
      "7874 майский\n",
      "7875 надлежащий\n",
      "7876 обобщение\n",
      "7877 обои\n",
      "7878 окрасить\n",
      "7879 отключить\n",
      "7880 пассаж\n",
      "7881 пересекать\n",
      "7882 перила\n",
      "7883 перрон\n",
      "7884 подружиться\n",
      "7885 подсчитать\n",
      "7886 пожаловать\n",
      "7887 постепенный\n",
      "7888 предотвратить\n",
      "7889 прикинуть\n",
      "7890 радиостанция\n",
      "7891 разрабатываться\n",
      "7892 реестр\n",
      "7893 сдержанный\n",
      "7894 синтетический\n",
      "7895 скелет\n",
      "7896 скрип\n",
      "7897 ступить\n",
      "7898 сущий\n",
      "7899 талия\n",
      "7900 тесто\n",
      "7901 упрямый\n",
      "7902 футболист\n",
      "7903 хмуро\n",
      "7904 чистка\n",
      "7905 штык\n",
      "7906 языковой\n",
      "7907 архиепископ\n",
      "7908 бабий\n",
      "7909 безразличный\n",
      "7910 босс\n",
      "7911 взаимодействовать\n",
      "7912 вырабатывать\n",
      "7913 вышка\n",
      "7914 гребень\n",
      "7915 доктрина\n",
      "7916 жилищно-коммунальный\n",
      "7917 завершать\n",
      "7918 заем\n",
      "7919 землетрясение\n",
      "7920 изобретатель\n",
      "7921 изъятие\n",
      "7922 иномарка\n",
      "7923 канцелярия\n",
      "7924 капиталистический\n",
      "7925 конкурентоспособность\n",
      "7926 ларек\n",
      "7927 лягушка\n",
      "7928 мельница\n",
      "7929 моча\n",
      "7930 обыденный\n",
      "7931 оговорка\n",
      "7932 округлый\n",
      "7933 отвлечься\n",
      "7934 отдаваться\n",
      "7935 пассивный\n",
      "7936 перепутать\n",
      "7937 подозрительно\n",
      "7938 покатиться\n",
      "7939 поросенок\n",
      "7940 потечь\n",
      "7941 правоотношение\n",
      "7942 предусматриваться\n",
      "7943 прекращаться\n",
      "7944 призванный\n",
      "7945 приподняться\n",
      "7946 прогнозировать\n",
      "7947 родовой\n",
      "7948 сбивать\n",
      "7949 сверстник\n",
      "7950 сенсация\n",
      "7951 сквер\n",
      "7952 смешать\n",
      "7953 смущенно\n",
      "7954 социология\n",
      "7955 спасаться\n",
      "7956 судорожно\n",
      "7957 таинство\n",
      "7958 укрыться\n",
      "7959 умеренный\n",
      "7960 умница\n",
      "7961 ускорить\n",
      "7962 уставной\n",
      "7963 уточнение\n",
      "7964 чернила\n",
      "7965 широта\n",
      "7966 эстетика\n",
      "7967 автомашина\n",
      "7968 бессмысленно\n",
      "7969 братство\n",
      "7970 величественный\n",
      "7971 вилла\n",
      "7972 виноград\n",
      "7973 воронежский\n",
      "7974 воспроизводство\n",
      "7975 всесоюзный\n",
      "7976 выговорить\n",
      "7977 выдумка\n",
      "7978 выясняться\n",
      "7979 грызть\n",
      "7980 доверительный\n",
      "7981 дубовый\n",
      "7982 зеркальный\n",
      "7983 инцидент\n",
      "7984 клей\n",
      "7985 колхозник\n",
      "7986 котелок\n",
      "7987 кружить\n",
      "7988 лак\n",
      "7989 лапка\n",
      "7990 летучий\n",
      "7991 листочек\n",
      "7992 литургия\n",
      "7993 лить\n",
      "7994 недолгий\n",
      "7995 немедленный\n",
      "7996 обильный\n",
      "7997 обнаруживаться\n",
      "7998 обработать\n",
      "7999 обреченный\n",
      "8000 осесть\n",
      "8001 отдельность\n",
      "8002 отличить\n",
      "8003 отстоять\n",
      "8004 пальчик\n",
      "8005 перемещаться\n",
      "8006 популяция\n",
      "8007 прибывать\n",
      "8008 прикрытие\n",
      "8009 прописка\n",
      "8010 пух\n",
      "8011 пшеница\n",
      "8012 растерять\n",
      "8013 сборка\n",
      "8014 сбыться\n",
      "8015 серебристый\n",
      "8016 сертификат\n",
      "8017 созреть\n",
      "8018 тележка\n",
      "8019 уютно\n",
      "8020 финансировать\n",
      "8021 штатный\n",
      "8022 эпидемия\n",
      "8023 автограф\n",
      "8024 азиатский\n",
      "8025 багажник\n",
      "8026 богатырь\n",
      "8027 ведущий\n",
      "8028 визг\n",
      "8029 виновный\n",
      "8030 выигрыш\n",
      "8031 голландский\n",
      "8032 дергаться\n",
      "8033 здоровенный\n",
      "8034 идеально\n",
      "8035 индеец\n",
      "8036 как\n",
      "8037 крепостной\n",
      "8038 кучка\n",
      "8039 леди\n",
      "8040 лихо\n",
      "8041 лихой\n",
      "8042 ловкий\n",
      "8043 лорд\n",
      "8044 мучаться\n",
      "8045 наглядный\n",
      "8046 надвигаться\n",
      "8047 напрячься\n",
      "8048 нацелить\n",
      "8049 несправедливость\n",
      "8050 обморок\n",
      "8051 отрезок\n",
      "8052 подлец\n",
      "8053 пострадавший\n",
      "8054 присылать\n",
      "8055 пчела\n",
      "8056 разлука\n",
      "8057 рукоятка\n",
      "8058 симфония\n",
      "8059 скомандовать\n",
      "8060 скула\n",
      "8061 стан\n",
      "8062 таракан\n",
      "8063 теневой\n",
      "8064 уборная\n",
      "8065 фронтовой\n",
      "8066 целесообразный\n",
      "8067 экономить\n",
      "8068 абзац\n",
      "8069 блеснуть\n",
      "8070 внушительный\n",
      "8071 воскресный\n",
      "8072 всплеск\n",
      "8073 вылетать\n",
      "8074 выпрямиться\n",
      "8075 выращивать\n",
      "8076 графический\n",
      "8077 двенадцатый\n",
      "8078 доставаться\n",
      "8079 дружок\n",
      "8080 залп\n",
      "8081 застрелить\n",
      "8082 землянка\n",
      "8083 знакомая\n",
      "8084 инновационный\n",
      "8085 кол\n",
      "8086 конунг\n",
      "8087 коттедж\n",
      "8088 маркетинг\n",
      "8089 машинист\n",
      "8090 нагнуться\n",
      "8091 неохотно\n",
      "8092 обследовать\n",
      "8093 опасно\n",
      "8094 оперативник\n",
      "8095 пасха\n",
      "8096 переступить\n",
      "8097 покурить\n",
      "8098 посоветоваться\n",
      "8099 продовольствие\n",
      "8100 продолжительный\n",
      "8101 прожектор\n",
      "8102 пугаться\n",
      "8103 пухлый\n",
      "8104 расцвет\n",
      "8105 родство\n",
      "8106 сетевой\n",
      "8107 скользнуть\n",
      "8108 снисходительно\n",
      "8109 солидарность\n",
      "8110 специализироваться\n",
      "8111 спецназ\n",
      "8112 таможня\n",
      "8113 телеканал\n",
      "8114 топтаться\n",
      "8115 третейский\n",
      "8116 умолкнуть\n",
      "8117 упорный\n",
      "8118 учредить\n",
      "8119 физиологический\n",
      "8120 франк\n",
      "8121 частичный\n",
      "8122 штучка\n",
      "8123 альянс\n",
      "8124 бакс\n",
      "8125 блин\n",
      "8126 бугор\n",
      "8127 вишневый\n",
      "8128 волшебник\n",
      "8129 всматриваться\n",
      "8130 выборка\n",
      "8131 доброволец\n",
      "8132 догонять\n",
      "8133 заведующий\n",
      "8134 запрещаться\n",
      "8135 защищаться\n",
      "8136 злодей\n",
      "8137 зрачок\n",
      "8138 искренность\n",
      "8139 истечение\n",
      "8140 клавиша\n",
      "8141 конвой\n",
      "8142 мишень\n",
      "8143 мудрец\n",
      "8144 мучение\n",
      "8145 навалиться\n",
      "8146 навещать\n",
      "8147 накинуть\n",
      "8148 напор\n",
      "8149 ныть\n",
      "8150 оборваться\n",
      "8151 один-единственный\n",
      "8152 озираться\n",
      "8153 отделка\n",
      "8154 пианист\n",
      "8155 побледнеть\n",
      "8156 поджидать\n",
      "8157 поправлять\n",
      "8158 пробыть\n",
      "8159 процветать\n",
      "8160 радиус\n",
      "8161 раздавать\n",
      "8162 рвануться\n",
      "8163 реализм\n",
      "8164 репортаж\n",
      "8165 рождественский\n",
      "8166 содружество\n",
      "8167 стареть\n",
      "8168 стиснуть\n",
      "8169 стихийный\n",
      "8170 стойкий\n",
      "8171 трепет\n",
      "8172 убитый\n",
      "8173 ужинать\n",
      "8174 ухватить\n",
      "8175 фонарик\n",
      "8176 шуршать\n",
      "8177 электростанция\n",
      "8178 яблоня\n",
      "8179 аграрный\n",
      "8180 алкоголик\n",
      "8181 безо\n",
      "8182 благо\n",
      "8183 вытянуться\n",
      "8184 выяснение\n",
      "8185 глиняный\n",
      "8186 датчик\n",
      "8187 душить\n",
      "8188 заинтересованность\n",
      "8189 извлекать\n",
      "8190 казна\n",
      "8191 копье\n",
      "8192 крещение\n",
      "8193 марксизм\n",
      "8194 миллионер\n",
      "8195 наглядно\n",
      "8196 надлежать\n",
      "8197 недостойный\n",
      "8198 обязывать\n",
      "8199 островок\n",
      "8200 остроумный\n",
      "8201 официантка\n",
      "8202 охотиться\n",
      "8203 паренек\n",
      "8204 патент\n",
      "8205 переделать\n",
      "8206 перекрыть\n",
      "8207 плановый\n",
      "8208 повязка\n",
      "8209 погашение\n",
      "8210 попугай\n",
      "8211 потереть\n",
      "8212 разгром\n",
      "8213 решимость\n",
      "8214 склоняться\n",
      "8215 смертельно\n",
      "8216 спускать\n",
      "8217 стартовый\n",
      "8218 стипендия\n",
      "8219 сулить\n",
      "8220 тундра\n",
      "8221 удобрение\n",
      "8222 форточка\n",
      "8223 цветочный\n",
      "8224 читаться\n",
      "8225 шашлык\n",
      "8226 являть\n",
      "8227 балка\n",
      "8228 безупречный\n",
      "8229 березовый\n",
      "8230 ближний\n",
      "8231 вексель\n",
      "8232 весло\n",
      "8233 взлетать\n",
      "8234 впредь\n",
      "8235 вспомогательный\n",
      "8236 дворянин\n",
      "8237 диктатура\n",
      "8238 жестоко\n",
      "8239 закусить\n",
      "8240 зараза\n",
      "8241 зачет\n",
      "8242 изобилие\n",
      "8243 кубик\n",
      "8244 люстра\n",
      "8245 машиностроение\n",
      "8246 нащупать\n",
      "8247 неблагоприятный\n",
      "8248 недействительный\n",
      "8249 нежелание\n",
      "8250 необъяснимый\n",
      "8251 основательно\n",
      "8252 осуждение\n",
      "8253 папаша\n",
      "8254 парашют\n",
      "8255 парить\n",
      "8256 паук\n",
      "8257 переглянуться\n",
      "8258 подвергать\n",
      "8259 подписка\n",
      "8260 подъезжать\n",
      "8261 по-человечески\n",
      "8262 преграда\n",
      "8263 пригодный\n",
      "8264 прогнозирование\n",
      "8265 прокомментировать\n",
      "8266 раздраженно\n",
      "8267 разыскивать\n",
      "8268 раскрыться\n",
      "8269 расстроиться\n",
      "8270 реабилитация\n",
      "8271 сеять\n",
      "8272 социально\n",
      "8273 терзать\n",
      "8274 толпиться\n",
      "8275 уводить\n",
      "8276 учредитель\n",
      "8277 целесообразность\n",
      "8278 червь\n",
      "8279 щетка\n",
      "8280 авангард\n",
      "8281 белоснежный\n",
      "8282 вводиться\n",
      "8283 внутрь\n",
      "8284 воскреснуть\n",
      "8285 втянуть\n",
      "8286 выписывать\n",
      "8287 главнокомандующий\n",
      "8288 демографический\n",
      "8289 досуг\n",
      "8290 единичный\n",
      "8291 ей-богу\n",
      "8292 заблудиться\n",
      "8293 запястье\n",
      "8294 засада\n",
      "8295 захохотать\n",
      "8296 истинно\n",
      "8297 кабель\n",
      "8298 конъюнктура\n",
      "8299 лесхоз\n",
      "8300 лохматый\n",
      "8301 любимец\n",
      "8302 магистраль\n",
      "8303 месячный\n",
      "8304 морщиться\n",
      "8305 нанесение\n",
      "8306 недоразумение\n",
      "8307 одноклассник\n",
      "8308 пивной\n",
      "8309 подражать\n",
      "8310 помойка\n",
      "8311 последователь\n",
      "8312 презрительно\n",
      "8313 причудливый\n",
      "8314 пропорция\n",
      "8315 раскрываться\n",
      "8316 раскрытый\n",
      "8317 рискованный\n",
      "8318 рок\n",
      "8319 соврать\n",
      "8320 солома\n",
      "8321 соорудить\n",
      "8322 странность\n",
      "8323 табачный\n",
      "8324 техникум\n",
      "8325 тополь\n",
      "8326 часовой\n",
      "8327 экспонат\n",
      "8328 антиген\n",
      "8329 взойти\n",
      "8330 вихрь\n",
      "8331 возмутить\n",
      "8332 воспитатель\n",
      "8333 вражеский\n",
      "8334 выкрикнуть\n",
      "8335 вырываться\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8336 выходец\n",
      "8337 гарнизон\n",
      "8338 гормон\n",
      "8339 дернуться\n",
      "8340 задаваться\n",
      "8341 закономерный\n",
      "8342 замужем\n",
      "8343 заповедник\n",
      "8344 запоминать\n",
      "8345 зацепиться\n",
      "8346 изволить\n",
      "8347 императрица\n",
      "8348 исковой\n",
      "8349 консервативный\n",
      "8350 контраст\n",
      "8351 лет\n",
      "8352 мерзкий\n",
      "8353 монитор\n",
      "8354 начисто\n",
      "8355 ненормальный\n",
      "8356 номенклатура\n",
      "8357 одиноко\n",
      "8358 оформлять\n",
      "8359 подбросить\n",
      "8360 подпольный\n",
      "8361 полосатый\n",
      "8362 поперек\n",
      "8363 причал\n",
      "8364 прогнать\n",
      "8365 проложить\n",
      "8366 пустырь\n",
      "8367 раненый\n",
      "8368 распространять\n",
      "8369 резина\n",
      "8370 сверх\n",
      "8371 светло\n",
      "8372 свисать\n",
      "8373 смысловой\n",
      "8374 сослуживец\n",
      "8375 сочетать\n",
      "8376 стартовать\n",
      "8377 суша\n",
      "8378 терминология\n",
      "8379 трап\n",
      "8380 уточнять\n",
      "8381 четверка\n",
      "8382 чеховский\n",
      "8383 чутье\n",
      "8384 алло\n",
      "8385 безымянный\n",
      "8386 блаженство\n",
      "8387 божество\n",
      "8388 бриллиант\n",
      "8389 венец\n",
      "8390 вериться\n",
      "8391 водород\n",
      "8392 волосок\n",
      "8393 врожденный\n",
      "8394 высунуться\n",
      "8395 газопровод\n",
      "8396 глотка\n",
      "8397 дворянский\n",
      "8398 деликатный\n",
      "8399 долгожданный\n",
      "8400 дружина\n",
      "8401 заголовок\n",
      "8402 зарядить\n",
      "8403 застраховать\n",
      "8404 именоваться\n",
      "8405 имперский\n",
      "8406 компартия\n",
      "8407 корейский\n",
      "8408 косяк\n",
      "8409 ладошка\n",
      "8410 минутка\n",
      "8411 настойчивый\n",
      "8412 нюанс\n",
      "8413 оглядывать\n",
      "8414 одесский\n",
      "8415 пастух\n",
      "8416 переполнить\n",
      "8417 периодический\n",
      "8418 повалить\n",
      "8419 повышаться\n",
      "8420 поддаться\n",
      "8421 послезавтра\n",
      "8422 потемнеть\n",
      "8423 предотвращение\n",
      "8424 представать\n",
      "8425 продвигаться\n",
      "8426 проступать\n",
      "8427 прут\n",
      "8428 рабство\n",
      "8429 радиолокационный\n",
      "8430 расписать\n",
      "8431 реструктуризация\n",
      "8432 сжаться\n",
      "8433 синдром\n",
      "8434 словечко\n",
      "8435 смущение\n",
      "8436 соединяться\n",
      "8437 уполномоченный\n",
      "8438 установиться\n",
      "8439 целостный\n",
      "8440 цельный\n",
      "8441 четыреста\n",
      "8442 шарф\n",
      "8443 шашка\n",
      "8444 язва\n",
      "8445 балтийский\n",
      "8446 взрывной\n",
      "8447 вонючий\n",
      "8448 вписываться\n",
      "8449 всплыть\n",
      "8450 выставочный\n",
      "8451 геолог\n",
      "8452 геометрия\n",
      "8453 гнилой\n",
      "8454 гнусный\n",
      "8455 дальневосточный\n",
      "8456 действенный\n",
      "8457 детишки\n",
      "8458 дочерний\n",
      "8459 запечатлеть\n",
      "8460 заподозрить\n",
      "8461 избыточный\n",
      "8462 информировать\n",
      "8463 конфигурация\n",
      "8464 кромка\n",
      "8465 лепесток\n",
      "8466 либерал\n",
      "8467 массаж\n",
      "8468 многообразие\n",
      "8469 морозный\n",
      "8470 наказывать\n",
      "8471 напарник\n",
      "8472 недопустимый\n",
      "8473 неприличный\n",
      "8474 нет-нет\n",
      "8475 неужто\n",
      "8476 обаятельный\n",
      "8477 обрадовать\n",
      "8478 отвлечь\n",
      "8479 поспать\n",
      "8480 привод\n",
      "8481 прозвать\n",
      "8482 развивающийся\n",
      "8483 разъяснить\n",
      "8484 расслышать\n",
      "8485 рельеф\n",
      "8486 рудник\n",
      "8487 самолюбие\n",
      "8488 серьезность\n",
      "8489 сослаться\n",
      "8490 спираль\n",
      "8491 срывать\n",
      "8492 старание\n",
      "8493 ступня\n",
      "8494 съемочный\n",
      "8495 только-только\n",
      "8496 урод\n",
      "8497 усомниться\n",
      "8498 фондовый\n",
      "8499 хлебный\n",
      "8500 чудак\n",
      "8501 яхта\n",
      "8502 беззвучно\n",
      "8503 богословский\n",
      "8504 вестник\n",
      "8505 взвесить\n",
      "8506 винт\n",
      "8507 вопить\n",
      "8508 воровство\n",
      "8509 въезд\n",
      "8510 вывернуть\n",
      "8511 выкрикивать\n",
      "8512 вылет\n",
      "8513 выплачивать\n",
      "8514 выскакивать\n",
      "8515 глубь\n",
      "8516 грабить\n",
      "8517 двойка\n",
      "8518 задержание\n",
      "8519 иголка\n",
      "8520 иммунный\n",
      "8521 интеллектуал\n",
      "8522 карета\n",
      "8523 каяться\n",
      "8524 колокольчик\n",
      "8525 корма\n",
      "8526 корона\n",
      "8527 лиловый\n",
      "8528 липкий\n",
      "8529 листать\n",
      "8530 методологический\n",
      "8531 надобность\n",
      "8532 негодование\n",
      "8533 ненавистный\n",
      "8534 опереться\n",
      "8535 опоздание\n",
      "8536 очищать\n",
      "8537 передел\n",
      "8538 подтверждаться\n",
      "8539 потрогать\n",
      "8540 правдивый\n",
      "8541 прилично\n",
      "8542 приучить\n",
      "8543 простейший\n",
      "8544 псевдоним\n",
      "8545 пульс\n",
      "8546 распределить\n",
      "8547 распустить\n",
      "8548 регистрировать\n",
      "8549 рявкнуть\n",
      "8550 сидение\n",
      "8551 скверный\n",
      "8552 содержательный\n",
      "8553 сочный\n",
      "8554 спад\n",
      "8555 стабилизация\n",
      "8556 степной\n",
      "8557 страховка\n",
      "8558 сэкономить\n",
      "8559 тапочка\n",
      "8560 теперешний\n",
      "8561 терапия\n",
      "8562 туда-сюда\n",
      "8563 угостить\n",
      "8564 украинец\n",
      "8565 ухватиться\n",
      "8566 хищник\n",
      "8567 цыпочки\n",
      "8568 чек\n",
      "8569 шишка\n",
      "8570 энергично\n",
      "8571 акула\n",
      "8572 благосостояние\n",
      "8573 ведомость\n",
      "8574 веровать\n",
      "8575 вздумать\n",
      "8576 второе\n",
      "8577 выдавить\n",
      "8578 вычисление\n",
      "8579 геометрический\n",
      "8580 грош\n",
      "8581 детальный\n",
      "8582 дуэт\n",
      "8583 жизнедеятельность\n",
      "8584 задевать\n",
      "8585 заморозить\n",
      "8586 избрание\n",
      "8587 караул\n",
      "8588 корабельный\n",
      "8589 лабиринт\n",
      "8590 нарушитель\n",
      "8591 небытие\n",
      "8592 недвижимый\n",
      "8593 необычайный\n",
      "8594 обвести\n",
      "8595 одобрять\n",
      "8596 освобождаться\n",
      "8597 осложнение\n",
      "8598 отомстить\n",
      "8599 отправка\n",
      "8600 отсек\n",
      "8601 пень\n",
      "8602 перевернуться\n",
      "8603 переписать\n",
      "8604 поблескивать\n",
      "8605 поговорка\n",
      "8606 посыпаться\n",
      "8607 потный\n",
      "8608 прикоснуться\n",
      "8609 прицел\n",
      "8610 пришелец\n",
      "8611 приют\n",
      "8612 прощальный\n",
      "8613 психиатр\n",
      "8614 равнина\n",
      "8615 различить\n",
      "8616 расправа\n",
      "8617 расхохотаться\n",
      "8618 рыбалка\n",
      "8619 свита\n",
      "8620 слесарь\n",
      "8621 смоленский\n",
      "8622 соавтор\n",
      "8623 стричь\n",
      "8624 торжествовать\n",
      "8625 тренироваться\n",
      "8626 триумф\n",
      "8627 удостоить\n",
      "8628 хлопотать\n",
      "8629 хранитель\n",
      "8630 экстремальный\n",
      "8631 электромагнитный\n",
      "8632 алтарь\n",
      "8633 антисемитизм\n",
      "8634 большевистский\n",
      "8635 бушевать\n",
      "8636 вежливость\n",
      "8637 великолепно\n",
      "8638 вставлять\n",
      "8639 второстепенный\n",
      "8640 гендиректор\n",
      "8641 донской\n",
      "8642 журналистский\n",
      "8643 зажигать\n",
      "8644 измерять\n",
      "8645 ипотечный\n",
      "8646 испугать\n",
      "8647 колоть\n",
      "8648 конструкторский\n",
      "8649 костыль\n",
      "8650 кража\n",
      "8651 красоваться\n",
      "8652 ландшафтный\n",
      "8653 лилия\n",
      "8654 миля\n",
      "8655 минерал\n",
      "8656 молить\n",
      "8657 наследственный\n",
      "8658 няня\n",
      "8659 обеденный\n",
      "8660 облегчать\n",
      "8661 однозначный\n",
      "8662 осведомиться\n",
      "8663 отчего-то\n",
      "8664 охранный\n",
      "8665 пахать\n",
      "8666 пепельница\n",
      "8667 перемениться\n",
      "8668 пила\n",
      "8669 питательный\n",
      "8670 повидать\n",
      "8671 подготовительный\n",
      "8672 подталкивать\n",
      "8673 полвека\n",
      "8674 положительно\n",
      "8675 порадовать\n",
      "8676 похлопать\n",
      "8677 представительный\n",
      "8678 прикрепить\n",
      "8679 пролетарский\n",
      "8680 развязать\n",
      "8681 разместиться\n",
      "8682 разочаровать\n",
      "8683 реставрация\n",
      "8684 саммит\n",
      "8685 свежесть\n",
      "8686 сворачивать\n",
      "8687 сменяться\n",
      "8688 содействовать\n",
      "8689 сокращаться\n",
      "8690 сохранность\n",
      "8691 социолог\n",
      "8692 специализация\n",
      "8693 спикер\n",
      "8694 срыв\n",
      "8695 стрелок\n",
      "8696 трепетать\n",
      "8697 умудриться\n",
      "8698 факел\n",
      "8699 фигурировать\n",
      "8700 чума\n",
      "8701 шланг\n",
      "8702 абсурд\n",
      "8703 арбуз\n",
      "8704 борщ\n",
      "8705 вареный\n",
      "8706 венок\n",
      "8707 возбуждать\n",
      "8708 воронка\n",
      "8709 вранье\n",
      "8710 вселенский\n",
      "8711 вскакивать\n",
      "8712 выявлять\n",
      "8713 гаснуть\n",
      "8714 грянуть\n",
      "8715 дань\n",
      "8716 джентльмен\n",
      "8717 диета\n",
      "8718 дразнить\n",
      "8719 жадность\n",
      "8720 жила\n",
      "8721 журналистика\n",
      "8722 задохнуться\n",
      "8723 идиотский\n",
      "8724 имение\n",
      "8725 испытуемый\n",
      "8726 конный\n",
      "8727 корка\n",
      "8728 крюк\n",
      "8729 лазерный\n",
      "8730 назло\n",
      "8731 напевать\n",
      "8732 несоответствие\n",
      "8733 ниточка\n",
      "8734 новосибирский\n",
      "8735 номинация\n",
      "8736 общепринятый\n",
      "8737 общероссийский\n",
      "8738 обыкновение\n",
      "8739 оконный\n",
      "8740 описываться\n",
      "8741 поглотить\n",
      "8742 подверженный\n",
      "8743 подтолкнуть\n",
      "8744 покуда\n",
      "8745 помада\n",
      "8746 послушный\n",
      "8747 протестовать\n",
      "8748 противоположность\n",
      "8749 прямо-таки\n",
      "8750 рапорт\n",
      "8751 расписаться\n",
      "8752 растаять\n",
      "8753 самосознание\n",
      "8754 свердловский\n",
      "8755 толковый\n",
      "8756 топать\n",
      "8757 убежище\n",
      "8758 углубление\n",
      "8759 хлынуть\n",
      "8760 цветочек\n",
      "8761 чемоданчик\n",
      "8762 блокировать\n",
      "8763 брызги\n",
      "8764 быстренько\n",
      "8765 включиться\n",
      "8766 вытягивать\n",
      "8767 гель\n",
      "8768 дополнять\n",
      "8769 дуэль\n",
      "8770 ион\n",
      "8771 ихний\n",
      "8772 канат\n",
      "8773 коалиция\n",
      "8774 котельная\n",
      "8775 кратко\n",
      "8776 крылатый\n",
      "8777 написание\n",
      "8778 напрасный\n",
      "8779 недобрый\n",
      "8780 оберегать\n",
      "8781 обмениваться\n",
      "8782 объявиться\n",
      "8783 опухоль\n",
      "8784 переодеться\n",
      "8785 преподнести\n",
      "8786 присоединение\n",
      "8787 разразиться\n",
      "8788 раскол\n",
      "8789 расстроить\n",
      "8790 рубин\n",
      "8791 святыня\n",
      "8792 сметана\n",
      "8793 телохранитель\n",
      "8794 улучшать\n",
      "8795 уместный\n",
      "8796 храбрый\n",
      "8797 чешский\n",
      "8798 шерстяной\n",
      "8799 автономия\n",
      "8800 антисоветский\n",
      "8801 архангельский\n",
      "8802 баран\n",
      "8803 белеть\n",
      "8804 брачный\n",
      "8805 влететь\n",
      "8806 внедрить\n",
      "8807 воистину\n",
      "8808 выплатить\n",
      "8809 годовщина\n",
      "8810 гостья\n",
      "8811 грозно\n",
      "8812 дерзкий\n",
      "8813 дифференциация\n",
      "8814 единомышленник\n",
      "8815 жид\n",
      "8816 закинуть\n",
      "8817 измерить\n",
      "8818 калининградский\n",
      "8819 кон\n",
      "8820 контингент\n",
      "8821 мебельный\n",
      "8822 мерзавец\n",
      "8823 монстр\n",
      "8824 мох\n",
      "8825 наведение\n",
      "8826 налететь\n",
      "8827 наличный\n",
      "8828 насторожиться\n",
      "8829 неотъемлемый\n",
      "8830 непонимание\n",
      "8831 открытость\n",
      "8832 отсчет\n",
      "8833 пазуха\n",
      "8834 полезно\n",
      "8835 пословица\n",
      "8836 потеряться\n",
      "8837 приезжий\n",
      "8838 пристать\n",
      "8839 пристроить\n",
      "8840 прутик\n",
      "8841 пузырек\n",
      "8842 растительность\n",
      "8843 ребеночек\n",
      "8844 революционер\n",
      "8845 санкт-петербургский\n",
      "8846 сени\n",
      "8847 спереди\n",
      "8848 спиртное\n",
      "8849 сплетня\n",
      "8850 сыпаться\n",
      "8851 таксист\n",
      "8852 туризм\n",
      "8853 упорство\n",
      "8854 фойе\n",
      "8855 холст\n",
      "8856 худенький\n",
      "8857 шнур\n",
      "8858 щелкать\n",
      "8859 бдительность\n",
      "8860 берлинский\n",
      "8861 болгарский\n",
      "8862 буквальный\n",
      "8863 валовой\n",
      "8864 вешалка\n",
      "8865 визжать\n",
      "8866 водоросль\n",
      "8867 выдернуть\n",
      "8868 выпускаться\n",
      "8869 грузчик\n",
      "8870 дворик\n",
      "8871 дико\n",
      "8872 драгоценность\n",
      "8873 духовенство\n",
      "8874 жарить\n",
      "8875 жопа\n",
      "8876 загорелый\n",
      "8877 здорово\n",
      "8878 злоупотребление\n",
      "8879 изгнать\n",
      "8880 изумиться\n",
      "8881 капелька\n",
      "8882 кашель\n",
      "8883 колея\n",
      "8884 лом\n",
      "8885 ломаться\n",
      "8886 мафия\n",
      "8887 мертвец\n",
      "8888 морковь\n",
      "8889 навязывать\n",
      "8890 недалекий\n",
      "8891 неловкость\n",
      "8892 неофициальный\n",
      "8893 непременный\n",
      "8894 низший\n",
      "8895 обострение\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8896 одаренный\n",
      "8897 одержать\n",
      "8898 одиннадцатый\n",
      "8899 опережать\n",
      "8900 опровергнуть\n",
      "8901 отчетливый\n",
      "8902 пограничник\n",
      "8903 подавление\n",
      "8904 подсистема\n",
      "8905 понестись\n",
      "8906 празднование\n",
      "8907 пред\n",
      "8908 престиж\n",
      "8909 прославить\n",
      "8910 раскачиваться\n",
      "8911 раскрытие\n",
      "8912 рация\n",
      "8913 регламентировать\n",
      "8914 редакционный\n",
      "8915 роса\n",
      "8916 самодельный\n",
      "8917 сборный\n",
      "8918 сверкнуть\n",
      "8919 свистеть\n",
      "8920 северо-западный\n",
      "8921 совместить\n",
      "8922 суверенитет\n",
      "8923 счетный\n",
      "8924 теорема\n",
      "8925 тоскливо\n",
      "8926 удивленный\n",
      "8927 удочка\n",
      "8928 улочка\n",
      "8929 усмехаться\n",
      "8930 фольклор\n",
      "8931 хорошенько\n",
      "8932 ярославский\n",
      "8933 агитация\n",
      "8934 афганский\n",
      "8935 бесценный\n",
      "8936 будни\n",
      "8937 бурый\n",
      "8938 быстрота\n",
      "8939 бюрократический\n",
      "8940 воевода\n",
      "8941 возлюбленная\n",
      "8942 вступительный\n",
      "8943 выписка\n",
      "8944 делегат\n",
      "8945 допрашивать\n",
      "8946 забивать\n",
      "8947 забиться\n",
      "8948 зарезать\n",
      "8949 избить\n",
      "8950 износ\n",
      "8951 инфекционный\n",
      "8952 калина\n",
      "8953 канава\n",
      "8954 капать\n",
      "8955 каркас\n",
      "8956 кидаться\n",
      "8957 клин\n",
      "8958 клумба\n",
      "8959 комок\n",
      "8960 краснодарский\n",
      "8961 лиса\n",
      "8962 листовка\n",
      "8963 лихорадочно\n",
      "8964 макушка\n",
      "8965 музейный\n",
      "8966 начинающий\n",
      "8967 неуклюжий\n",
      "8968 ножницы\n",
      "8969 нотариус\n",
      "8970 нырять\n",
      "8971 обоснованный\n",
      "8972 одиночный\n",
      "8973 ослепительный\n",
      "8974 отменять\n",
      "8975 отрицание\n",
      "8976 охлаждение\n",
      "8977 пересечение\n",
      "8978 печь\n",
      "8979 побояться\n",
      "8980 позвоночник\n",
      "8981 полемика\n",
      "8982 полуостров\n",
      "8983 похудеть\n",
      "8984 притягивать\n",
      "8985 прищуриться\n",
      "8986 разгромить\n",
      "8987 расплатиться\n",
      "8988 робот\n",
      "8989 ронять\n",
      "8990 рыть\n",
      "8991 своевременно\n",
      "8992 сдохнуть\n",
      "8993 солист\n",
      "8994 станица\n",
      "8995 стержень\n",
      "8996 травка\n",
      "8997 трон\n",
      "8998 унитаз\n",
      "8999 утюг\n",
      "9000 фантастика\n",
      "9001 цветовой\n",
      "9002 что-то\n",
      "9003 эстрадный\n",
      "9004 ан\n",
      "9005 артерия\n",
      "9006 бесспорный\n",
      "9007 боб\n",
      "9008 болезненно\n",
      "9009 вынесение\n",
      "9010 генеральский\n",
      "9011 гимнастика\n",
      "9012 гласность\n",
      "9013 гражданка\n",
      "9014 грант\n",
      "9015 диаграмма\n",
      "9016 женитьба\n",
      "9017 запретный\n",
      "9018 идентичность\n",
      "9019 избушка\n",
      "9020 индустриальный\n",
      "9021 камерный\n",
      "9022 квантовый\n",
      "9023 китель\n",
      "9024 коктейль\n",
      "9025 компетентный\n",
      "9026 конечность\n",
      "9027 кубический\n",
      "9028 курский\n",
      "9029 легкомысленный\n",
      "9030 линейка\n",
      "9031 мэтр\n",
      "9032 намекнуть\n",
      "9033 настольный\n",
      "9034 незачем\n",
      "9035 неловкий\n",
      "9036 неровный\n",
      "9037 нива\n",
      "9038 осмыслить\n",
      "9039 парализовать\n",
      "9040 педаль\n",
      "9041 плавный\n",
      "9042 подержать\n",
      "9043 подлость\n",
      "9044 подрядчик\n",
      "9045 позавчера\n",
      "9046 пояснять\n",
      "9047 предназначение\n",
      "9048 прекращать\n",
      "9049 прерывать\n",
      "9050 прививка\n",
      "9051 примечательный\n",
      "9052 прислониться\n",
      "9053 раскалить\n",
      "9054 расплачиваться\n",
      "9055 реалия\n",
      "9056 ритуальный\n",
      "9057 самодеятельность\n",
      "9058 секретариат\n",
      "9059 семнадцатый\n",
      "9060 сокращать\n",
      "9061 стаканчик\n",
      "9062 сумрак\n",
      "9063 тереть\n",
      "9064 тропический\n",
      "9065 уделяться\n",
      "9066 уполномоченный\n",
      "9067 ух\n",
      "9068 фермер\n",
      "9069 шестидесятый\n",
      "9070 этикетка\n",
      "9071 автоматизация\n",
      "9072 аксиома\n",
      "9073 Аллах\n",
      "9074 антенна\n",
      "9075 апелляционный\n",
      "9076 благородство\n",
      "9077 блистать\n",
      "9078 бросок\n",
      "9079 бурно\n",
      "9080 бюрократия\n",
      "9081 вариация\n",
      "9082 взаимопонимание\n",
      "9083 виновник\n",
      "9084 вручать\n",
      "9085 вязать\n",
      "9086 глыба\n",
      "9087 демонстративно\n",
      "9088 довоенный\n",
      "9089 дорогостоящий\n",
      "9090 доходность\n",
      "9091 завопить\n",
      "9092 зазвонить\n",
      "9093 затвор\n",
      "9094 избранник\n",
      "9095 изгиб\n",
      "9096 изолировать\n",
      "9097 изумительный\n",
      "9098 исправление\n",
      "9099 козырек\n",
      "9100 кусать\n",
      "9101 латеральный\n",
      "9102 ликовать\n",
      "9103 маяк\n",
      "9104 наделать\n",
      "9105 нереальный\n",
      "9106 нулевой\n",
      "9107 отвлекаться\n",
      "9108 отработка\n",
      "9109 отчуждение\n",
      "9110 переменный\n",
      "9111 подсознание\n",
      "9112 подчиненный\n",
      "9113 полугодие\n",
      "9114 по-новому\n",
      "9115 прибрежный\n",
      "9116 прилегать\n",
      "9117 приостановить\n",
      "9118 приписывать\n",
      "9119 приставить\n",
      "9120 пробраться\n",
      "9121 провоцировать\n",
      "9122 проноситься\n",
      "9123 проскочить\n",
      "9124 просмотреть\n",
      "9125 разбежаться\n",
      "9126 рифма\n",
      "9127 румяный\n",
      "9128 свечка\n",
      "9129 сережка\n",
      "9130 скорбный\n",
      "9131 сова\n",
      "9132 соединиться\n",
      "9133 сожалеть\n",
      "9134 споткнуться\n",
      "9135 стационарный\n",
      "9136 стрелковый\n",
      "9137 съехать\n",
      "9138 теплоход\n",
      "9139 типография\n",
      "9140 трус\n",
      "9141 успокаиваться\n",
      "9142 утешить\n",
      "9143 фланг\n",
      "9144 фотоаппарат\n",
      "9145 ха-ха-ха\n",
      "9146 хвойный\n",
      "9147 хранилище\n",
      "9148 хрипло\n",
      "9149 чеснок\n",
      "9150 честность\n",
      "9151 шипеть\n",
      "9152 электроэнергетика\n",
      "9153 эскиз\n",
      "9154 ассистент\n",
      "9155 бездарный\n",
      "9156 богородица\n",
      "9157 болтовня\n",
      "9158 бутылочка\n",
      "9159 бухта\n",
      "9160 визуальный\n",
      "9161 виться\n",
      "9162 волевой\n",
      "9163 вслушиваться\n",
      "9164 государственность\n",
      "9165 добавление\n",
      "9166 доверенность\n",
      "9167 евангельский\n",
      "9168 зажмуриться\n",
      "9169 заиграть\n",
      "9170 замедлить\n",
      "9171 зашагать\n",
      "9172 искушение\n",
      "9173 итоговый\n",
      "9174 катушка\n",
      "9175 концептуальный\n",
      "9176 легион\n",
      "9177 любезно\n",
      "9178 малиновый\n",
      "9179 манер\n",
      "9180 мусорный\n",
      "9181 навеки\n",
      "9182 накладывать\n",
      "9183 настоять\n",
      "9184 насущный\n",
      "9185 нехитрый\n",
      "9186 нутро\n",
      "9187 односторонний\n",
      "9188 осмелиться\n",
      "9189 отворачиваться\n",
      "9190 отдача\n",
      "9191 охарактеризовать\n",
      "9192 паек\n",
      "9193 паркет\n",
      "9194 планка\n",
      "9195 поджать\n",
      "9196 пожениться\n",
      "9197 пополнение\n",
      "9198 постареть\n",
      "9199 почтенный\n",
      "9200 приветливо\n",
      "9201 привлекательность\n",
      "9202 придерживать\n",
      "9203 причастный\n",
      "9204 сатира\n",
      "9205 сбережение\n",
      "9206 свадебный\n",
      "9207 селение\n",
      "9208 скромность\n",
      "9209 сняться\n",
      "9210 соскучиться\n",
      "9211 стоп\n",
      "9212 супружеский\n",
      "9213 счетчик\n",
      "9214 считанный\n",
      "9215 тачка\n",
      "9216 трибунал\n",
      "9217 уполномочить\n",
      "9218 финиш\n",
      "9219 химик\n",
      "9220 хриплый\n",
      "9221 цирковой\n",
      "9222 чувственный\n",
      "9223 чудом\n",
      "9224 шелк\n",
      "9225 эдакий\n",
      "9226 электроника\n",
      "9227 эстонский\n",
      "9228 аборт\n",
      "9229 австрийский\n",
      "9230 аквариум\n",
      "9231 аспирант\n",
      "9232 бессмертие\n",
      "9233 благословить\n",
      "9234 блестяще\n",
      "9235 винить\n",
      "9236 возглас\n",
      "9237 вывозить\n",
      "9238 высадить\n",
      "9239 дамский\n",
      "9240 душный\n",
      "9241 замминистра\n",
      "9242 зэк\n",
      "9243 извне\n",
      "9244 канадский\n",
      "9245 катализатор\n",
      "9246 коготь\n",
      "9247 компактный\n",
      "9248 красноармеец\n",
      "9249 ль\n",
      "9250 мельком\n",
      "9251 меховой\n",
      "9252 мыться\n",
      "9253 наказываться\n",
      "9254 наклонить\n",
      "9255 насмерть\n",
      "9256 насчитывать\n",
      "9257 нежелательный\n",
      "9258 носилки\n",
      "9259 обдумывать\n",
      "9260 обнажить\n",
      "9261 овальный\n",
      "9262 оживление\n",
      "9263 отважный\n",
      "9264 очевидец\n",
      "9265 очертить\n",
      "9266 перечитывать\n",
      "9267 племянница\n",
      "9268 подключить\n",
      "9269 позорный\n",
      "9270 показываться\n",
      "9271 покорить\n",
      "9272 покорный\n",
      "9273 политически\n",
      "9274 поправиться\n",
      "9275 праведный\n",
      "9276 превышение\n",
      "9277 преувеличение\n",
      "9278 привязанность\n",
      "9279 прикидывать\n",
      "9280 пропеть\n",
      "9281 просвет\n",
      "9282 разбегаться\n",
      "9283 разведывательный\n",
      "9284 режиссура\n",
      "9285 роспись\n",
      "9286 сдержанно\n",
      "9287 сертификация\n",
      "9288 сечение\n",
      "9289 систематический\n",
      "9290 скопление\n",
      "9291 слог\n",
      "9292 смирение\n",
      "9293 спутать\n",
      "9294 сравнимый\n",
      "9295 сувенир\n",
      "9296 тамошний\n",
      "9297 тоннель\n",
      "9298 тоталитарный\n",
      "9299 то-то\n",
      "9300 труженик\n",
      "9301 туловище\n",
      "9302 угрюмо\n",
      "9303 укрытие\n",
      "9304 укусить\n",
      "9305 унизительный\n",
      "9306 уродливый\n",
      "9307 хрустеть\n",
      "9308 чреватый\n",
      "9309 эротический\n",
      "9310 явственно\n",
      "9311 амнистия\n",
      "9312 бедняга\n",
      "9313 битый\n",
      "9314 бортовой\n",
      "9315 боязнь\n",
      "9316 бритва\n",
      "9317 вальс\n",
      "9318 ван\n",
      "9319 вата\n",
      "9320 весь\n",
      "9321 восходить\n",
      "9322 горючее\n",
      "9323 дарование\n",
      "9324 джунгли\n",
      "9325 добродетель\n",
      "9326 доходный\n",
      "9327 затруднение\n",
      "9328 земляной\n",
      "9329 изолят\n",
      "9330 кайф\n",
      "9331 карьер\n",
      "9332 кнут\n",
      "9333 кондиционер\n",
      "9334 копаться\n",
      "9335 креститься\n",
      "9336 лепить\n",
      "9337 лирика\n",
      "9338 материк\n",
      "9339 маячить\n",
      "9340 навязать\n",
      "9341 намечаться\n",
      "9342 новгородский\n",
      "9343 обзавестись\n",
      "9344 обитание\n",
      "9345 обняться\n",
      "9346 обобщенный\n",
      "9347 оперетта\n",
      "9348 оратор\n",
      "9349 ослабление\n",
      "9350 перераспределение\n",
      "9351 побрести\n",
      "9352 подделка\n",
      "9353 постсоветский\n",
      "9354 предъявление\n",
      "9355 преемник\n",
      "9356 прилипнуть\n",
      "9357 примыкать\n",
      "9358 приписать\n",
      "9359 проблематика\n",
      "9360 прокатиться\n",
      "9361 пролетариат\n",
      "9362 пропитать\n",
      "9363 протяженность\n",
      "9364 профсоюзный\n",
      "9365 пустовать\n",
      "9366 разыгрывать\n",
      "9367 распасться\n",
      "9368 самочувствие\n",
      "9369 светильник\n",
      "9370 сирень\n",
      "9371 сковородка\n",
      "9372 скудный\n",
      "9373 следующее\n",
      "9374 сокол\n",
      "9375 строфа\n",
      "9376 топливный\n",
      "9377 торопить\n",
      "9378 трубочка\n",
      "9379 уборщица\n",
      "9380 увлекательный\n",
      "9381 усатый\n",
      "9382 ухмыльнуться\n",
      "9383 фаворит\n",
      "9384 черед\n",
      "9385 чукча\n",
      "9386 шестерка\n",
      "9387 шляпка\n",
      "9388 арендатор\n",
      "9389 арендовать\n",
      "9390 балерина\n",
      "9391 безобидный\n",
      "9392 береговой\n",
      "9393 бесполезно\n",
      "9394 бессилие\n",
      "9395 богиня\n",
      "9396 бомбардировщик\n",
      "9397 броня\n",
      "9398 валять\n",
      "9399 возводить\n",
      "9400 возня\n",
      "9401 выговор\n",
      "9402 выкладывать\n",
      "9403 грим\n",
      "9404 грядка\n",
      "9405 действо\n",
      "9406 диссидент\n",
      "9407 жрец\n",
      "9408 игрушечный\n",
      "9409 извлечение\n",
      "9410 индикатор\n",
      "9411 инициировать\n",
      "9412 каковой\n",
      "9413 камешек\n",
      "9414 каска\n",
      "9415 кверху\n",
      "9416 колпак\n",
      "9417 коммуна\n",
      "9418 мгла\n",
      "9419 мел\n",
      "9420 метнуться\n",
      "9421 мотать\n",
      "9422 мрамор\n",
      "9423 мятый\n",
      "9424 назначаться\n",
      "9425 недорогой\n",
      "9426 нечаянно\n",
      "9427 оборотень\n",
      "9428 объединиться\n",
      "9429 останки\n",
      "9430 откровенность\n",
      "9431 ошеломить\n",
      "9432 победный\n",
      "9433 подготовиться\n",
      "9434 подтянуть\n",
      "9435 полководец\n",
      "9436 потреблять\n",
      "9437 предписание\n",
      "9438 проваливаться\n",
      "9439 продержаться\n",
      "9440 пьяный\n",
      "9441 равномерно\n",
      "9442 радуга\n",
      "9443 разозлиться\n",
      "9444 расхождение\n",
      "9445 реактивный\n",
      "9446 регулятор\n",
      "9447 репродукция\n",
      "9448 рушиться\n",
      "9449 салют\n",
      "9450 сверток\n",
      "9451 сдвинуться\n",
      "9452 сжатый\n",
      "9453 смежный\n",
      "9454 сокровенный\n",
      "9455 стихнуть\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9456 стянуть\n",
      "9457 указательный\n",
      "9458 употребить\n",
      "9459 условность\n",
      "9460 ха\n",
      "9461 цветение\n",
      "9462 черно-белый\n",
      "9463 шарить\n",
      "9464 шататься\n",
      "9465 шахтер\n",
      "9466 языческий\n",
      "9467 актуальность\n",
      "9468 баржа\n",
      "9469 беседка\n",
      "9470 блистательный\n",
      "9471 брезгливо\n",
      "9472 воз\n",
      "9473 возвышенный\n",
      "9474 воспаление\n",
      "9475 вписать\n",
      "9476 вполголоса\n",
      "9477 вынырнуть\n",
      "9478 говно\n",
      "9479 двойник\n",
      "9480 дебют\n",
      "9481 девиз\n",
      "9482 длительность\n",
      "9483 доминировать\n",
      "9484 задумчивый\n",
      "9485 затормозить\n",
      "9486 зубр\n",
      "9487 идол\n",
      "9488 извинение\n",
      "9489 капризный\n",
      "9490 климатический\n",
      "9491 ключик\n",
      "9492 комбат\n",
      "9493 комнатный\n",
      "9494 кооперация\n",
      "9495 крушение\n",
      "9496 лень\n",
      "9497 лира\n",
      "9498 ложечка\n",
      "9499 лошадка\n",
      "9500 макет\n",
      "9501 матрас\n",
      "9502 мигрант\n",
      "9503 миграционный\n",
      "9504 мнимый\n",
      "9505 нависнуть\n",
      "9506 наподобие\n",
      "9507 напрочь\n",
      "9508 нестандартный\n",
      "9509 неуловимый\n",
      "9510 обучить\n",
      "9511 окружной\n",
      "9512 опека\n",
      "9513 отросток\n",
      "9514 оттолкнуть\n",
      "9515 отчетный\n",
      "9516 патруль\n",
      "9517 пельмень\n",
      "9518 переменная\n",
      "9519 плот\n",
      "9520 поглощать\n",
      "9521 погреб\n",
      "9522 поди\n",
      "9523 подол\n",
      "9524 помянуть\n",
      "9525 поощрять\n",
      "9526 почет\n",
      "9527 предназначаться\n",
      "9528 предсказание\n",
      "9529 прижиматься\n",
      "9530 проклятие\n",
      "9531 пронизать\n",
      "9532 просматриваться\n",
      "9533 разрушительный\n",
      "9534 рассеянно\n",
      "9535 реформатор\n",
      "9536 сверкающий\n",
      "9537 светофор\n",
      "9538 следование\n",
      "9539 слушание\n",
      "9540 снайпер\n",
      "9541 совокупный\n",
      "9542 спасатель\n",
      "9543 спровоцировать\n",
      "9544 техник\n",
      "9545 толща\n",
      "9546 треснуть\n",
      "9547 трос\n",
      "9548 финальный\n",
      "9549 футляр\n",
      "9550 чашечка\n",
      "9551 череда\n",
      "9552 чинить\n",
      "9553 эксплуатационный\n",
      "9554 азот\n",
      "9555 бессонница\n",
      "9556 весомый\n",
      "9557 вникать\n",
      "9558 встревожить\n",
      "9559 встрепенуться\n",
      "9560 вывоз\n",
      "9561 выругаться\n",
      "9562 гостиничный\n",
      "9563 добродушный\n",
      "9564 дядюшка\n",
      "9565 завоевание\n",
      "9566 завтракать\n",
      "9567 заготовить\n",
      "9568 заметать\n",
      "9569 запускать\n",
      "9570 зрелость\n",
      "9571 исповедовать\n",
      "9572 карабин\n",
      "9573 клан\n",
      "9574 кобура\n",
      "9575 коммуналка\n",
      "9576 краб\n",
      "9577 круговой\n",
      "9578 ласкать\n",
      "9579 личико\n",
      "9580 малость\n",
      "9581 миленький\n",
      "9582 мохнатый\n",
      "9583 мстить\n",
      "9584 наемный\n",
      "9585 настоятель\n",
      "9586 обменяться\n",
      "9587 обогнать\n",
      "9588 оживать\n",
      "9589 опорный\n",
      "9590 отложение\n",
      "9591 перевезти\n",
      "9592 перечисленный\n",
      "9593 печенье\n",
      "9594 платочек\n",
      "9595 пожертвовать\n",
      "9596 половинка\n",
      "9597 попутно\n",
      "9598 посвящать\n",
      "9599 презумпция\n",
      "9600 проклинать\n",
      "9601 прокричать\n",
      "9602 пролить\n",
      "9603 пронести\n",
      "9604 протоиерей\n",
      "9605 рента\n",
      "9606 рогатый\n",
      "9607 свершиться\n",
      "9608 семидесятый\n",
      "9609 сжигать\n",
      "9610 символика\n",
      "9611 синева\n",
      "9612 скандальный\n",
      "9613 сколько-нибудь\n",
      "9614 скоростной\n",
      "9615 славиться\n",
      "9616 сладость\n",
      "9617 смешаться\n",
      "9618 создаться\n",
      "9619 соловей\n",
      "9620 строгость\n",
      "9621 супермаркет\n",
      "9622 теленок\n",
      "9623 уменьшать\n",
      "9624 усаживаться\n",
      "9625 ухудшение\n",
      "9626 цепной\n",
      "9627 церка\n",
      "9628 шоколадный\n",
      "9629 аплодировать\n",
      "9630 башмак\n",
      "9631 больная\n",
      "9632 весить\n",
      "9633 владимирский\n",
      "9634 вовлечь\n",
      "9635 восторженно\n",
      "9636 всего-то\n",
      "9637 вышестоящий\n",
      "9638 господство\n",
      "9639 докторский\n",
      "9640 духовность\n",
      "9641 завершаться\n",
      "9642 закусывать\n",
      "9643 засесть\n",
      "9644 затаиться\n",
      "9645 идеолог\n",
      "9646 израильтянин\n",
      "9647 каток\n",
      "9648 колокольня\n",
      "9649 кудрявый\n",
      "9650 курировать\n",
      "9651 лень\n",
      "9652 льготный\n",
      "9653 лютый\n",
      "9654 метель\n",
      "9655 морально\n",
      "9656 мученик\n",
      "9657 надзиратель\n",
      "9658 насчитываться\n",
      "9659 негосударственный\n",
      "9660 немаловажный\n",
      "9661 неудобство\n",
      "9662 обжечь\n",
      "9663 оборотный\n",
      "9664 оправдаться\n",
      "9665 оскорблять\n",
      "9666 отрыв\n",
      "9667 переливаться\n",
      "9668 плодотворный\n",
      "9669 подозреваемый\n",
      "9670 подпрыгивать\n",
      "9671 подпрыгнуть\n",
      "9672 подставлять\n",
      "9673 подыматься\n",
      "9674 полумрак\n",
      "9675 потомство\n",
      "9676 приведение\n",
      "9677 приветливый\n",
      "9678 приказание\n",
      "9679 примирение\n",
      "9680 присмотреться\n",
      "9681 прогуливаться\n",
      "9682 проповедовать\n",
      "9683 просматривать\n",
      "9684 разгадать\n",
      "9685 разоблачение\n",
      "9686 сводка\n",
      "9687 сердитый\n",
      "9688 скосить\n",
      "9689 смущаться\n",
      "9690 сопоставимый\n",
      "9691 струйка\n",
      "9692 твердость\n",
      "9693 тестирование\n",
      "9694 тряхнуть\n",
      "9695 уклон\n",
      "9696 умелый\n",
      "9697 унаследовать\n",
      "9698 уплатить\n",
      "9699 урна\n",
      "9700 устремить\n",
      "9701 утечка\n",
      "9702 фигурный\n",
      "9703 финн\n",
      "9704 фыркнуть\n",
      "9705 шахматист\n",
      "9706 шприц\n",
      "9707 энергетик\n",
      "9708 буйный\n",
      "9709 веник\n",
      "9710 воспроизводить\n",
      "9711 высыпать\n",
      "9712 генератор\n",
      "9713 герб\n",
      "9714 грамотно\n",
      "9715 графиня\n",
      "9716 гримаса\n",
      "9717 девятнадцатый\n",
      "9718 дурачок\n",
      "9719 житься\n",
      "9720 жулик\n",
      "9721 закрепление\n",
      "9722 зацепить\n",
      "9723 звериный\n",
      "9724 зов\n",
      "9725 иль\n",
      "9726 калибр\n",
      "9727 картонный\n",
      "9728 кофта\n",
      "9729 лыжный\n",
      "9730 мироздание\n",
      "9731 модельный\n",
      "9732 натягивать\n",
      "9733 небритый\n",
      "9734 недуг\n",
      "9735 нью-йоркский\n",
      "9736 обучаться\n",
      "9737 особь\n",
      "9738 отбой\n",
      "9739 отбыть\n",
      "9740 ото\n",
      "9741 ошибочный\n",
      "9742 палестинский\n",
      "9743 педагогика\n",
      "9744 петрушка\n",
      "9745 побеседовать\n",
      "9746 подвесить\n",
      "9747 подействовать\n",
      "9748 поклясться\n",
      "9749 понизить\n",
      "9750 пошлость\n",
      "9751 преподавание\n",
      "9752 прибрать\n",
      "9753 признанный\n",
      "9754 примесь\n",
      "9755 причастность\n",
      "9756 продольный\n",
      "9757 прототип\n",
      "9758 психиатрический\n",
      "9759 разграничение\n",
      "9760 райский\n",
      "9761 резной\n",
      "9762 романтик\n",
      "9763 романтика\n",
      "9764 рычать\n",
      "9765 складской\n",
      "9766 сломить\n",
      "9767 состязание\n",
      "9768 стирка\n",
      "9769 танкист\n",
      "9770 теплота\n",
      "9771 тесть\n",
      "9772 томиться\n",
      "9773 траншея\n",
      "9774 третья\n",
      "9775 физкультура\n",
      "9776 швырять\n",
      "9777 шевельнуться\n",
      "9778 щи\n",
      "9779 ювелирный\n",
      "9780 апельсин\n",
      "9781 безграничный\n",
      "9782 бинт\n",
      "9783 богач\n",
      "9784 вакцинация\n",
      "9785 валиться\n",
      "9786 вдаль\n",
      "9787 вековой\n",
      "9788 верующий\n",
      "9789 взамен\n",
      "9790 внушить\n",
      "9791 волчий\n",
      "9792 воспитанник\n",
      "9793 всплывать\n",
      "9794 генерал-майор\n",
      "9795 гоночный\n",
      "9796 дельфин\n",
      "9797 доброжелательный\n",
      "9798 доверчивый\n",
      "9799 доводиться\n",
      "9800 договорить\n",
      "9801 дружественный\n",
      "9802 дюжина\n",
      "9803 жгучий\n",
      "9804 жестяной\n",
      "9805 жизненно\n",
      "9806 заботливый\n",
      "9807 задрожать\n",
      "9808 замкнуть\n",
      "9809 заполнение\n",
      "9810 затопить\n",
      "9811 катить\n",
      "9812 кашлять\n",
      "9813 квартирка\n",
      "9814 корт\n",
      "9815 кофточка\n",
      "9816 лидировать\n",
      "9817 лукавый\n",
      "9818 магистральный\n",
      "9819 могущественный\n",
      "9820 мячик\n",
      "9821 навоз\n",
      "9822 нелегальный\n",
      "9823 несложный\n",
      "9824 неуместный\n",
      "9825 обстрел\n",
      "9826 однородный\n",
      "9827 оживленный\n",
      "9828 окрестный\n",
      "9829 оргазм\n",
      "9830 осмысление\n",
      "9831 отличительный\n",
      "9832 ощупь\n",
      "9833 парадигма\n",
      "9834 персидский\n",
      "9835 пианино\n",
      "9836 подрасти\n",
      "9837 подчиниться\n",
      "9838 позавидовать\n",
      "9839 пошлый\n",
      "9840 право\n",
      "9841 превзойти\n",
      "9842 пробегать\n",
      "9843 проблемный\n",
      "9844 продиктовать\n",
      "9845 прозрачность\n",
      "9846 психологически\n",
      "9847 раздать\n",
      "9848 расклад\n",
      "9849 расстраиваться\n",
      "9850 расстреливать\n",
      "9851 рассудок\n",
      "9852 резинка\n",
      "9853 ровесник\n",
      "9854 русскоязычный\n",
      "9855 сироп\n",
      "9856 сырость\n",
      "9857 тайком\n",
      "9858 тогда-то\n",
      "9859 трест\n",
      "9860 тяжко\n",
      "9861 улавливать\n",
      "9862 унижать\n",
      "9863 усмотрение\n",
      "9864 учредительный\n",
      "9865 уют\n",
      "9866 хитро\n",
      "9867 централизованный\n",
      "9868 чех\n",
      "9869 щадить\n",
      "9870 аспирантура\n",
      "9871 бактерия\n",
      "9872 бездействие\n",
      "9873 безразлично\n",
      "9874 будда\n",
      "9875 ватный\n",
      "9876 ведомственный\n",
      "9877 видео\n",
      "9878 вишня\n",
      "9879 вопросительно\n",
      "9880 выдумывать\n",
      "9881 выращивание\n",
      "9882 горком\n",
      "9883 грабеж\n",
      "9884 грубость\n",
      "9885 грузить\n",
      "9886 губернский\n",
      "9887 гулкий\n",
      "9888 добросовестный\n",
      "9889 док\n",
      "9890 донор\n",
      "9891 дощатый\n",
      "9892 дымок\n",
      "9893 еж\n",
      "9894 желаемый\n",
      "9895 забастовка\n",
      "9896 завестись\n",
      "9897 замахать\n",
      "9898 захоронение\n",
      "9899 зевать\n",
      "9900 знатный\n",
      "9901 извозчик\n",
      "9902 излишне\n",
      "9903 искажение\n",
      "9904 искусственно\n",
      "9905 капот\n",
      "9906 керосин\n",
      "9907 клад\n",
      "9908 кровля\n",
      "9909 курение\n",
      "9910 легковой\n",
      "9911 лизинг\n",
      "9912 лысина\n",
      "9913 металлург\n",
      "9914 мышечный\n",
      "9915 мюзикл\n",
      "9916 набок\n",
      "9917 нагло\n",
      "9918 назавтра\n",
      "9919 настройка\n",
      "9920 насытить\n",
      "9921 невестка\n",
      "9922 незабываемый\n",
      "9923 незаменимый\n",
      "9924 неспособный\n",
      "9925 нечеловеческий\n",
      "9926 ого\n",
      "9927 опушка\n",
      "9928 осел\n",
      "9929 отремонтировать\n",
      "9930 партизанский\n",
      "9931 переезжать\n",
      "9932 переложить\n",
      "9933 повалиться\n",
      "9934 повиноваться\n",
      "9935 поганый\n",
      "9936 погружение\n",
      "9937 подданный\n",
      "9938 подорвать\n",
      "9939 подполье\n",
      "9940 покоиться\n",
      "9941 помиловать\n",
      "9942 поминать\n",
      "9943 преддверие\n",
      "9944 привить\n",
      "9945 придаток\n",
      "9946 придворный\n",
      "9947 прикасаться\n",
      "9948 пристав\n",
      "9949 радиоактивный\n",
      "9950 разведение\n",
      "9951 рыхлый\n",
      "9952 свирепый\n",
      "9953 скачок\n",
      "9954 смола\n",
      "9955 сосать\n",
      "9956 сосиска\n",
      "9957 состоятельный\n",
      "9958 судорога\n",
      "9959 сыщик\n",
      "9960 тайник\n",
      "9961 тематический\n",
      "HTTPSConnectionPool(host='translate.academic.ru', port=443): Max retries exceeded with url: /%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9/ru/en/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000016E038ECEC8>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))\n",
      "9962 трансляция\n",
      "9963 угадывать\n",
      "9964 укоротить\n",
      "9965 упрощенный\n",
      "9966 упускать\n",
      "9967 усилиться\n",
      "9968 утопить\n",
      "9969 хирургический\n",
      "9970 ценовой\n",
      "9971 центнер\n",
      "9972 шнурок\n",
      "9973 эксплуатировать\n",
      "9974 автопилот\n",
      "9975 арестовывать\n",
      "9976 барин\n",
      "9977 беспомощно\n",
      "9978 бессонный\n",
      "9979 биолог\n",
      "9980 богослов\n",
      "9981 бродяга\n",
      "9982 бульдозер\n",
      "9983 бюст\n",
      "9984 взмахнуть\n",
      "9985 виновный\n",
      "9986 вольно\n",
      "9987 впустить\n",
      "9988 выкуп\n",
      "9989 выстраиваться\n",
      "9990 глобализация\n",
      "9991 даровать\n",
      "9992 депо\n",
      "9993 дикарь\n",
      "9994 дискотека\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9995 душистый\n",
      "9996 заемщик\n",
      "9997 застонать\n",
      "9998 заход\n",
      "9999 имитировать\n",
      "10000 исправно\n",
      "10001 королевство\n",
      "10002 либерализм\n",
      "10003 мамонт\n",
      "10004 монастырский\n",
      "10005 нагреть\n",
      "10006 накапливаться\n",
      "10007 нарушаться\n",
      "10008 насмешливый\n",
      "10009 недоверчиво\n",
      "10010 необъятный\n",
      "10011 несовместимый\n",
      "10012 неясно\n",
      "10013 никель\n",
      "10014 ограбить\n",
      "10015 окончиться\n",
      "10016 оспаривать\n",
      "10017 отвод\n",
      "10018 отклонить\n",
      "10019 отсрочка\n",
      "10020 отставить\n",
      "10021 отчисление\n",
      "10022 охота\n",
      "10023 первобытный\n",
      "10024 побочный\n",
      "10025 погнать\n",
      "10026 помедлить\n",
      "10027 поменяться\n",
      "10028 пообщаться\n",
      "10029 поселить\n",
      "10030 посему\n",
      "10031 почуять\n",
      "10032 престарелый\n",
      "10033 присоединяться\n",
      "10034 продуктивный\n",
      "10035 пролетать\n",
      "10036 проситься\n",
      "10037 прославиться\n",
      "10038 публиковаться\n",
      "10039 пятилетний\n",
      "10040 развертывание\n",
      "10041 разлить\n",
      "10042 ремонтный\n",
      "10043 рентабельность\n",
      "10044 репортер\n",
      "10045 свекла\n",
      "10046 сервер\n",
      "10047 сложнейший\n",
      "10048 смертность\n",
      "10049 смещение\n",
      "10050 сносить\n",
      "10051 собрат\n",
      "10052 сопка\n",
      "10053 спрашиваться\n",
      "10054 створка\n",
      "10055 стекать\n",
      "10056 страничка\n",
      "10057 телогрейка\n",
      "10058 тетушка\n",
      "10059 треугольный\n",
      "10060 убеждаться\n",
      "10061 угловой\n",
      "10062 уголовник\n",
      "10063 укрыть\n",
      "10064 унизить\n",
      "10065 устремляться\n",
      "10066 целина\n",
      "10067 эпидемический\n",
      "10068 юго-восточный\n",
      "10069 автобусный\n",
      "10070 активизация\n",
      "10071 антигенный\n",
      "10072 банан\n",
      "10073 беда\n",
      "10074 блокада\n",
      "10075 брошюра\n",
      "10076 бумажник\n",
      "10077 вирусология\n",
      "10078 вкусно\n",
      "10079 водопад\n",
      "10080 возобновить\n",
      "10081 выемка\n",
      "10082 выспаться\n",
      "10083 двинуть\n",
      "10084 динамичный\n",
      "10085 житие\n",
      "10086 забвение\n",
      "10087 загрузка\n",
      "10088 замучить\n",
      "10089 затягивать\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-361-16da0927bf3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0macademic_ru_scrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in rnc_freq_list.iterrows():\n",
    "    print(index, row['Word'])\n",
    "    while True:\n",
    "        try:\n",
    "            [output_file.write(phrase + '\\n') for phrase in academic_ru_scrape(row['Word'])]\n",
    "            time.sleep(5)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Filter and format the phrases from dic.academic.ru and export filtered phrases to txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(proj_dir + '\\\\dic_academic_ru_phrases.txt', 'r', encoding='utf-8') as input_file:\n",
    "    with open(proj_dir + '\\\\dic_academic_ru_phrases_filtered.txt', 'w+', encoding='utf-8') as output_file:\n",
    "        \n",
    "        phrase_dict = {}\n",
    "        \n",
    "        for line in input_file.readlines():\n",
    "            if any(string in line for string in ['Перевод:',\n",
    "                                         'Толкование перевода',\n",
    "                                        'Толкование Перевод',\n",
    "                                         'Экспорт словарей на сайты',\n",
    "                                         'Пометить текст и поделиться']\n",
    "                  ) == False:\n",
    "                if bool(re.search(r'\\d[\\.\\)]', line)) == False:\n",
    "                    if bool(re.search(r'[а-яА-Я]', line)) == True:\n",
    "                        if len(line.strip().split(' ')) > 1:\n",
    "                            \n",
    "                            line = line.lower()\n",
    "                                    \n",
    "                            phrases = []\n",
    "                            for phrase in line.split(';'):\n",
    "                                \n",
    "                                phrase = re.sub(r'\\([^)]*\\)', '', phrase)\n",
    "                                phrase = re.sub(r'\\w+\\.\\s', '', phrase)\n",
    "                                phrase = re.sub(r'\\w+\\.\\;', ';', phrase)\n",
    "                                if phrase.startswith(('- ',' - ', '— ', ' — ', ' —  ')):\n",
    "                                    phrase = phrase[2:]\n",
    "                                    \n",
    "                                if bool(re.search(r'[а-яА-Я]+\\s[\\—\\-]\\s[a-zA-Z]+', phrase)) == True:\n",
    "                                    ru = re.split(r'\\s[\\—\\-]\\s', phrase)[0]\n",
    "                                    en = re.split(r'\\s[\\—\\-]\\s', phrase)[1]\n",
    "                                else:\n",
    "                                    if bool(re.search(r'[a-zA-Z]+\\s*[a-zA-Z]', phrase)) == True:\n",
    "                                        ru = re.sub(r'[a-zA-Z]+\\s*[a-zA-Z]', '', phrase)\n",
    "                                        en = re.findall(r'[a-zA-Z]+\\s*[a-zA-Z]', phrase)[0]\n",
    "                                    else:\n",
    "                                        ru = phrase\n",
    "                                        en = ''\n",
    "                                \n",
    "                                ru = ''.join([char for char in ru if char.isalpha() or \\\n",
    "                                                                    char.isspace() or \\\n",
    "                                                                    char == '-'])\n",
    "                                for key, value in {'о́' : 'о', 'я́' : 'я', 'и́' : 'и',\n",
    "                                                   'э́' : 'э', 'а́' : 'а', 'е' : 'е',\n",
    "                                                   'ы́' : 'ы', 'у́' : 'у'}.items():\n",
    "                                    if key in ru:\n",
    "                                        phrase = phrase.replace(key, value)\n",
    "                                phrase = re.sub(r'\\s+', ' ', ru)\n",
    "                                ru = ' ' + ru.strip() + ' '\n",
    "                                \n",
    "                                en = en.replace('\\n', '')\n",
    "                    \n",
    "                                if len(ru.strip().split(' ')) > 1:\n",
    "                            \n",
    "                                    if (ru not in phrase_dict) or (phrase_dict[ru] == ''):\n",
    "                                        phrase_dict[ru] = en\n",
    "                                        \n",
    "        for ru, en in phrase_dict.items():\n",
    "            output_file.write((ru + '||' + en).replace('\\n', '') + '\\n')\n",
    "            idiom_dict[ru] = {'Original ru phrase' : ru,\n",
    "                             'Eng tran' : en}\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Import dic.academic.ru filtered phrases by adding to idiom_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(proj_dir + '\\\\dic_academic_ru_phrases_filtered.txt', 'r', encoding='utf-8') as input_file:\n",
    "    for line in input_file:\n",
    "        ru = line.split('||')[0]\n",
    "        en = line.split('||')[1]\n",
    "        \n",
    "        idiom_dict[ru] = {'Original ru phrase' : ru,\n",
    "                     'Eng tran' : en}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Standardise and lemmatise idiom dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# REDUNDANT\n",
    "\n",
    "def standardise_idiom(ru_idiom, eng_tran):\n",
    "\n",
    "    return_dict = {}\n",
    "    \n",
    "    ru_phrase_for_lemming = ru_idiom.replace('    ', ' ')\n",
    "    ru_phrase_for_lemming = ru_phrase_for_lemming.replace('  ', ' ')\n",
    "    \n",
    "    ru_phrase_for_lemming = ru_phrase_for_lemming.replace('-', '/')\n",
    "    \n",
    "    ru_phrase_for_lemming = ru_phrase_for_lemming.replace('кого/н', 'кого-н').replace('кому/н', 'кому-н')\n",
    "    ru_phrase_for_lemming = ru_phrase_for_lemming.replace('что/н', 'что-н').replace('куда/нибудь', 'куда-нибудь')\n",
    "    ru_phrase_for_lemming = ru_phrase_for_lemming.replace(' чём/н', ' чём-н')\n",
    "    ru_phrase_for_lemming = ru_phrase_for_lemming.replace('из/за', 'из-за')\n",
    "    \n",
    "    print(ru_phrase_for_lemming)\n",
    "    \n",
    "    variants = []\n",
    "    \n",
    "    #Divide phrase syntax into multiple phrases where applicable:\n",
    "    \n",
    "    if '/' in ru_phrase_for_lemming:\n",
    "\n",
    "        phrase_ru_text_list = ru_phrase_for_lemming.split(' ')\n",
    "\n",
    "        print(phrase_ru_text_list)\n",
    "\n",
    "        idx = 0\n",
    "        for word in phrase_ru_text_list:\n",
    "\n",
    "            if '/' in word:\n",
    "                variant_words = word.split('/')\n",
    "                slash_word_index = idx\n",
    "                \n",
    "            idx += 1\n",
    "        \n",
    "        for variant_word in variant_words:\n",
    "            phrase_ru_text_list[slash_word_index] = variant_word\n",
    "            print(phrase_ru_text_list)\n",
    "            variants.append(' '.join(phrase_ru_text_list))\n",
    "\n",
    "    else:\n",
    "        variants.append(ru_phrase_for_lemming)\n",
    "        \n",
    "        \n",
    "    print(variants)\n",
    "        \n",
    "        \n",
    "    for variant in variants:\n",
    "    \n",
    "        ru_phrase_for_lemming = variant.replace('(perf)', '').replace('(impf)', '')\n",
    "\n",
    "        ru_phrase_for_lemming = ru_phrase_for_lemming.replace('о́','о').replace('ы́','ы').replace('а́','а').replace('у́','у').replace('и́','и').replace('я́','я').replace('е́','е').replace('ю́','ю').replace('э́','э')\n",
    "        ru_phrase_for_lemming = ru_phrase_for_lemming.replace('кого-н', '').replace('кому-н', '')\n",
    "        ru_phrase_for_lemming = ru_phrase_for_lemming.replace('что-н', '').replace('кого-н', '').replace('куда-нибудь', '')\n",
    "        ru_phrase_for_lemming = ru_phrase_for_lemming.replace('чём-н', '')\n",
    "        ru_phrase_for_lemming = ru_phrase_for_lemming.replace('  +instr ', '').replace('+gen', '').replace('+dat', '').replace('+infin', '')\n",
    "\n",
    "\n",
    "        lemmed_ru_phrase = lem_coll(ru_phrase_for_lemming)\n",
    "        \n",
    "        lemmed_ru_phrase = lemmed_ru_phrase.replace('  ', ' ')\n",
    "\n",
    "\n",
    "        return_dict[lemmed_ru_phrase] = {'Original ru phrase' : variant, 'Eng tran' : eng_tran}\n",
    "\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "standardise_idiom('приносить кого-н-что-н в жертву ', 'to sacrifice sb/sth ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original ru phrase': ' в перспективе ',\n",
       " 'Eng tran': 'over/in the long term, ultimately, going forward \\n'}"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idiom_dict[' в перспективе ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# RE-LEMMATISE THE IDIOM DICT SO THAT IT LEMMATISES EVERY WORD IN THE PHRASE:\n",
    "\n",
    "original_ru_phrase_list = []\n",
    "eng_tran_list = []\n",
    "\n",
    "for key, value in idiom_dict.items():\n",
    "    original_ru_phrase_list.append(value['Original ru phrase'])\n",
    "    eng_tran_list.append(value['Eng tran'])\n",
    "    \n",
    "idiom_dict_df = pd.DataFrame({'Original ru phrase' : original_ru_phrase_list,\n",
    "                              'Eng tran' : eng_tran_list                           \n",
    "                             }\n",
    "                            )\n",
    "\n",
    "def lem_coll_from_string(coll_string):\n",
    "    coll_string = ''.join([char for char in coll_string if char.isalpha() or \\\n",
    "                                                    char.isspace() or \\\n",
    "                                                    char == '-'])\n",
    "    coll_string = coll_string.strip()\n",
    "    coll_list = coll_string.split(' ')\n",
    "    lem_coll = ' '\n",
    "    for word in coll_list:\n",
    "        p = morph.parse(word)[0]\n",
    "        lem_coll += p.normal_form + ' '\n",
    "    # replace ё with е (to account for variations in spelling practices in para_texts_df)\n",
    "    lem_coll = lem_coll.replace('ё', 'е')\n",
    "    return lem_coll\n",
    "\n",
    "idiom_dict_df['Lemmed coll'] = idiom_dict_df['Original ru phrase'].apply(lem_coll_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original ru phrase</th>\n",
       "      <th>Eng tran</th>\n",
       "      <th>Lemmed coll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90020</th>\n",
       "      <td>pay  платить вперед  платить наличными деньгами</td>\n",
       "      <td>pay in cash \\n</td>\n",
       "      <td>pay  платить вперед  платить наличный деньга</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90021</th>\n",
       "      <td>платить дань  платить той же монетой</td>\n",
       "      <td></td>\n",
       "      <td>платить дань  платить тот же монета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90022</th>\n",
       "      <td>платить той же монетой</td>\n",
       "      <td></td>\n",
       "      <td>платить тот же монета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90023</th>\n",
       "      <td>платить за</td>\n",
       "      <td>w p\\n</td>\n",
       "      <td>платить за</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90024</th>\n",
       "      <td>акустическое нарушение</td>\n",
       "      <td></td>\n",
       "      <td>акустический нарушение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90025</th>\n",
       "      <td>противодействовать нарушению прав человека</td>\n",
       "      <td>to counteract the violation of human rights\\n</td>\n",
       "      <td>противодействовать нарушение право человек</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90026</th>\n",
       "      <td>в нарушение</td>\n",
       "      <td>in d\\n</td>\n",
       "      <td>в нарушение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90027</th>\n",
       "      <td>ответственность за нарушение обязательства</td>\n",
       "      <td>liability for the breach  of one's commitment \\n</td>\n",
       "      <td>ответственность за нарушение обязательство</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90028</th>\n",
       "      <td>нарушение действующего законодательства</td>\n",
       "      <td>breach  of current  legislation\\n</td>\n",
       "      <td>нарушение действующий законодательство</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90029</th>\n",
       "      <td>нарушение законных прав и интересов частных лиц</td>\n",
       "      <td>private wrongs\\n</td>\n",
       "      <td>нарушение законный право и интерес частное лицо</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Original ru phrase  \\\n",
       "90020   pay  платить вперед  платить наличными деньгами    \n",
       "90021              платить дань  платить той же монетой    \n",
       "90022                            платить той же монетой    \n",
       "90023                                        платить за    \n",
       "90024                            акустическое нарушение    \n",
       "90025        противодействовать нарушению прав человека    \n",
       "90026                                       в нарушение    \n",
       "90027        ответственность за нарушение обязательства    \n",
       "90028           нарушение действующего законодательства    \n",
       "90029   нарушение законных прав и интересов частных лиц    \n",
       "\n",
       "                                               Eng tran  \\\n",
       "90020                                    pay in cash \\n   \n",
       "90021                                                     \n",
       "90022                                                     \n",
       "90023                                             w p\\n   \n",
       "90024                                                     \n",
       "90025     to counteract the violation of human rights\\n   \n",
       "90026                                            in d\\n   \n",
       "90027  liability for the breach  of one's commitment \\n   \n",
       "90028                 breach  of current  legislation\\n   \n",
       "90029                                  private wrongs\\n   \n",
       "\n",
       "                                             Lemmed coll  \n",
       "90020      pay  платить вперед  платить наличный деньга   \n",
       "90021               платить дань  платить тот же монета   \n",
       "90022                             платить тот же монета   \n",
       "90023                                        платить за   \n",
       "90024                            акустический нарушение   \n",
       "90025        противодействовать нарушение право человек   \n",
       "90026                                       в нарушение   \n",
       "90027        ответственность за нарушение обязательство   \n",
       "90028            нарушение действующий законодательство   \n",
       "90029   нарушение законный право и интерес частное лицо   "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idiom_dict_df.iloc[90020:90030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original ru phrase</th>\n",
       "      <th>Eng tran</th>\n",
       "      <th>Lemmed coll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100843</th>\n",
       "      <td>в перспективе</td>\n",
       "      <td>over/in the long term, ultimately, going forwa...</td>\n",
       "      <td>в перспектива</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Original ru phrase                                           Eng tran  \\\n",
       "100843     в перспективе   over/in the long term, ultimately, going forwa...   \n",
       "\n",
       "            Lemmed coll  \n",
       "100843   в перспектива   "
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idiom_dict_df[idiom_dict_df['Lemmed coll']==' еще бы ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Export idiom_dict_df to csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idiom_dict_df.to_csv('C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy\\\\Russian Vocab Project\\\\idiom_dict_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Export idiom dictionary to txt file (redundant):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy/ru_phrases_file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-432-dc93c2f36713>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproj_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/ru_phrases_file.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproj_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/lemmed_ru_phrases_file.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfile_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\MdeCL\\\\Google Drive\\\\Work, productivity and interests_\\\\computer science\\\\coding skills (technical)\\\\VS Code project files\\\\NLP-powered Vocab Learning Strategy/ru_phrases_file.txt'"
     ]
    }
   ],
   "source": [
    "with open(proj_dir + '/ru_phrases_file.txt', 'r') as file:\n",
    "    \n",
    "    output_file = open(proj_dir + '/lemmed_ru_phrases_file.txt', 'w+')\n",
    "    \n",
    "    file_read = file.read()\n",
    "    lines = file_read.split('\\n')\n",
    "    idx = 1\n",
    "    for line in lines:\n",
    "        \n",
    "        if line != '':\n",
    "        \n",
    "            ru_phrase = line.split('£')[0]\n",
    "\n",
    "            eng_phrase = line.split('£')[1]\n",
    "            \n",
    "            lemmed_ru_phrase_dict = standardise_idiom(ru_phrase, eng_phrase)\n",
    "            \n",
    "            for key,value in lemmed_ru_phrase_dict.items():\n",
    "                \n",
    "                lemmed_ru_phrase = key\n",
    "                ru_phrase = value['Original ru phrase']\n",
    "                eng_phrase = value['Eng tran']\n",
    "            \n",
    "                output_file.write(lemmed_ru_phrase + '£' + ru_phrase + '£' + eng_phrase + '\\n')\n",
    "\n",
    "        idx += 1\n",
    "    \n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_texts_df[para_texts_df['Lemmed source sentence'].str.contains(' выйти за рамка ', regex=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnc_freq_list[rnc_freq_list['Estimated frequency']>=1780]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform analysis of each term in frequency list and write flashcards:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the info about a word in the corpus and otherwise online:\n",
    "- Semantic analysis\n",
    "- Collocational analysis\n",
    "- Grammatical analysis\n",
    "- Register / genre analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_en_note_type = genanki.Model(\n",
    "  1607392319,\n",
    "  'TL-EN TYPE TEST v3',\n",
    "  fields=[\n",
    "    {'name': 'Scaled frequency'},\n",
    "    {'name' : 'Frequency rank'},\n",
    "    {'name' : 'Term/collocation test'},\n",
    "    {'name': 'Question'},\n",
    "    {'name': 'Answer'},\n",
    "    {'name': 'Term with accent'},\n",
    "    {'name': 'Distinguishing grammatical info'},\n",
    "    {'name' : 'Conjugation and declension info'},\n",
    "    {'name' : 'Top three grammatical collocations'},\n",
    "    {'name': 'Definition being tested'},\n",
    "    {'name': 'Other definitions'},\n",
    "    {'name': 'Source sentence'},\n",
    "    {'name': 'Target sentence'},\n",
    "    {'name': 'Sentence source'},\n",
    "    {'name' : 'Other sentence pairs ru'},\n",
    "    {'name' : 'Other sentence pairs both'}\n",
    "  ],\n",
    "  templates=[\n",
    "    {\n",
    "      'name': 'TL-EN CARD TYPE',\n",
    "      'qfmt': '<font>{{Term/collocation test}}<br><br><font size=\"+6\">{{Term with accent}}</font><br><font size=\"-1\">{{Conjugation and declension info}}<br>{{Distinguishing grammatical info}}<br>{{Top three grammatical collocations}}<br><hr><font size=\"+1\"><font color=\"navy\"><b>____</b><br>{{Other definitions}}</font><br><hr>{{Source sentence}}{{type:Target sentence}}<br>{{Other sentence pairs ru}}</font>',\n",
    "      'afmt': '<font>{{Term/collocation test}}<br><br><font size=\"+6\">{{Term with accent}}</font><br><font size=\"-1\">{{Conjugation and declension info}}<br>{{Distinguishing grammatical info}}<br>{{Top three grammatical collocations}}<br><hr><font size=\"+1\"><font color=\"navy\"><b>{{Definition being tested}}</b><br>{{Other definitions}}</font><br><hr>{{Source sentence}}<br><font color=\"green\">{{Target sentence}}</font>{{type:Target sentence}}<br>{{Other sentence pairs both}}</font>',\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "en_tl_note_type = genanki.Model(\n",
    "  1607392320,\n",
    "  'EN-TL TYPE TEST v3',\n",
    "  fields=[\n",
    "    {'name': 'Scaled frequency'},\n",
    "    {'name' : 'Frequency rank'},\n",
    "    {'name' : 'Term/collocation test'},\n",
    "    {'name': 'Question'},\n",
    "    {'name': 'Answer'},\n",
    "    {'name': 'Term with accent'},\n",
    "    {'name': 'Distinguishing grammatical info'},\n",
    "    {'name' : 'Conjugation and declension info'},\n",
    "    {'name' : 'Top three grammatical collocations'},\n",
    "    {'name': 'Definition being tested'},\n",
    "    {'name': 'Other definitions'},\n",
    "    {'name': 'Source sentence'},\n",
    "    {'name': 'Target sentence'},\n",
    "    {'name': 'Sentence source'},\n",
    "    {'name' : 'Other sentence pairs en'},\n",
    "    {'name' : 'Other sentence pairs both'}\n",
    "  ],\n",
    "  templates=[\n",
    "    {\n",
    "      'name': 'EN-TL CARD TYPE',\n",
    "      'qfmt': '<font>{{Term/collocation test}}<br><br><font size=\"+6\">______</font><br><br><font size=\"-1\">{{Distinguishing grammatical info}}<br><hr><font size=\"+1\"><font color=\"navy\"><b>{{Definition being tested}}</b><br>{{Other definitions}}</font><br><hr>{{Target sentence}}{{type:Source sentence}}<br>{{Other sentence pairs en}}</font>',\n",
    "      'afmt': '<font>{{Term/collocation test}}<br><br><font size=\"+6\">{{Term with accent}}</font><br><font size=\"-1\">{{Conjugation and declension info}}<br>{{Distinguishing grammatical info}}<br>{{Top three grammatical collocations}}<br><hr><font size=\"+1\"><font color=\"navy\"><b>{{Definition being tested}}</b><br>{{Other definitions}}</font><br><hr>{{Target sentence}}<br><font color=\"green\">{{Source sentence}}</font>{{type:Source sentence}}<br>{{Other sentence pairs both}}</font>',\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency rank</th>\n",
       "      <th>Estimated frequency</th>\n",
       "      <th>Word</th>\n",
       "      <th>PoS tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14046</th>\n",
       "      <td>14047</td>\n",
       "      <td>303</td>\n",
       "      <td>иней</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frequency rank  Estimated frequency  Word PoS tag\n",
       "14046           14047                  303  иней    noun"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnc_freq_list[rnc_freq_list['Word']=='иней']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "colls_written_to_cards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n",
      "мысленно\n",
      "TERM ESTIMATED FREQUENCY: 2341\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: мысленно\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 132\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 132\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' \"mentally, in one's mind\"]\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "mentally, in one's mind    20\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: mentally, in one's mind\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 20\n",
      "ESTIMATED ENG DEF FREQUENCY: 2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:269: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:271: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: мысленно в <font color=\"blue\">loct</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 18\n",
      "\tLEMMED COLLOCATION: ('просто', 'хотеть', 'мысленно', 'подготовить')\n",
      "\tORIGINAL COLLOCATION: ('просто', 'хочу', 'мысленно', 'подготовить')\n",
      "\tCARD FREQUENCY: 2341\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "112\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4501\n",
      "наверх\n",
      "TERM ESTIMATED FREQUENCY: 2339\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: наверх\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1940\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1940\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS_DF.UNIQUE() ['up(ward); upstairs (по лестнице); to the top' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "up(ward); upstairs (по лестнице); to the top    335\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: up(ward); upstairs (по лестнице); to the top\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 335\n",
      "ESTIMATED ENG DEF FREQUENCY: 2339\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: наверх в accs 3 | наверх на <font color=\"green\">gent</font> 1 | наверх на accs 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 40\n",
      "\tSCALED FREQUENCY: 234\n",
      "\tLEMMED COLLOCATION: ('подняться', 'наверх')\n",
      "\tORIGINAL COLLOCATION: ('поднялась', 'наверх')\n",
      "\tCARD FREQUENCY: 2339\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "65\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4502\n",
      "отмена\n",
      "TERM ESTIMATED FREQUENCY: 2339\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: отмена\n",
      "TERM'S INFLECTED FORMS: отмены, отмен, отменам, отмены, отменами, отменах, отмена, отмены, отмене, отмену, отменой, отмене\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 572\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 572\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'abolition' 'abrogation, repeal, revocation'\n",
      " 'cancellation, countermand (о приказании || of an order); disaffirmation юр. (о решении || of a judgement)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "abolition                                                                                                    76\n",
      "abrogation, repeal, revocation                                                                               29\n",
      "cancellation, countermand (о приказании || of an order); disaffirmation юр. (о решении || of a judgement)    17\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: abolition\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 76\n",
      "ESTIMATED ENG DEF FREQUENCY: 2339\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: об отмене 10 | к отмене 9 | за отмену 7\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 40\n",
      "\tSCALED FREQUENCY: 234\n",
      "\tLEMMED COLLOCATION: ('отмена', 'смертный', 'казнь')\n",
      "\tORIGINAL COLLOCATION: ('отмены', 'смертной', 'казни')\n",
      "\tCARD FREQUENCY: 2339\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: abrogation, repeal, revocation\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 29\n",
      "ESTIMATED ENG DEF FREQUENCY: 170\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: cancellation, countermand (о приказании || of an order); disaffirmation юр. (о решении || of a judgement)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 17\n",
      "ESTIMATED ENG DEF FREQUENCY: 99\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "278\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4503\n",
      "отправлять\n",
      "TERM ESTIMATED FREQUENCY: 2336\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: отправлять\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">отправля́ю</font>, <font color=\"orange\">отправля́ешь</font>, <font color=\"orange\">отправля́ет</font>, <font color=\"orange\">отправля́ем</font>, <font color=\"orange\">отправля́ете</font>, <font color=\"orange\">отправля́ют</font>, <font color=\"orange\">отправля́й</font>, <font color=\"orange\">отправля́йте</font>, <font color=\"orange\">отправля́л бы</font>, <font color=\"orange\">отправля́ла бы</font>, <font color=\"orange\">отправля́ло бы</font>, <font color=\"orange\">отправля́ли бы</font>, <font color=\"orange\">отправля́ющий</font>, <font color=\"orange\">отправля́вший</font>, <font color=\"orange\">отправля́емый</font>, <font color=\"orange\">—</font>, <font color=\"orange\">отправля́я</font>, <font color=\"orange\">отправля́в</font>, <font color=\"orange\">отправля́л</font>, <font color=\"orange\">отправля́ла</font>, <font color=\"orange\">отправля́ло</font>, <font color=\"orange\">отправля́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1843\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1843\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MdeCL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'send, dispatch, forward; mail; post брит.'\n",
      " '(исполнять) exercise, perform; discharge']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "send, dispatch, forward; mail; post брит.    273\n",
      "(исполнять) exercise, perform; discharge      14\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: send, dispatch, forward; mail; post брит.\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 273\n",
      "ESTIMATED ENG DEF FREQUENCY: 2336\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: отправляй в accs 7 | отправляем на accs 5 | отправлять за accs 3\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 10\n",
      "\tSCALED FREQUENCY: 58\n",
      "\tLEMMED COLLOCATION: ('отправлять', 'письмо')\n",
      "\tORIGINAL COLLOCATION: ('отправляю', 'письма')\n",
      "\tCARD FREQUENCY: 2336\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: (исполнять) exercise, perform; discharge\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 14\n",
      "ESTIMATED ENG DEF FREQUENCY: 82\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "113\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4504\n",
      "побег\n",
      "TERM ESTIMATED FREQUENCY: 2336\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: побег\n",
      "TERM'S INFLECTED FORMS: побеги, побегов, побегам, побеги, побегами, побегах, побег, побега, побегу, побег, побегом, побеге\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1165\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1165\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['escape, flight' 'Unmatched' 'shoot, sprout; sucker; set; graft']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "escape, flight                       176\n",
      "shoot, sprout; sucker; set; graft      9\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: escape, flight\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 176\n",
      "ESTIMATED ENG DEF FREQUENCY: 2336\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: для побега 10 | в побеге 6 | с побегом 6\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 19\n",
      "\tSCALED FREQUENCY: 111\n",
      "\tLEMMED COLLOCATION: ('план', 'побег')\n",
      "\tORIGINAL COLLOCATION: ('план', 'побега')\n",
      "\tCARD FREQUENCY: 2336\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: shoot, sprout; sucker; set; graft\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 9\n",
      "ESTIMATED ENG DEF FREQUENCY: 53\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "215\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4505\n",
      "ползти\n",
      "TERM ESTIMATED FREQUENCY: 2336\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: ползти\n",
      "TERM'S INFLECTED FORMS: <font color=\"firebrick\">ползу́</font>, <font color=\"firebrick\">ползёшь</font>, <font color=\"firebrick\">ползёт</font>, <font color=\"firebrick\">ползём</font>, <font color=\"firebrick\">ползёте</font>, <font color=\"firebrick\">ползу́т</font>, <font color=\"firebrick\">ползи́</font>, <font color=\"firebrick\">ползи́те</font>, <font color=\"firebrick\">по́лз бы</font>, <font color=\"firebrick\">ползла́ бы</font>, <font color=\"firebrick\">ползло́ бы</font>, <font color=\"firebrick\">ползли́ бы</font>, <font color=\"firebrick\">ползу́щий</font>, <font color=\"firebrick\">по́лзший</font>, <font color=\"firebrick\">—</font>, <font color=\"firebrick\"></font>, <font color=\"firebrick\">ползя́</font>, <font color=\"firebrick\">по́лзши</font>, <font color=\"firebrick\">по́лз</font>, <font color=\"firebrick\">ползла́</font>, <font color=\"firebrick\">ползло́</font>, <font color=\"firebrick\">ползли́</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 195\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 195\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'slip, collapse' 'fray, ravel out' 'spread']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "slip, collapse     5\n",
      "spread             1\n",
      "fray, ravel out    1\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: slip, collapse\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 5\n",
      "ESTIMATED ENG DEF FREQUENCY: 2336\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: ползёт по <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 12\n",
      "\tLEMMED COLLOCATION: ('начало', 'ползти', 'к', 'алтарь')\n",
      "\tORIGINAL COLLOCATION: ('начала', 'ползти', 'к', 'алтарю')\n",
      "\tCARD FREQUENCY: 2336\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: spread\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 1\n",
      "ESTIMATED ENG DEF FREQUENCY: 12\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: fray, ravel out\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 1\n",
      "ESTIMATED ENG DEF FREQUENCY: 12\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "188\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4506\n",
      "провал\n",
      "TERM ESTIMATED FREQUENCY: 2335\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: провал\n",
      "TERM'S INFLECTED FORMS: провалы, провалов, провалам, провалы, провалами, провалах, провал, провала, провалу, провал, провалом, провале\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 954\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 954\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'failure; flop театр' 'lapse' 'collapse'\n",
      " '(яма) depression, hole; театр (люк) vampire']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "failure; flop театр                            151\n",
      "(яма) depression, hole; театр (люк) vampire      6\n",
      "lapse                                            5\n",
      "collapse                                         3\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: failure; flop театр\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 151\n",
      "ESTIMATED ENG DEF FREQUENCY: 2335\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: на провал 16 | к провалу 5 | за провал 3\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 14\n",
      "\tSCALED FREQUENCY: 82\n",
      "\tLEMMED COLLOCATION: ('полный', 'провал')\n",
      "\tORIGINAL COLLOCATION: ('полного', 'провала')\n",
      "\tCARD FREQUENCY: 2335\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: (яма) depression, hole; театр (люк) vampire\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 6\n",
      "ESTIMATED ENG DEF FREQUENCY: 35\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: lapse\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 5\n",
      "ESTIMATED ENG DEF FREQUENCY: 29\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 4\n",
      "ENG DEF: collapse\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 3\n",
      "ESTIMATED ENG DEF FREQUENCY: 18\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4507\n",
      "разряд\n",
      "TERM ESTIMATED FREQUENCY: 2335\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: разряд\n",
      "TERM'S INFLECTED FORMS: разряды, разрядов, разрядам, разряды, разрядами, разрядах, разряд, разряда, разряду, разряд, разрядом, разряде\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 460\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 460\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'grade, class, rating' 'discharge'\n",
      " 'category, class; rank, sort']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "grade, class, rating           88\n",
      "category, class; rank, sort    33\n",
      "discharge                      13\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: grade, class, rating\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 88\n",
      "ESTIMATED ENG DEF FREQUENCY: 2335\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: разряда для <font color=\"green\">gent</font> 5 | к разряду 2 | в разряд 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 36\n",
      "\tSCALED FREQUENCY: 210\n",
      "\tLEMMED COLLOCATION: ('местный', 'разряд')\n",
      "\tORIGINAL COLLOCATION: ('местный', 'разряд')\n",
      "\tCARD FREQUENCY: 2335\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: category, class; rank, sort\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 33\n",
      "ESTIMATED ENG DEF FREQUENCY: 193\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: discharge\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 13\n",
      "ESTIMATED ENG DEF FREQUENCY: 76\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "266\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4508\n",
      "ракетный\n",
      "TERM ESTIMATED FREQUENCY: 2331\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: ракетный\n",
      "TERM'S INFLECTED FORMS: ракетнее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 303\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 303\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['rocket(-powered); missile; jet' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "rocket(-powered); missile; jet    215\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: rocket(-powered); missile; jet\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 215\n",
      "ESTIMATED ENG DEF FREQUENCY: 2331\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 18\n",
      "\tSCALED FREQUENCY: 138\n",
      "\tLEMMED COLLOCATION: ('ракетный', 'топливо')\n",
      "\tORIGINAL COLLOCATION: ('ракетное', 'топливо')\n",
      "\tCARD FREQUENCY: 2331\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "88\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4509\n",
      "сходство\n",
      "TERM ESTIMATED FREQUENCY: 2331\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: сходство\n",
      "TERM'S INFLECTED FORMS: сходства, сходств, сходствам, сходства, сходствами, сходствах, сходство, сходства, сходству, сходство, сходством, сходстве\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 304\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 304\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['similarity, likeness, resemblance' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "similarity, likeness, resemblance    214\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: similarity, likeness, resemblance\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 214\n",
      "ESTIMATED ENG DEF FREQUENCY: 2331\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: сходства с <font color=\"aqua\">ablt</font> 10 | о сходстве 5 | сходство с accs 5\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 17\n",
      "\tSCALED FREQUENCY: 130\n",
      "\tLEMMED COLLOCATION: ('семейный', 'сходство')\n",
      "\tORIGINAL COLLOCATION: ('семейное', 'сходство')\n",
      "\tCARD FREQUENCY: 2331\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "90\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4510\n",
      "тыл\n",
      "TERM ESTIMATED FREQUENCY: 2331\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: тыл\n",
      "TERM'S INFLECTED FORMS: тылы, тылов, тылам, тылы, тылами, тылах, тыл<font size=\"+5\" color=\"purple\">у</font>, тылу, тыл, тыла, тылу, тыл, тылом, тыле\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 229\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 229\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' '(задняя сторона чего-л.) back, rear']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "(задняя сторона чего-л.) back, rear    149\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: (задняя сторона чего-л.) back, rear\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 149\n",
      "ESTIMATED ENG DEF FREQUENCY: 2331\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: в тыл 42 | с тыла 39 | за тылом 7\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: gram without case ahead\n",
      "\tRAW FREQUENCY: 42\n",
      "\tSCALED FREQUENCY: 428\n",
      "\tLEMMED COLLOCATION: ('в', 'тыл')\n",
      "\tORIGINAL COLLOCATION: ('в', 'тыл')\n",
      "\tCARD FREQUENCY: 2331\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "80\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4511\n",
      "упустить\n",
      "TERM ESTIMATED FREQUENCY: 2326\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: упустить\n",
      "REROUTING...\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: упускать\n",
      "TERM'S INFLECTED FORMS: <font color=\"blue\">упущу́</font>, <font color=\"blue\">упу́стишь</font>, <font color=\"blue\">упу́стит</font>, <font color=\"blue\">упу́стим</font>, <font color=\"blue\">упу́стите</font>, <font color=\"blue\">упу́стят</font>, <font color=\"blue\">упусти́</font>, <font color=\"blue\">упусти́те</font>, <font color=\"blue\">упусти́л бы</font>, <font color=\"blue\">упусти́ла бы</font>, <font color=\"blue\">упусти́ло бы</font>, <font color=\"blue\">упусти́ли бы</font>, <font color=\"blue\">—</font>, <font color=\"blue\">упусти́вший</font>, <font color=\"blue\"></font>, <font color=\"blue\">упу́щенный</font>, <font color=\"blue\"></font>, <font color=\"blue\">упусти́в</font>, <font color=\"blue\">упусти́л</font>, <font color=\"blue\">упусти́ла</font>, <font color=\"blue\">упусти́ло</font>, <font color=\"blue\">упусти́ли</font>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 2452\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 2452\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['(терять) miss; (не замечать) overlook' 'Unmatched' 'let go / slip']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "(терять) miss; (не замечать) overlook    236\n",
      "let go / slip                              6\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: (терять) miss; (не замечать) overlook\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 236\n",
      "ESTIMATED ENG DEF FREQUENCY: 2326\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: упущенная в accs 1 | упустили в <font color=\"blue\">loct</font> 1 | упустили в <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 14\n",
      "\tSCALED FREQUENCY: 81\n",
      "\tLEMMED COLLOCATION: ('упустить', 'возможность')\n",
      "\tORIGINAL COLLOCATION: ('упустите', 'возможности')\n",
      "\tCARD FREQUENCY: 2326\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: let go / slip\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 6\n",
      "ESTIMATED ENG DEF FREQUENCY: 35\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "158\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4512\n",
      "ученый\n",
      "TERM ESTIMATED FREQUENCY: 2323\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: ученый\n",
      "TERM'S INFLECTED FORMS: учёнее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1831\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1831\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'scientist; scholar' '(относящийся к науке) scientific'\n",
      " '(о человеке || of a person) learned, erudite']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "scientist; scholar                              165\n",
      "(о человеке || of a person) learned, erudite      7\n",
      "(относящийся к науке) scientific                  5\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: scientist; scholar\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 165\n",
      "ESTIMATED ENG DEF FREQUENCY: 2323\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: ученый в <font color=\"green\">gent</font> 3 | ученого по accs 2 | ученым в <font color=\"blue\">loct</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 5\n",
      "\tSCALED FREQUENCY: 29\n",
      "\tLEMMED COLLOCATION: ('великий', 'учёный')\n",
      "\tORIGINAL COLLOCATION: ('великий', 'учёный')\n",
      "\tCARD FREQUENCY: 2323\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: (о человеке || of a person) learned, erudite\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 7\n",
      "ESTIMATED ENG DEF FREQUENCY: 41\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: (относящийся к науке) scientific\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 5\n",
      "ESTIMATED ENG DEF FREQUENCY: 29\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "223\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4513\n",
      "аж\n",
      "TERM ESTIMATED FREQUENCY: 2322\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: аж\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 502\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 502\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'частица; прост. even']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "частица; прост. even    10\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: частица; прост. even\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 10\n",
      "ESTIMATED ENG DEF FREQUENCY: 2322\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 6\n",
      "\tLEMMED COLLOCATION: ('на', 'ты', ',', 'аж', 'в')\n",
      "\tORIGINAL COLLOCATION: ('на', 'тебя', ',', 'аж', 'в')\n",
      "\tCARD FREQUENCY: 2322\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "390\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4514\n",
      "базар\n",
      "TERM ESTIMATED FREQUENCY: 2322\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: базар\n",
      "TERM'S INFLECTED FORMS: базары, базаров, базарам, базары, базарами, базарах, базар, базара, базару, базар, базаром, базаре\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 183\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 183\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched'\n",
      " 'market; bazaar (на Востоке; тж. благотворительный и т. п. || in the East; also charitable, etc.)'\n",
      " '(предпраздничный, сезонный) fair; sale' 'разг. (разговор) chat; talk'\n",
      " 'перен.; разг. revel, row, uproar; beargarden']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "market; bazaar (на Востоке; тж. благотворительный и т. п. || in the East; also charitable, etc.)    90\n",
      "разг. (разговор) chat; talk                                                                         10\n",
      "(предпраздничный, сезонный) fair; sale                                                               4\n",
      "перен.; разг. revel, row, uproar; beargarden                                                         2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: market; bazaar (на Востоке; тж. благотворительный и т. п. || in the East; also charitable, etc.)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 90\n",
      "ESTIMATED ENG DEF FREQUENCY: 2322\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: на базарах 39 | через базар 2 | за базар 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: gram without case ahead\n",
      "\tRAW FREQUENCY: 39\n",
      "\tSCALED FREQUENCY: 495\n",
      "\tLEMMED COLLOCATION: ('на', 'базар')\n",
      "\tORIGINAL COLLOCATION: ('на', 'базарах')\n",
      "\tCARD FREQUENCY: 2322\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: разг. (разговор) chat; talk\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 10\n",
      "ESTIMATED ENG DEF FREQUENCY: 127\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: (предпраздничный, сезонный) fair; sale\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 4\n",
      "ESTIMATED ENG DEF FREQUENCY: 51\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 4\n",
      "ENG DEF: перен.; разг. revel, row, uproar; beargarden\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 25\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4515\n",
      "болтать\n",
      "TERM ESTIMATED FREQUENCY: 2321\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: болтать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">болта́ю</font>, <font color=\"orange\">болта́ешь</font>, <font color=\"orange\">болта́ет</font>, <font color=\"orange\">болта́ем</font>, <font color=\"orange\">болта́ете</font>, <font color=\"orange\">болта́ют</font>, <font color=\"orange\">болта́й</font>, <font color=\"orange\">болта́йте</font>, <font color=\"orange\">болта́л бы</font>, <font color=\"orange\">болта́ла бы</font>, <font color=\"orange\">болта́ло бы</font>, <font color=\"orange\">болта́ли бы</font>, <font color=\"orange\">болта́ющий</font>, <font color=\"orange\">болта́вший</font>, <font color=\"orange\">болта́емый</font>, <font color=\"orange\">бо́лтанный</font>, <font color=\"orange\">болта́я</font>, <font color=\"orange\">болта́в</font>, <font color=\"orange\">болта́л</font>, <font color=\"orange\">болта́ла</font>, <font color=\"orange\">болта́ло</font>, <font color=\"orange\">болта́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 2028\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 2028\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched'\n",
      " 'chat(ter), jabber, natter, gabble; to babble, twaddle (бестолково, невнятно); prattle (о детской речи || of the chatter of children)'\n",
      " 'dangle (руками или ногами || by arms or legs)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "chat(ter), jabber, natter, gabble; to babble, twaddle (бестолково, невнятно); prattle (о детской речи || of the chatter of children)    37\n",
      "dangle (руками или ногами || by arms or legs)                                                                                            2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: chat(ter), jabber, natter, gabble; to babble, twaddle (бестолково, невнятно); prattle (о детской речи || of the chatter of children)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 37\n",
      "ESTIMATED ENG DEF FREQUENCY: 2321\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: болтать до <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 3\n",
      "\tSCALED FREQUENCY: 17\n",
      "\tLEMMED COLLOCATION: ('много', 'болтать')\n",
      "\tORIGINAL COLLOCATION: ('много', 'болтаешь')\n",
      "\tCARD FREQUENCY: 2321\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: dangle (руками или ногами || by arms or legs)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 12\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "361\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4516\n",
      "бревно\n",
      "TERM ESTIMATED FREQUENCY: 2321\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: бревно\n",
      "TERM'S INFLECTED FORMS: бр<font size=\"+5\" color=\"blue\">ё</font>вна, брёвен, брёвнам, брёвна, брёвнами, брёвнах, бревно, бревна, бревну, бревно, бревном, бревне\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 225\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 225\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['log; beam; dullard, numskull перен.; balance beam (гимнастический снаряд)'\n",
      " 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "log; beam; dullard, numskull перен.; balance beam (гимнастический снаряд)    129\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: log; beam; dullard, numskull перен.; balance beam (гимнастический снаряд)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 129\n",
      "ESTIMATED ENG DEF FREQUENCY: 2321\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: на бревне 19 | с бревнами 5 | из бревен 4\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 3\n",
      "\tSCALED FREQUENCY: 31\n",
      "\tLEMMED COLLOCATION: ('пиломатериал', 'и', 'бревно')\n",
      "\tORIGINAL COLLOCATION: ('пиломатериалы', 'и', 'бревна')\n",
      "\tCARD FREQUENCY: 2321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "96\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4517\n",
      "вспыхнуть\n",
      "TERM ESTIMATED FREQUENCY: 2321\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: вспыхнуть\n",
      "REROUTING...\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: вспыхивать\n",
      "TERM'S INFLECTED FORMS: <font color=\"purple\">вспы́хну</font>, <font color=\"purple\">вспы́хнешь</font>, <font color=\"purple\">вспы́хнет</font>, <font color=\"purple\">вспы́хнем</font>, <font color=\"purple\">вспы́хнете</font>, <font color=\"purple\">вспы́хнут</font>, <font color=\"purple\">вспы́хни</font>, <font color=\"purple\">вспы́хните</font>, <font color=\"purple\">вспы́хнул бы</font>, <font color=\"purple\">вспы́хнула бы</font>, <font color=\"purple\">вспы́хнуло бы</font>, <font color=\"purple\">вспы́хнули бы</font>, <font color=\"purple\">—</font>, <font color=\"purple\">вспы́хнувший</font>, <font color=\"purple\"></font>, <font color=\"purple\"></font>, <font color=\"purple\"></font>, <font color=\"purple\">вспы́хнув</font>, <font color=\"purple\">вспы́хнул</font>, <font color=\"purple\">вспы́хнула</font>, <font color=\"purple\">вспы́хнуло</font>, <font color=\"purple\">вспы́хнули</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 186\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 186\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched'\n",
      " 'blaze up, take fire (воспламеняться); break out (о пожаре || of fire); flare up (о пламени); flash (out) (об огнях || of lights)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "blaze up, take fire (воспламеняться); break out (о пожаре || of fire); flare up (о пламени); flash (out) (об огнях || of lights)    1\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: blaze up, take fire (воспламеняться); break out (о пожаре || of fire); flare up (о пламени); flash (out) (об огнях || of lights)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 1\n",
      "ESTIMATED ENG DEF FREQUENCY: 2321\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: вспыхнул в accs 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 12\n",
      "\tLEMMED COLLOCATION: ('план', 'вспыхнуть')\n",
      "\tORIGINAL COLLOCATION: ('план', 'вспыхнул')\n",
      "\tCARD FREQUENCY: 2321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "185\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4518\n",
      "дежурный\n",
      "TERM ESTIMATED FREQUENCY: 2320\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: дежурный\n",
      "TERM'S INFLECTED FORMS: дежурн<font size=\"+5\" color=\"blue\">ые</font>, дежурные, дежурных, дежурным, дежурных, дежурными, дежурных, дежурный, дежурного, дежурному, дежурного, дежурным, дежурном\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 274\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 274\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'on duty; orderly воен.']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "on duty; orderly воен.    2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: on duty; orderly воен.\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 2320\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT GRAM COLLS BELOW MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR NO PUNCT COLLS\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: ignore\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 17\n",
      "\tLEMMED COLLOCATION: ('дежурный',)\n",
      "\tORIGINAL COLLOCATION: ('дежурным',)\n",
      "\tCARD FREQUENCY: 2320\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "272\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4519\n",
      "драма\n",
      "TERM ESTIMATED FREQUENCY: 2317\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: драма\n",
      "TERM'S INFLECTED FORMS: драмы, драм, драмам, драмы, драмами, драмах, драма, драмы, драме, драму, драмой, драме\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 737\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 737\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['drama' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "drama    315\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: drama\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 315\n",
      "ESTIMATED ENG DEF FREQUENCY: 2317\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: в драм 12 | без драмы 11 | с драмой 5\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 15\n",
      "\tSCALED FREQUENCY: 87\n",
      "\tLEMMED COLLOCATION: ('семейный', 'драма')\n",
      "\tORIGINAL COLLOCATION: ('семейных', 'драм')\n",
      "\tCARD FREQUENCY: 2317\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "85\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4520\n",
      "климат\n",
      "TERM ESTIMATED FREQUENCY: 2317\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: климат\n",
      "TERM'S INFLECTED FORMS: климаты, климатов, климатам, климаты, климатами, климатах, климат, климата, климату, климат, климатом, климате\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 928\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 928\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['climate' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "climate    310\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: climate\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 310\n",
      "ESTIMATED ENG DEF FREQUENCY: 2317\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: климата в <font color=\"green\">gent</font> 11 | по климату 8 | на климат 6\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 169\n",
      "\tSCALED FREQUENCY: 979\n",
      "\tLEMMED COLLOCATION: ('изменение', 'климат')\n",
      "\tORIGINAL COLLOCATION: ('изменение', 'климата')\n",
      "\tCARD FREQUENCY: 2317\n",
      "\n",
      "\n",
      "COLL INDEX: 1\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 169\n",
      "\tSCALED FREQUENCY: 979\n",
      "\tLEMMED COLLOCATION: ('изменение', 'климат')\n",
      "\tORIGINAL COLLOCATION: ('изменение', 'климата')\n",
      "\tCARD FREQUENCY: 979\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "90\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4521\n",
      "комсомольский\n",
      "TERM ESTIMATED FREQUENCY: 2316\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: комсомольский\n",
      "REROUTING...\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: комсомол\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 5\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 5\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'Komsomol, Young Commuinist League, YCL']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Komsomol, Young Commuinist League, YCL    2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: Komsomol, Young Commuinist League, YCL\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 2316\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 463\n",
      "\tLEMMED COLLOCATION: ('председатель', 'на', 'комсомольский', 'собрание')\n",
      "\tORIGINAL COLLOCATION: ('председателем', 'на', 'комсомольском', 'собрании')\n",
      "\tCARD FREQUENCY: 2316\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "3\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4522\n",
      "кончать\n",
      "TERM ESTIMATED FREQUENCY: 2316\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: кончать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">конча́ю</font>, <font color=\"orange\">конча́ешь</font>, <font color=\"orange\">конча́ет</font>, <font color=\"orange\">конча́ем</font>, <font color=\"orange\">конча́ете</font>, <font color=\"orange\">конча́ют</font>, <font color=\"orange\">конча́й</font>, <font color=\"orange\">конча́йте</font>, <font color=\"orange\">конча́л бы</font>, <font color=\"orange\">конча́ла бы</font>, <font color=\"orange\">конча́ло бы</font>, <font color=\"orange\">конча́ли бы</font>, <font color=\"orange\">конча́ющий</font>, <font color=\"orange\">конча́вший</font>, <font color=\"orange\">конча́емый</font>, <font color=\"orange\">—</font>, <font color=\"orange\">конча́я</font>, <font color=\"orange\">конча́в</font>, <font color=\"orange\">конча́л</font>, <font color=\"orange\">конча́ла</font>, <font color=\"orange\">конча́ло</font>, <font color=\"orange\">конча́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 521\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 521\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'stop, finish (doing smth.)' 'finish, end; graduate from']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "stop, finish (doing smth.)    65\n",
      "finish, end; graduate from    43\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: stop, finish (doing smth.)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 65\n",
      "ESTIMATED ENG DEF FREQUENCY: 2316\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: кончают с <font color=\"green\">gent</font> 1 | кончай с <font color=\"aqua\">ablt</font> 1 | кончаешь в accs 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 5\n",
      "\tSCALED FREQUENCY: 29\n",
      "\tLEMMED COLLOCATION: ('пора', 'кончать')\n",
      "\tORIGINAL COLLOCATION: ('пора', 'кончать')\n",
      "\tCARD FREQUENCY: 2316\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: finish, end; graduate from\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 43\n",
      "ESTIMATED ENG DEF FREQUENCY: 249\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4523\n",
      "набить\n",
      "TERM ESTIMATED FREQUENCY: 2314\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: набить\n",
      "TERM'S INFLECTED FORMS: <font color=\"firebrick\">набью́</font>, <font color=\"firebrick\">набьёшь</font>, <font color=\"firebrick\">набьёт</font>, <font color=\"firebrick\">набьём</font>, <font color=\"firebrick\">набьёте</font>, <font color=\"firebrick\">набью́т</font>, <font color=\"firebrick\">набе́й</font>, <font color=\"firebrick\">набе́йте</font>, <font color=\"firebrick\">наби́л бы</font>, <font color=\"firebrick\">наби́ла бы</font>, <font color=\"firebrick\">наби́ло бы</font>, <font color=\"firebrick\">наби́ли бы</font>, <font color=\"firebrick\">—</font>, <font color=\"firebrick\">наби́вший</font>, <font color=\"firebrick\"></font>, <font color=\"firebrick\">наби́тый</font>, <font color=\"firebrick\"></font>, <font color=\"firebrick\">наби́в</font>, <font color=\"firebrick\">наби́л</font>, <font color=\"firebrick\">наби́ла</font>, <font color=\"firebrick\">наби́ло</font>, <font color=\"firebrick\">наби́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 347\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 347\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'fix (on, to)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "fix (on, to)    64\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: fix (on, to)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 64\n",
      "ESTIMATED ENG DEF FREQUENCY: 2314\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: набили в <font color=\"blue\">loct</font> 2 | набил на accs 1 | набил на <font color=\"blue\">loct</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 6\n",
      "\tSCALED FREQUENCY: 40\n",
      "\tLEMMED COLLOCATION: ('набить', 'рука')\n",
      "\tORIGINAL COLLOCATION: ('набьешь', 'руку')\n",
      "\tCARD FREQUENCY: 2314\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "283\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4524\n",
      "наследник\n",
      "TERM ESTIMATED FREQUENCY: 2314\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: наследник\n",
      "TERM'S INFLECTED FORMS: наследники, наследников, наследникам, наследников, наследниками, наследниках, наследник, наследника, наследнику, наследника, наследником, наследнике\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 627\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 627\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'heir, legatee; successor перен. (преемник)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "heir, legatee; successor перен. (преемник)    289\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: heir, legatee; successor перен. (преемник)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 289\n",
      "ESTIMATED ENG DEF FREQUENCY: 2314\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: из наследников 5 | без наследника 3 | на наследнике 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 13\n",
      "\tSCALED FREQUENCY: 75\n",
      "\tLEMMED COLLOCATION: ('единственный', 'наследник')\n",
      "\tORIGINAL COLLOCATION: ('единственным', 'наследником')\n",
      "\tCARD FREQUENCY: 2314\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "111\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4525\n",
      "наследство\n",
      "TERM ESTIMATED FREQUENCY: 2313\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: наследство\n",
      "TERM'S INFLECTED FORMS: наследства, наследств, наследствам, наследства, наследствами, наследствах, наследство, наследства, наследству, наследство, наследством, наследстве\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 650\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 650\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['inheritance; legacy' 'Unmatched' 'перен. (наследие) heritage']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "inheritance; legacy           176\n",
      "перен. (наследие) heritage      8\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: inheritance; legacy\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 176\n",
      "ESTIMATED ENG DEF FREQUENCY: 2313\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: в наследство 11 | на наследство 9 | за наследство 6\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 5\n",
      "\tSCALED FREQUENCY: 29\n",
      "\tLEMMED COLLOCATION: ('налог', 'на', 'наследство')\n",
      "\tORIGINAL COLLOCATION: ('налог', 'на', 'наследство')\n",
      "\tCARD FREQUENCY: 2313\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: перен. (наследие) heritage\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 8\n",
      "ESTIMATED ENG DEF FREQUENCY: 46\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "216\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 64\n",
      "\tSCALED FREQUENCY: 370\n",
      "\tLEMMED COLLOCATION: ('по', 'наследство')\n",
      "\tORIGINAL COLLOCATION: ('по', 'наследству')\n",
      "\tCARD FREQUENCY: 370\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4526\n",
      "недвижимость\n",
      "TERM ESTIMATED FREQUENCY: 2313\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: недвижимость\n",
      "TERM'S INFLECTED FORMS: недвижимости, недвижимостей, недвижимостям, недвижимости, недвижимостями, недвижимостях, недвижимость, недвижимости, недвижимости, недвижимость, недвижимостью, недвижимости\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1001\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1001\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'immovable property, real estate, realty']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "immovable property, real estate, realty    10\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: immovable property, real estate, realty\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 10\n",
      "ESTIMATED ENG DEF FREQUENCY: 2313\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: из недвижимости 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 12\n",
      "\tLEMMED COLLOCATION: ('траст', 'недвижимость')\n",
      "\tORIGINAL COLLOCATION: ('траст', 'недвижимости')\n",
      "\tCARD FREQUENCY: 2313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "390\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4527\n",
      "ненужный\n",
      "TERM ESTIMATED FREQUENCY: 2312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: ненужный\n",
      "TERM'S INFLECTED FORMS: ненужнее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 448\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 448\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['unnecessary, needless; useless (бесполезный), unneeded' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "unnecessary, needless; useless (бесполезный), unneeded    158\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: unnecessary, needless; useless (бесполезный), unneeded\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 158\n",
      "ESTIMATED ENG DEF FREQUENCY: 2312\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 9\n",
      "\tSCALED FREQUENCY: 52\n",
      "\tLEMMED COLLOCATION: ('ненужный', 'страдание')\n",
      "\tORIGINAL COLLOCATION: ('ненужные', 'страдания')\n",
      "\tCARD FREQUENCY: 2312\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "242\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4528\n",
      "нить\n",
      "TERM ESTIMATED FREQUENCY: 2312\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: нить\n",
      "TERM'S INFLECTED FORMS: нити, нитей, нитям, нити, нитями, нитях, нить, нити, нити, нить, нитью, нити\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 531\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 531\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['filament' 'Unmatched' 'thread' 'suture']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "thread      83\n",
      "filament    40\n",
      "suture      11\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: thread\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 83\n",
      "ESTIMATED ENG DEF FREQUENCY: 2312\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: за нить 2 | с нитью 1 | от нити 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 4\n",
      "\tSCALED FREQUENCY: 23\n",
      "\tLEMMED COLLOCATION: ('игла', 'и', 'нить')\n",
      "\tORIGINAL COLLOCATION: ('иглой', 'и', 'нитью')\n",
      "\tCARD FREQUENCY: 2312\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: filament\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 40\n",
      "ESTIMATED ENG DEF FREQUENCY: 231\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: suture\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 11\n",
      "ESTIMATED ENG DEF FREQUENCY: 64\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "266\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4529\n",
      "опоздать\n",
      "TERM ESTIMATED FREQUENCY: 2310\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: опоздать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">опозда́ю</font>, <font color=\"orange\">опозда́ешь</font>, <font color=\"orange\">опозда́ет</font>, <font color=\"orange\">опозда́ем</font>, <font color=\"orange\">опозда́ете</font>, <font color=\"orange\">опозда́ют</font>, <font color=\"orange\">опозда́й</font>, <font color=\"orange\">опозда́йте</font>, <font color=\"orange\">опозда́л бы</font>, <font color=\"orange\">опозда́ла бы</font>, <font color=\"orange\">опозда́ло бы</font>, <font color=\"orange\">опозда́ли бы</font>, <font color=\"orange\">—</font>, <font color=\"orange\">опозда́вший</font>, <font color=\"orange\"></font>, <font color=\"orange\"></font>, <font color=\"orange\"></font>, <font color=\"orange\">опозда́в</font>, <font color=\"orange\">опозда́л</font>, <font color=\"orange\">опозда́ла</font>, <font color=\"orange\">опозда́ло</font>, <font color=\"orange\">опозда́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 2788\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 2788\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Series([], Name: English definition, dtype: int64)\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "400\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4530\n",
      "переработка\n",
      "TERM ESTIMATED FREQUENCY: 2309\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: переработка\n",
      "TERM'S INFLECTED FORMS: переработки, переработок, переработкам, переработки, переработками, переработках, переработка, переработки, переработке, переработку, переработкой, переработке\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 368\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 368\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'working (up), processing, treatment']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "working (up), processing, treatment    86\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: working (up), processing, treatment\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 86\n",
      "ESTIMATED ENG DEF FREQUENCY: 2309\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: по переработке 10 | для переработки 10 | на переработку 4\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 12\n",
      "\tSCALED FREQUENCY: 75\n",
      "\tLEMMED COLLOCATION: ('переработка', 'отход')\n",
      "\tORIGINAL COLLOCATION: ('переработки', 'отходов')\n",
      "\tCARD FREQUENCY: 2309\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "282\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4531\n",
      "полевой\n",
      "TERM ESTIMATED FREQUENCY: 2305\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: полевой\n",
      "TERM'S INFLECTED FORMS: полевее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 821\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 821\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['field' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "field    307\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: field\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 307\n",
      "ESTIMATED ENG DEF FREQUENCY: 2305\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 34\n",
      "\tSCALED FREQUENCY: 196\n",
      "\tLEMMED COLLOCATION: ('полевой', 'служба')\n",
      "\tORIGINAL COLLOCATION: ('полевой', 'службы')\n",
      "\tCARD FREQUENCY: 2305\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "93\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4532\n",
      "пропаганда\n",
      "TERM ESTIMATED FREQUENCY: 2303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: пропаганда\n",
      "TERM'S INFLECTED FORMS: пропаганды, пропаганд, пропагандам, пропаганды, пропагандами, пропагандах, пропаганда, пропаганды, пропаганде, пропаганду, пропагандой, пропаганде\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 535\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 535\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'information, teaching; propaganda; popularization']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "information, teaching; propaganda; popularization    159\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: information, teaching; propaganda; popularization\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 159\n",
      "ESTIMATED ENG DEF FREQUENCY: 2303\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: в пропаганде 4 | на пропаганду 3 | по пропаганде 3\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 8\n",
      "\tSCALED FREQUENCY: 46\n",
      "\tLEMMED COLLOCATION: ('расистский', 'пропаганда')\n",
      "\tORIGINAL COLLOCATION: ('расистской', 'пропагандой')\n",
      "\tCARD FREQUENCY: 2303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "241\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4533\n",
      "равновесие\n",
      "TERM ESTIMATED FREQUENCY: 2303\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: равновесие\n",
      "TERM'S INFLECTED FORMS: равновесия, равновесий, равновесиям, равновесия, равновесиями, равновесиях, равновесие, равновесия, равновесию, равновесие, равновесием, равновесии\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 430\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 430\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'balance, equilibrium прям. и перен.; equipoise']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "balance, equilibrium прям. и перен.; equipoise    267\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: balance, equilibrium прям. и перен.; equipoise\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 267\n",
      "ESTIMATED ENG DEF FREQUENCY: 2303\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: из равновесия 18 | с равновесием 7 | о равновесии 5\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 25\n",
      "\tSCALED FREQUENCY: 144\n",
      "\tLEMMED COLLOCATION: ('потерять', 'равновесие')\n",
      "\tORIGINAL COLLOCATION: ('потеряли', 'равновесие')\n",
      "\tCARD FREQUENCY: 2303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "133\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4534\n",
      "разрабатывать\n",
      "TERM ESTIMATED FREQUENCY: 2302\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: разрабатывать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">разраба́тываю</font>, <font color=\"orange\">разраба́тываешь</font>, <font color=\"orange\">разраба́тывает</font>, <font color=\"orange\">разраба́тываем</font>, <font color=\"orange\">разраба́тываете</font>, <font color=\"orange\">разраба́тывают</font>, <font color=\"orange\">разраба́тывай</font>, <font color=\"orange\">разраба́тывайте</font>, <font color=\"orange\">разраба́тывал бы</font>, <font color=\"orange\">разраба́тывала бы</font>, <font color=\"orange\">разраба́тывало бы</font>, <font color=\"orange\">разраба́тывали бы</font>, <font color=\"orange\">разраба́тывающий</font>, <font color=\"orange\">разраба́тывавший</font>, <font color=\"orange\">разраба́тываемый</font>, <font color=\"orange\">—</font>, <font color=\"orange\">разраба́тывая</font>, <font color=\"orange\">разраба́тывав</font>, <font color=\"orange\">разраба́тывал</font>, <font color=\"orange\">разраба́тывала</font>, <font color=\"orange\">разраба́тывало</font>, <font color=\"orange\">разраба́тывали</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 575\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 575\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['work out / up; elaborate (детально || in details); develop (планы || plans)'\n",
      " 'exploit, work (шахту || a mine); mine (минералы || a certain mineral)'\n",
      " 'Unmatched' 'cultivate; till' 'work up (into), process' 'exhaust']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "work out / up; elaborate (детально || in details); develop (планы || plans)    173\n",
      "exploit, work (шахту || a mine); mine (минералы || a certain mineral)           61\n",
      "work up (into), process                                                         10\n",
      "cultivate; till                                                                  4\n",
      "exhaust                                                                          1\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: work out / up; elaborate (детально || in details); develop (планы || plans)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 173\n",
      "ESTIMATED ENG DEF FREQUENCY: 2302\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: разрабатывать в <font color=\"green\">gent</font> 6 | разрабатывать для accs 2 | разрабатывать за <font color=\"aqua\">ablt</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 9\n",
      "\tSCALED FREQUENCY: 52\n",
      "\tLEMMED COLLOCATION: ('разрабатывать', 'план')\n",
      "\tORIGINAL COLLOCATION: ('разрабатывает', 'план')\n",
      "\tCARD FREQUENCY: 2302\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: exploit, work (шахту || a mine); mine (минералы || a certain mineral)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 61\n",
      "ESTIMATED ENG DEF FREQUENCY: 351\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: work up (into), process\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 10\n",
      "ESTIMATED ENG DEF FREQUENCY: 58\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 4\n",
      "ENG DEF: cultivate; till\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 4\n",
      "ESTIMATED ENG DEF FREQUENCY: 23\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 5\n",
      "ENG DEF: exhaust\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 1\n",
      "ESTIMATED ENG DEF FREQUENCY: 6\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "151\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4535\n",
      "синтез\n",
      "TERM ESTIMATED FREQUENCY: 2299\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: синтез\n",
      "TERM'S INFLECTED FORMS: синтезы, синтезов, синтезам, синтезы, синтезами, синтезах, синтез, синтеза, синтезу, синтез, синтезом, синтезе\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 97\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 97\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Series([], Name: English definition, dtype: int64)\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4536\n",
      "спинка\n",
      "TERM ESTIMATED FREQUENCY: 2298\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: спинка\n",
      "TERM'S INFLECTED FORMS: спинки, спинок, спинкам, спинки, спинками, спинках, спинка, спинки, спинке, спинку, спинкой, спинке\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 181\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 181\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'back']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "back    111\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: back\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 111\n",
      "ESTIMATED ENG DEF FREQUENCY: 2298\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: на спинку 24 | со спинкой 4 | за спинку 4\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 17\n",
      "\tSCALED FREQUENCY: 216\n",
      "\tLEMMED COLLOCATION: ('спинка', 'стул')\n",
      "\tORIGINAL COLLOCATION: ('спинке', 'стула')\n",
      "\tCARD FREQUENCY: 2298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "70\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4537\n",
      "угрожать\n",
      "TERM ESTIMATED FREQUENCY: 2298\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: угрожать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">угрожа́ю</font>, <font color=\"orange\">угрожа́ешь</font>, <font color=\"orange\">угрожа́ет</font>, <font color=\"orange\">угрожа́ем</font>, <font color=\"orange\">угрожа́ете</font>, <font color=\"orange\">угрожа́ют</font>, <font color=\"orange\">угрожа́й</font>, <font color=\"orange\">угрожа́йте</font>, <font color=\"orange\">угрожа́л бы</font>, <font color=\"orange\">угрожа́ла бы</font>, <font color=\"orange\">угрожа́ло бы</font>, <font color=\"orange\">угрожа́ли бы</font>, <font color=\"orange\">угрожа́ющий</font>, <font color=\"orange\">угрожа́вший</font>, <font color=\"orange\">—</font>, <font color=\"orange\"></font>, <font color=\"orange\">угрожа́я</font>, <font color=\"orange\">угрожа́в</font>, <font color=\"orange\">угрожа́л</font>, <font color=\"orange\">угрожа́ла</font>, <font color=\"orange\">угрожа́ло</font>, <font color=\"orange\">угрожа́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 3398\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 3398\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['threaten (with)' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "threaten (with)    267\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: threaten (with)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 267\n",
      "ESTIMATED ENG DEF FREQUENCY: 2298\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: угрожал в <font color=\"blue\">loct</font> 2 | угрожать в <font color=\"green\">gent</font> 1 | угрожать с <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 4\n",
      "\tSCALED FREQUENCY: 23\n",
      "\tLEMMED COLLOCATION: ('угрожать', 'человек')\n",
      "\tORIGINAL COLLOCATION: ('угрожать', 'людям')\n",
      "\tCARD FREQUENCY: 2298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "133\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4538\n",
      "делить\n",
      "TERM ESTIMATED FREQUENCY: 2297\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: делить\n",
      "TERM'S INFLECTED FORMS: <font color=\"blue\">делю́</font>, <font color=\"blue\">де́лишь</font>, <font color=\"blue\">де́лит</font>, <font color=\"blue\">де́лим</font>, <font color=\"blue\">де́лите</font>, <font color=\"blue\">де́лят</font>, <font color=\"blue\">дели́</font>, <font color=\"blue\">дели́те</font>, <font color=\"blue\">дели́л бы</font>, <font color=\"blue\">дели́ла бы</font>, <font color=\"blue\">дели́ло бы</font>, <font color=\"blue\">дели́ли бы</font>, <font color=\"blue\">деля́щий</font>, <font color=\"blue\">дели́вший</font>, <font color=\"blue\">дели́мый</font>, <font color=\"blue\">делённый</font>, <font color=\"blue\">деля́</font>, <font color=\"blue\">дели́в</font>, <font color=\"blue\">дели́л</font>, <font color=\"blue\">дели́ла</font>, <font color=\"blue\">дели́ло</font>, <font color=\"blue\">дели́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 705\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 705\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['share' 'Unmatched' 'divide; (между чем-л.) divide among']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "share                                  224\n",
      "divide; (между чем-л.) divide among     57\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: share\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 224\n",
      "ESTIMATED ENG DEF FREQUENCY: 2297\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: делил с accs 26 | делишь с <font color=\"aqua\">ablt</font> 13 | делить с <font color=\"green\">gent</font> 5\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 15\n",
      "\tSCALED FREQUENCY: 86\n",
      "\tLEMMED COLLOCATION: ('делить', 'комната')\n",
      "\tORIGINAL COLLOCATION: ('делила', 'комнату')\n",
      "\tCARD FREQUENCY: 2297\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: divide; (между чем-л.) divide among\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 57\n",
      "ESTIMATED ENG DEF FREQUENCY: 327\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "119\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4539\n",
      "должник\n",
      "TERM ESTIMATED FREQUENCY: 2296\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: должник\n",
      "TERM'S INFLECTED FORMS: должники, должников, должникам, должников, должниками, должниках, должник, должника, должнику, должника, должником, должнике\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 345\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 345\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'debtor']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "debtor    112\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: debtor\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 112\n",
      "ESTIMATED ENG DEF FREQUENCY: 2296\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: должника по <font color=\"green\">gent</font> 6 | должником с <font color=\"green\">gent</font> 2 | в должниках 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 7\n",
      "\tSCALED FREQUENCY: 47\n",
      "\tLEMMED COLLOCATION: ('предприятие', 'должник')\n",
      "\tORIGINAL COLLOCATION: ('предприятия', 'должника')\n",
      "\tCARD FREQUENCY: 2296\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4540\n",
      "ленинский\n",
      "TERM ESTIMATED FREQUENCY: 2296\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: ленинский\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 10\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 10\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'Leninist']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Leninist    3\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: Leninist\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 3\n",
      "ESTIMATED ENG DEF FREQUENCY: 2296\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 459\n",
      "\tLEMMED COLLOCATION: ('ленинский', 'союз')\n",
      "\tORIGINAL COLLOCATION: ('ленинского', 'союза')\n",
      "\tCARD FREQUENCY: 2296\n",
      "\n",
      "\n",
      "COLL INDEX: 1\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 459\n",
      "\tLEMMED COLLOCATION: ('ленинский', 'союз')\n",
      "\tORIGINAL COLLOCATION: ('ленинского', 'союза')\n",
      "\tCARD FREQUENCY: 459\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "7\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 459\n",
      "\tLEMMED COLLOCATION: ('ленинский', 'премия')\n",
      "\tORIGINAL COLLOCATION: ('ленинской', 'премии')\n",
      "\tCARD FREQUENCY: 459\n",
      "\n",
      "\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 459\n",
      "\tLEMMED COLLOCATION: ('на', 'ленинский', 'проспект')\n",
      "\tORIGINAL COLLOCATION: ('на', 'ленинском', 'проспекте')\n",
      "\tCARD FREQUENCY: 459\n",
      "\n",
      "\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 459\n",
      "\tLEMMED COLLOCATION: ('ленинский', 'проспект')\n",
      "\tORIGINAL COLLOCATION: ('ленинском', 'проспекте')\n",
      "\tCARD FREQUENCY: 459\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4541\n",
      "надевать\n",
      "TERM ESTIMATED FREQUENCY: 2296\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: надевать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">надева́ю</font>, <font color=\"orange\">надева́ешь</font>, <font color=\"orange\">надева́ет</font>, <font color=\"orange\">надева́ем</font>, <font color=\"orange\">надева́ете</font>, <font color=\"orange\">надева́ют</font>, <font color=\"orange\">надева́й</font>, <font color=\"orange\">надева́йте</font>, <font color=\"orange\">надева́л бы</font>, <font color=\"orange\">надева́ла бы</font>, <font color=\"orange\">надева́ло бы</font>, <font color=\"orange\">надева́ли бы</font>, <font color=\"orange\">надева́ющий</font>, <font color=\"orange\">надева́вший</font>, <font color=\"orange\">надева́емый</font>, <font color=\"orange\">—</font>, <font color=\"orange\">надева́я</font>, <font color=\"orange\">надева́в</font>, <font color=\"orange\">надева́л</font>, <font color=\"orange\">надева́ла</font>, <font color=\"orange\">надева́ло</font>, <font color=\"orange\">надева́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1138\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1138\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Series([], Name: English definition, dtype: int64)\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "400\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4542\n",
      "попадаться\n",
      "TERM ESTIMATED FREQUENCY: 2295\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: попадаться\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">попада́юсь</font>, <font color=\"orange\">попада́ешься</font>, <font color=\"orange\">попада́ется</font>, <font color=\"orange\">попада́емся</font>, <font color=\"orange\">попада́етесь</font>, <font color=\"orange\">попада́ются</font>, <font color=\"orange\">попада́йся</font>, <font color=\"orange\">попада́йтесь</font>, <font color=\"orange\">попада́лся бы</font>, <font color=\"orange\">попада́лась бы</font>, <font color=\"orange\">попада́лось бы</font>, <font color=\"orange\">попада́лись бы</font>, <font color=\"orange\">попада́ющийся</font>, <font color=\"orange\">попада́вшийся</font>, <font color=\"orange\">—</font>, <font color=\"orange\"></font>, <font color=\"orange\">попада́ясь</font>, <font color=\"orange\">попада́вшись</font>, <font color=\"orange\">попада́лся</font>, <font color=\"orange\">попада́лась</font>, <font color=\"orange\">попада́лось</font>, <font color=\"orange\">попада́лись</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 410\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 410\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'be caught; get'\n",
      " 'come across, chance (up)on, meet; occur, there is / are']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "be caught; get                                             230\n",
      "come across, chance (up)on, meet; occur, there is / are     71\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: be caught; get\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 230\n",
      "ESTIMATED ENG DEF FREQUENCY: 2295\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: попадайся на accs 5 | попадался в <font color=\"blue\">loct</font> 2 | попадается со <font color=\"aqua\">ablt</font> 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 6\n",
      "\tSCALED FREQUENCY: 34\n",
      "\tLEMMED COLLOCATION: ('попадаться', 'человек')\n",
      "\tORIGINAL COLLOCATION: ('попадайся', 'людям')\n",
      "\tCARD FREQUENCY: 2295\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: come across, chance (up)on, meet; occur, there is / are\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 71\n",
      "ESTIMATED ENG DEF FREQUENCY: 407\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: попадаются на <font color=\"green\">gent</font> 2 | попадалась на accs 2 | попадалась в accs 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 5\n",
      "\tSCALED FREQUENCY: 29\n",
      "\tLEMMED COLLOCATION: ('попадаться', 'на', 'глаз')\n",
      "\tORIGINAL COLLOCATION: ('попадаться', 'на', 'глаза')\n",
      "\tCARD FREQUENCY: 407\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "99\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4543\n",
      "почтовый\n",
      "TERM ESTIMATED FREQUENCY: 2295\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: почтовый\n",
      "TERM'S INFLECTED FORMS: почтовее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1079\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1079\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'post(al); mail']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "post(al); mail    88\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: post(al); mail\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 88\n",
      "ESTIMATED ENG DEF FREQUENCY: 2295\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 30\n",
      "\tSCALED FREQUENCY: 172\n",
      "\tLEMMED COLLOCATION: ('почтовый', 'отделение')\n",
      "\tORIGINAL COLLOCATION: ('почтовое', 'отделение')\n",
      "\tCARD FREQUENCY: 2295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 131\n",
      "\tSCALED FREQUENCY: 752\n",
      "\tLEMMED COLLOCATION: ('почтовый', 'ящик')\n",
      "\tORIGINAL COLLOCATION: ('почтовом', 'ящике')\n",
      "\tCARD FREQUENCY: 752\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4544\n",
      "правоохранительный\n",
      "TERM ESTIMATED FREQUENCY: 2294\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: правоохранительный\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 305\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 305\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'law-enforcement']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "law-enforcement    2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: law-enforcement\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 2294\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 8\n",
      "\tLEMMED COLLOCATION: ('программа', 'подготовка', 'персонал', 'правоохранительный', 'орган')\n",
      "\tORIGINAL COLLOCATION: ('программа', 'подготовки', 'персонала', 'правоохранительных', 'органов')\n",
      "\tCARD FREQUENCY: 2294\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "303\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 198\n",
      "\tSCALED FREQUENCY: 1489\n",
      "\tLEMMED COLLOCATION: ('правоохранительный', 'орган')\n",
      "\tORIGINAL COLLOCATION: ('правоохранительных', 'органов')\n",
      "\tCARD FREQUENCY: 1489\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4545\n",
      "ранг\n",
      "TERM ESTIMATED FREQUENCY: 2294\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: ранг\n",
      "TERM'S INFLECTED FORMS: ранги, рангов, рангам, ранги, рангами, рангах, ранг, ранга, рангу, ранг, рангом, ранге\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 245\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 245\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'rank, class']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "rank, class    97\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: rank, class\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 97\n",
      "ESTIMATED ENG DEF FREQUENCY: 2294\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: в ранге 12 | по рангу 7 | с рангом 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 7\n",
      "\tSCALED FREQUENCY: 66\n",
      "\tLEMMED COLLOCATION: ('ранг', 'посол')\n",
      "\tORIGINAL COLLOCATION: ('ранг', 'посла')\n",
      "\tCARD FREQUENCY: 2294\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "148\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4546\n",
      "слепой\n",
      "TERM ESTIMATED FREQUENCY: 2293\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: слепой\n",
      "TERM'S INFLECTED FORMS: слепее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1380\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1380\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['blind; dull; indistinct; собир. the blind' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "blind; dull; indistinct; собир. the blind    358\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: blind; dull; indistinct; собир. the blind\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 358\n",
      "ESTIMATED ENG DEF FREQUENCY: 2293\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: слепой у <font color=\"green\">gent</font> 1 | слепого к <font color=\"green\">gent</font> 1 | слепых из <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 8\n",
      "\tSCALED FREQUENCY: 46\n",
      "\tLEMMED COLLOCATION: ('слепой', 'и', 'зрячий')\n",
      "\tORIGINAL COLLOCATION: ('слепой', 'и', 'зрячий')\n",
      "\tCARD FREQUENCY: 2293\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "42\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4547\n",
      "стыд\n",
      "TERM ESTIMATED FREQUENCY: 2293\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: стыд\n",
      "TERM'S INFLECTED FORMS: стыды, стыдов, стыдам, стыды, стыдами, стыдах, стыд, стыда, стыду, стыд, стыдом, стыде\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 527\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 527\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'shame']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "shame    260\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: shame\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 260\n",
      "ESTIMATED ENG DEF FREQUENCY: 2293\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: от стыда 24 | со стыда 12 | без стыда 6\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 8\n",
      "\tSCALED FREQUENCY: 46\n",
      "\tLEMMED COLLOCATION: ('чувство', 'стыд')\n",
      "\tORIGINAL COLLOCATION: ('чувство', 'стыда')\n",
      "\tCARD FREQUENCY: 2293\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "140\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4548\n",
      "управляющий\n",
      "TERM ESTIMATED FREQUENCY: 2293\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "COOLJUGATOR SCRAPE RAISED AN ERROR:\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: управляющий\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 4724\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 4724\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'manager; (имением и т. п. || of an estate, etc.) steward']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "manager; (имением и т. п. || of an estate, etc.) steward    36\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: manager; (имением и т. п. || of an estate, etc.) steward\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 36\n",
      "ESTIMATED ENG DEF FREQUENCY: 2293\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: управляющим при <font color=\"blue\">loct</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 4\n",
      "\tSCALED FREQUENCY: 23\n",
      "\tLEMMED COLLOCATION: ('управлять', 'дело')\n",
      "\tORIGINAL COLLOCATION: ('управляющий', 'делами')\n",
      "\tCARD FREQUENCY: 2293\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "364\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4549\n",
      "христианство\n",
      "TERM ESTIMATED FREQUENCY: 2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: христианство\n",
      "TERM'S INFLECTED FORMS: христианства, христианств, христианствам, христианства, христианствами, христианствах, христианство, христианства, христианству, христианство, христианством, христианстве\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 159\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 159\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'Christianity']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Christianity    103\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: Christianity\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 103\n",
      "ESTIMATED ENG DEF FREQUENCY: 2289\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: в христианство 13 | к христианству 2 | о христианстве 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 5\n",
      "\tSCALED FREQUENCY: 72\n",
      "\tLEMMED COLLOCATION: ('принять', 'христианство')\n",
      "\tORIGINAL COLLOCATION: ('принял', 'христианство')\n",
      "\tCARD FREQUENCY: 2289\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "56\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4550\n",
      "встречный\n",
      "TERM ESTIMATED FREQUENCY: 2288\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: встречный\n",
      "TERM'S INFLECTED FORMS: встречнее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 314\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 314\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'oncoming, approaching'\n",
      " 'counter, coming from the opposite direction']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "oncoming, approaching                          21\n",
      "counter, coming from the opposite direction    14\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: oncoming, approaching\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 21\n",
      "ESTIMATED ENG DEF FREQUENCY: 2288\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 7\n",
      "\tSCALED FREQUENCY: 51\n",
      "\tLEMMED COLLOCATION: ('встречный', 'полоса')\n",
      "\tORIGINAL COLLOCATION: ('встречной', 'полосе')\n",
      "\tCARD FREQUENCY: 2288\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: counter, coming from the opposite direction\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 14\n",
      "ESTIMATED ENG DEF FREQUENCY: 102\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "279\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4551\n",
      "выявление\n",
      "TERM ESTIMATED FREQUENCY: 2287\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: выявление\n",
      "TERM'S INFLECTED FORMS: выявления, выявлений, выявлениям, выявления, выявлениями, выявлениях, выявление, выявления, выявлению, выявление, выявлением, выявлении\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 523\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 523\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'exposure, showing up; revelation']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "exposure, showing up; revelation    3\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: exposure, showing up; revelation\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 3\n",
      "ESTIMATED ENG DEF FREQUENCY: 2287\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 6\n",
      "\tLEMMED COLLOCATION: ('касаться', 'выявление', 'просчёт')\n",
      "\tORIGINAL COLLOCATION: ('касались', 'выявления', 'просчетов')\n",
      "\tCARD FREQUENCY: 2287\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "397\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4552\n",
      "график\n",
      "TERM ESTIMATED FREQUENCY: 2287\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: график\n",
      "TERM'S INFLECTED FORMS: графики, графиков, графикам, графиками, графиках, график, графика, графику, графиком, графике\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1438\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1438\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'schedule; time-table' 'diagram, graph']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "schedule; time-table    171\n",
      "diagram, graph            9\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: schedule; time-table\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 171\n",
      "ESTIMATED ENG DEF FREQUENCY: 2287\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: от графика 19 | в график 2 | с графиком 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 14\n",
      "\tSCALED FREQUENCY: 80\n",
      "\tLEMMED COLLOCATION: ('по', 'график')\n",
      "\tORIGINAL COLLOCATION: ('по', 'графику')\n",
      "\tCARD FREQUENCY: 2287\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: diagram, graph\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 9\n",
      "ESTIMATED ENG DEF FREQUENCY: 51\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "220\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4553\n",
      "доза\n",
      "TERM ESTIMATED FREQUENCY: 2286\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: доза\n",
      "TERM'S INFLECTED FORMS: дозы, доз, дозам, дозы, дозами, дозах, доза, дозы, дозе, дозу, дозой, дозе\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1069\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1069\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'dose; draught (о жидком лекарстве || of liquid medicine)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "dose; draught (о жидком лекарстве || of liquid medicine)    199\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: dose; draught (о жидком лекарстве || of liquid medicine)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 199\n",
      "ESTIMATED ENG DEF FREQUENCY: 2286\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: с дозой 6 | в дозах 4 | доза в <font color=\"green\">gent</font> 4\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 9\n",
      "\tSCALED FREQUENCY: 51\n",
      "\tLEMMED COLLOCATION: ('смертельный', 'доза')\n",
      "\tORIGINAL COLLOCATION: ('смертельная', 'доза')\n",
      "\tCARD FREQUENCY: 2286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4554\n",
      "забавный\n",
      "TERM ESTIMATED FREQUENCY: 2285\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: забавный\n",
      "TERM'S INFLECTED FORMS: забавнее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1727\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1727\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['amusing, funny' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "amusing, funny    258\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: amusing, funny\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 258\n",
      "ESTIMATED ENG DEF FREQUENCY: 2285\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: забавные у accs 1 | забавным за <font color=\"green\">gent</font> 1 | забавный до <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 11\n",
      "\tSCALED FREQUENCY: 63\n",
      "\tLEMMED COLLOCATION: ('забавный', 'история')\n",
      "\tORIGINAL COLLOCATION: ('забавные', 'истории')\n",
      "\tCARD FREQUENCY: 2285\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "142\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4555\n",
      "заслуживать\n",
      "TERM ESTIMATED FREQUENCY: 2284\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: заслуживать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">заслу́живаю</font>, <font color=\"orange\">заслу́живаешь</font>, <font color=\"orange\">заслу́живает</font>, <font color=\"orange\">заслу́живаем</font>, <font color=\"orange\">заслу́живаете</font>, <font color=\"orange\">заслу́живают</font>, <font color=\"orange\">заслу́живай</font>, <font color=\"orange\">заслу́живайте</font>, <font color=\"orange\">заслу́живал бы</font>, <font color=\"orange\">заслу́живала бы</font>, <font color=\"orange\">заслу́живало бы</font>, <font color=\"orange\">заслу́живали бы</font>, <font color=\"orange\">заслу́живающий</font>, <font color=\"orange\">заслу́живавший</font>, <font color=\"orange\">заслу́живаемый</font>, <font color=\"orange\">—</font>, <font color=\"orange\">заслу́живая</font>, <font color=\"orange\">заслу́живав</font>, <font color=\"orange\">заслу́живал</font>, <font color=\"orange\">заслу́живала</font>, <font color=\"orange\">заслу́живало</font>, <font color=\"orange\">заслу́живали</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 4586\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 4586\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['merit, deserve; win, earn, gain разг.' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "merit, deserve; win, earn, gain разг.    336\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: merit, deserve; win, earn, gain разг.\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 336\n",
      "ESTIMATED ENG DEF FREQUENCY: 2284\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: заслуживаешь в accs 1 | заслуживаю от <font color=\"green\">gent</font> 1 | заслуживаем к <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 11\n",
      "\tSCALED FREQUENCY: 63\n",
      "\tLEMMED COLLOCATION: ('заслуживать', 'смерть')\n",
      "\tORIGINAL COLLOCATION: ('заслуживаешь', 'смерти')\n",
      "\tCARD FREQUENCY: 2284\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "64\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4556\n",
      "интерьер\n",
      "TERM ESTIMATED FREQUENCY: 2283\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: интерьер\n",
      "TERM'S INFLECTED FORMS: интерьеры, интерьеров, интерьерам, интерьеры, интерьерами, интерьерах, интерьер, интерьера, интерьеру, интерьер, интерьером, интерьере\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 166\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 166\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'interior']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "interior    94\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: interior\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 94\n",
      "ESTIMATED ENG DEF FREQUENCY: 2283\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: по интерьеру 7 | о интерьере 2 | насчет интерьера 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 20\n",
      "\tSCALED FREQUENCY: 275\n",
      "\tLEMMED COLLOCATION: ('дизайнер', 'интерьер')\n",
      "\tORIGINAL COLLOCATION: ('дизайнером', 'интерьеров')\n",
      "\tCARD FREQUENCY: 2283\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "72\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4557\n",
      "как-нибудь\n",
      "TERM ESTIMATED FREQUENCY: 2281\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: как-нибудь\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1496\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1496\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'sometime, some time, some day'\n",
      " 'somehow, in some way or other' 'anyhow']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "sometime, some time, some day    117\n",
      "somehow, in some way or other     23\n",
      "anyhow                             2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: sometime, some time, some day\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 117\n",
      "ESTIMATED ENG DEF FREQUENCY: 2281\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: как-нибудь на <font color=\"blue\">loct</font> 1 | как-нибудь в <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 7\n",
      "\tSCALED FREQUENCY: 40\n",
      "\tLEMMED COLLOCATION: ('как-нибудь', 'сходить')\n",
      "\tORIGINAL COLLOCATION: ('как-нибудь', 'сходить')\n",
      "\tCARD FREQUENCY: 2281\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: somehow, in some way or other\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 23\n",
      "ESTIMATED ENG DEF FREQUENCY: 131\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: anyhow\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 11\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "258\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4558\n",
      "королева\n",
      "TERM ESTIMATED FREQUENCY: 2277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: королева\n",
      "TERM'S INFLECTED FORMS: королевы, королев, королевам, королев, королевами, королевах, королева, королевы, королеве, королеву, королевой, королеве\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 3638\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 3638\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['queen' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "queen    359\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: queen\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 359\n",
      "ESTIMATED ENG DEF FREQUENCY: 2277\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: с королевой 19 | для королевы 5 | от королевы 3\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 13\n",
      "\tSCALED FREQUENCY: 74\n",
      "\tLEMMED COLLOCATION: ('король', 'и', 'королева')\n",
      "\tORIGINAL COLLOCATION: ('король', 'и', 'королева')\n",
      "\tCARD FREQUENCY: 2277\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "41\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4559\n",
      "кредитор\n",
      "TERM ESTIMATED FREQUENCY: 2277\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: кредитор\n",
      "TERM'S INFLECTED FORMS: кредиторы, кредиторов, кредиторам, кредиторов, кредиторами, кредиторах, кредитор, кредитора, кредитору, кредитора, кредитором, кредиторе\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 278\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 278\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['creditor; mortgagee (по закладной)' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "creditor; mortgagee (по закладной)    174\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: creditor; mortgagee (по закладной)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 174\n",
      "ESTIMATED ENG DEF FREQUENCY: 2277\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: с кредиторами 7 | от кредиторов 3 | для кредиторов 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 17\n",
      "\tSCALED FREQUENCY: 139\n",
      "\tLEMMED COLLOCATION: ('обеспечить', 'кредитор')\n",
      "\tORIGINAL COLLOCATION: ('обеспеченного', 'кредитора')\n",
      "\tCARD FREQUENCY: 2277\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "104\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4560\n",
      "логический\n",
      "TERM ESTIMATED FREQUENCY: 2276\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: логический\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 228\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 228\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['logical' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "logical    135\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: logical\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 135\n",
      "ESTIMATED ENG DEF FREQUENCY: 2276\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 28\n",
      "\tSCALED FREQUENCY: 280\n",
      "\tLEMMED COLLOCATION: ('логический', 'объяснение')\n",
      "\tORIGINAL COLLOCATION: ('логическое', 'объяснение')\n",
      "\tCARD FREQUENCY: 2276\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "93\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4561\n",
      "настать\n",
      "TERM ESTIMATED FREQUENCY: 2275\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: настать\n",
      "REROUTING...\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: наставать\n",
      "TERM'S INFLECTED FORMS: <font color=\"purple\">наста́ну</font>, <font color=\"purple\">наста́нешь</font>, <font color=\"purple\">наста́нет</font>, <font color=\"purple\">наста́нем</font>, <font color=\"purple\">наста́нете</font>, <font color=\"purple\">наста́нут</font>, <font color=\"purple\">наста́нь</font>, <font color=\"purple\">наста́ньте</font>, <font color=\"purple\">наста́л бы</font>, <font color=\"purple\">наста́ла бы</font>, <font color=\"purple\">наста́ло бы</font>, <font color=\"purple\">наста́ли бы</font>, <font color=\"purple\">—</font>, <font color=\"purple\">наста́вший</font>, <font color=\"purple\"></font>, <font color=\"purple\"></font>, <font color=\"purple\"></font>, <font color=\"purple\">наста́в</font>, <font color=\"purple\">наста́л</font>, <font color=\"purple\">наста́ла</font>, <font color=\"purple\">наста́ло</font>, <font color=\"purple\">наста́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1226\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1226\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['come, begin (о времени года и т. п.)' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "come, begin (о времени года и т. п.)    143\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: come, begin (о времени года и т. п.)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 143\n",
      "ESTIMATED ENG DEF FREQUENCY: 2275\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: настал в <font color=\"blue\">loct</font> 1 | настали для <font color=\"green\">gent</font> 1 | настал из <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 31\n",
      "\tSCALED FREQUENCY: 176\n",
      "\tLEMMED COLLOCATION: ('настать', 'время')\n",
      "\tORIGINAL COLLOCATION: ('настало', 'время')\n",
      "\tCARD FREQUENCY: 2275\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "257\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 95\n",
      "\tSCALED FREQUENCY: 540\n",
      "\tLEMMED COLLOCATION: ('настать', 'время')\n",
      "\tORIGINAL COLLOCATION: ('настало', 'время')\n",
      "\tCARD FREQUENCY: 540\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4562\n",
      "непрерывный\n",
      "TERM ESTIMATED FREQUENCY: 2273\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: непрерывный\n",
      "TERM'S INFLECTED FORMS: непрерывнее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 379\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 379\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched'\n",
      " 'continuous; uninterrupted, unbroken; persistent, permanent; continual, ceaseless; steady']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "continuous; uninterrupted, unbroken; persistent, permanent; continual, ceaseless; steady    172\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: continuous; uninterrupted, unbroken; persistent, permanent; continual, ceaseless; steady\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 172\n",
      "ESTIMATED ENG DEF FREQUENCY: 2273\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 8\n",
      "\tSCALED FREQUENCY: 48\n",
      "\tLEMMED COLLOCATION: ('непрерывный', 'поток')\n",
      "\tORIGINAL COLLOCATION: ('непрерывный', 'поток')\n",
      "\tCARD FREQUENCY: 2273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4563\n",
      "обидно\n",
      "TERM ESTIMATED FREQUENCY: 2272\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: обидно\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 350\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 350\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Series([], Name: English definition, dtype: int64)\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "350\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4564\n",
      "обходиться\n",
      "TERM ESTIMATED FREQUENCY: 2272\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: обходиться\n",
      "TERM'S INFLECTED FORMS: <font color=\"blue\">обхожу́сь</font>, <font color=\"blue\">обхо́дишься</font>, <font color=\"blue\">обхо́дится</font>, <font color=\"blue\">обхо́димся</font>, <font color=\"blue\">обхо́дитесь</font>, <font color=\"blue\">обхо́дятся</font>, <font color=\"blue\">обходи́сь</font>, <font color=\"blue\">обходи́тесь</font>, <font color=\"blue\">обходи́лся бы</font>, <font color=\"blue\">обходи́лась бы</font>, <font color=\"blue\">обходи́лось бы</font>, <font color=\"blue\">обходи́лись бы</font>, <font color=\"blue\">обходя́щийся</font>, <font color=\"blue\">обходи́вшийся</font>, <font color=\"blue\">—</font>, <font color=\"blue\"></font>, <font color=\"blue\">обходя́сь</font>, <font color=\"blue\">обходи́вшись</font>, <font color=\"blue\">обходи́лся</font>, <font color=\"blue\">обходи́лась</font>, <font color=\"blue\">обходи́лось</font>, <font color=\"blue\">обходи́лись</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 552\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 552\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['manage (with), do (with), make (with); get by with' 'Unmatched'\n",
      " 'cost; come to']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "cost; come to                                         176\n",
      "manage (with), do (with), make (with); get by with    118\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: cost; come to\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 176\n",
      "ESTIMATED ENG DEF FREQUENCY: 2272\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: обходимся с <font color=\"aqua\">ablt</font> 8 | обходится в accs 4 | обходимся с accs 3\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 25\n",
      "\tSCALED FREQUENCY: 142\n",
      "\tLEMMED COLLOCATION: ('обходиться', 'без')\n",
      "\tORIGINAL COLLOCATION: ('обходится', 'без')\n",
      "\tCARD FREQUENCY: 2272\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: manage (with), do (with), make (with); get by with\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 118\n",
      "ESTIMATED ENG DEF FREQUENCY: 670\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: обходятся с <font color=\"aqua\">ablt</font> 2 | обходились со accs 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 37\n",
      "\tSCALED FREQUENCY: 210\n",
      "\tLEMMED COLLOCATION: ('обходиться', 'без')\n",
      "\tORIGINAL COLLOCATION: ('обходился', 'без')\n",
      "\tCARD FREQUENCY: 670\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "106\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4565\n",
      "отбор\n",
      "TERM ESTIMATED FREQUENCY: 2271\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: отбор\n",
      "TERM'S INFLECTED FORMS: отборы, отборов, отборам, отборы, отборами, отборах, отбор, отбора, отбору, отбор, отбором, отборе\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 969\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 969\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['selection, choice' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "selection, choice    154\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: selection, choice\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 154\n",
      "ESTIMATED ENG DEF FREQUENCY: 2271\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: для отбора 10 | по отбору 5 | к отбору 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 25\n",
      "\tSCALED FREQUENCY: 142\n",
      "\tLEMMED COLLOCATION: ('критерий', 'отбор')\n",
      "\tORIGINAL COLLOCATION: ('критериев', 'отбора')\n",
      "\tCARD FREQUENCY: 2271\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "246\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 88\n",
      "\tSCALED FREQUENCY: 500\n",
      "\tLEMMED COLLOCATION: ('отбор', 'проба')\n",
      "\tORIGINAL COLLOCATION: ('отбора', 'проб')\n",
      "\tCARD FREQUENCY: 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4566\n",
      "отчаянный\n",
      "TERM ESTIMATED FREQUENCY: 2271\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: отчаянный\n",
      "TERM'S INFLECTED FORMS: отчаяннее\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 377\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 377\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['desperate' 'Unmatched'\n",
      " 'foolhardy (о человеке || of a person), reckless (о поступке || of an act)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "desperate                                                                    247\n",
      "foolhardy (о человеке || of a person), reckless (о поступке || of an act)      6\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: desperate\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 247\n",
      "ESTIMATED ENG DEF FREQUENCY: 2271\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: отчаянным в <font color=\"blue\">loct</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 22\n",
      "\tSCALED FREQUENCY: 133\n",
      "\tLEMMED COLLOCATION: ('отчаянный', 'положение')\n",
      "\tORIGINAL COLLOCATION: ('отчаянном', 'положении')\n",
      "\tCARD FREQUENCY: 2271\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: foolhardy (о человеке || of a person), reckless (о поступке || of an act)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 6\n",
      "ESTIMATED ENG DEF FREQUENCY: 36\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "124\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4567\n",
      "пешком\n",
      "TERM ESTIMATED FREQUENCY: 2270\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: пешком\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 978\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 978\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "Series([], Name: English definition, dtype: int64)\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4568\n",
      "приз\n",
      "TERM ESTIMATED FREQUENCY: 2270\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: приз\n",
      "TERM'S INFLECTED FORMS: призы, призов, призам, призы, призами, призах, приз, приза, призу, приз, призом, призе\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 902\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 902\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'prize']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "prize    304\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: prize\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 304\n",
      "ESTIMATED ENG DEF FREQUENCY: 2270\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: за приз 7 | с призом 7 | приз за accs 7\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 27\n",
      "\tSCALED FREQUENCY: 153\n",
      "\tLEMMED COLLOCATION: ('получить', 'приз')\n",
      "\tORIGINAL COLLOCATION: ('получит', 'приз')\n",
      "\tCARD FREQUENCY: 2270\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "96\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4569\n",
      "пропускать\n",
      "TERM ESTIMATED FREQUENCY: 2266\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: пропускать\n",
      "TERM'S INFLECTED FORMS: <font color=\"orange\">пропуска́ю</font>, <font color=\"orange\">пропуска́ешь</font>, <font color=\"orange\">пропуска́ет</font>, <font color=\"orange\">пропуска́ем</font>, <font color=\"orange\">пропуска́ете</font>, <font color=\"orange\">пропуска́ют</font>, <font color=\"orange\">пропуска́й</font>, <font color=\"orange\">пропуска́йте</font>, <font color=\"orange\">пропуска́л бы</font>, <font color=\"orange\">пропуска́ла бы</font>, <font color=\"orange\">пропуска́ло бы</font>, <font color=\"orange\">пропуска́ли бы</font>, <font color=\"orange\">пропуска́ющий</font>, <font color=\"orange\">пропуска́вший</font>, <font color=\"orange\">пропуска́емый</font>, <font color=\"orange\">—</font>, <font color=\"orange\">пропуска́я</font>, <font color=\"orange\">пропуска́в</font>, <font color=\"orange\">пропуска́л</font>, <font color=\"orange\">пропуска́ла</font>, <font color=\"orange\">пропуска́ло</font>, <font color=\"orange\">пропуска́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 871\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 871\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'allow' 'miss, fail to attend; let slip'\n",
      " 'run / pass (through)' 'let pass / in / through, admit'\n",
      " 'let pass, let in; drink, absorb (о бумаге || of paper)'\n",
      " 'omit, leave out']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "miss, fail to attend; let slip                            151\n",
      "run / pass (through)                                       58\n",
      "let pass / in / through, admit                             53\n",
      "allow                                                      14\n",
      "let pass, let in; drink, absorb (о бумаге || of paper)      9\n",
      "omit, leave out                                             2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: miss, fail to attend; let slip\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 151\n",
      "ESTIMATED ENG DEF FREQUENCY: 2266\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: пропускали во <font color=\"green\">gent</font> 1 | пропускать в loc2 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 7\n",
      "\tSCALED FREQUENCY: 40\n",
      "\tLEMMED COLLOCATION: ('пропускать', 'весь', 'веселие')\n",
      "\tORIGINAL COLLOCATION: ('пропускаем', 'всё', 'веселье')\n",
      "\tCARD FREQUENCY: 2266\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: run / pass (through)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 58\n",
      "ESTIMATED ENG DEF FREQUENCY: 329\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: let pass / in / through, admit\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 53\n",
      "ESTIMATED ENG DEF FREQUENCY: 300\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 4\n",
      "ENG DEF: allow\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 14\n",
      "ESTIMATED ENG DEF FREQUENCY: 79\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 5\n",
      "ENG DEF: let pass, let in; drink, absorb (о бумаге || of paper)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 9\n",
      "ESTIMATED ENG DEF FREQUENCY: 51\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 6\n",
      "ENG DEF: omit, leave out\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 11\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "113\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4570\n",
      "сбежать\n",
      "TERM ESTIMATED FREQUENCY: 2265\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: сбежать\n",
      "TERM'S INFLECTED FORMS: <font color=\"blue\">сбегу́</font>, <font color=\"blue\">сбежи́шь</font>, <font color=\"blue\">сбежи́т</font>, <font color=\"blue\">сбежи́м</font>, <font color=\"blue\">сбежи́те</font>, <font color=\"blue\">сбегу́т</font>, <font color=\"blue\">сбеги́</font>, <font color=\"blue\">сбеги́те</font>, <font color=\"blue\">сбежа́л бы</font>, <font color=\"blue\">сбежа́ла бы</font>, <font color=\"blue\">сбежа́ло бы</font>, <font color=\"blue\">сбежа́ли бы</font>, <font color=\"blue\">—</font>, <font color=\"blue\">сбежа́вший</font>, <font color=\"blue\"></font>, <font color=\"blue\"></font>, <font color=\"blue\"></font>, <font color=\"blue\">сбежа́в</font>, <font color=\"blue\">сбежа́л</font>, <font color=\"blue\">сбежа́ла</font>, <font color=\"blue\">сбежа́ло</font>, <font color=\"blue\">сбежа́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 6473\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 6473\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'run away (from); escape' 'disappear, vanish']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "run away (from); escape    249\n",
      "disappear, vanish            4\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: run away (from); escape\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 249\n",
      "ESTIMATED ENG DEF FREQUENCY: 2265\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: сбежали с <font color=\"aqua\">ablt</font> 5 | сбежать в accs 4 | сбежать от <font color=\"green\">gent</font> 2\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 6\n",
      "\tSCALED FREQUENCY: 34\n",
      "\tLEMMED COLLOCATION: ('сбежать', 'из', 'дом')\n",
      "\tORIGINAL COLLOCATION: ('сбежал', 'из', 'дома')\n",
      "\tCARD FREQUENCY: 2265\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: disappear, vanish\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 4\n",
      "ESTIMATED ENG DEF FREQUENCY: 23\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4571\n",
      "уменьшение\n",
      "TERM ESTIMATED FREQUENCY: 2265\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: уменьшение\n",
      "TERM'S INFLECTED FORMS: уменьшения, уменьшений, уменьшениям, уменьшения, уменьшениями, уменьшениях, уменьшение, уменьшения, уменьшению, уменьшение, уменьшением, уменьшении\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 631\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 631\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['diminution, decrease, lessening; (цен и т. п. || of prices) reduction; (боли и т. п. || of pain, etc.) abatement; (вины || of fault) extenuation'\n",
      " 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "diminution, decrease, lessening; (цен и т. п. || of prices) reduction; (боли и т. п. || of pain, etc.) abatement; (вины || of fault) extenuation    187\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: diminution, decrease, lessening; (цен и т. п. || of prices) reduction; (боли и т. п. || of pain, etc.) abatement; (вины || of fault) extenuation\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 187\n",
      "ESTIMATED ENG DEF FREQUENCY: 2265\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: по уменьшению 14 | о уменьшении 2 | уменьшение в <font color=\"blue\">loct</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 26\n",
      "\tSCALED FREQUENCY: 147\n",
      "\tLEMMED COLLOCATION: ('уменьшение', 'опасность')\n",
      "\tORIGINAL COLLOCATION: ('уменьшение', 'опасности')\n",
      "\tCARD FREQUENCY: 2265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "213\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4572\n",
      "урожай\n",
      "TERM ESTIMATED FREQUENCY: 2265\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: урожай\n",
      "TERM'S INFLECTED FORMS: урож<font size=\"+5\" color=\"blue\">аи</font>, урожаи, урожаев, урожаям, урожаи, урожаями, урожаях, урожай, урожая, урожаю, урожай, урожаем, урожае\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 592\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 592\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['harvest, yield, crop' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "harvest, yield, crop    327\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: harvest, yield, crop\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 327\n",
      "ESTIMATED ENG DEF FREQUENCY: 2265\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: с урожаем 6 | на урожай 5 | урожай в loc2 4\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 43\n",
      "\tSCALED FREQUENCY: 243\n",
      "\tLEMMED COLLOCATION: ('сбор', 'урожай')\n",
      "\tORIGINAL COLLOCATION: ('сбора', 'урожая')\n",
      "\tCARD FREQUENCY: 2265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "73\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4573\n",
      "чуждый\n",
      "TERM ESTIMATED FREQUENCY: 2264\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: чуждый\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 157\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 157\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'alien (to); extraneous'\n",
      " 'stranger (to smth.); free (from), devoid (of)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "alien (to); extraneous                           58\n",
      "stranger (to smth.); free (from), devoid (of)    18\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: alien (to); extraneous\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 58\n",
      "ESTIMATED ENG DEF FREQUENCY: 2264\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: чуждое в <font color=\"purple\">datv</font> 1 | чуждую для accs 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 4\n",
      "\tSCALED FREQUENCY: 58\n",
      "\tLEMMED COLLOCATION: ('чуждый', 'понятие')\n",
      "\tORIGINAL COLLOCATION: ('чуждое', 'понятие')\n",
      "\tCARD FREQUENCY: 2264\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: stranger (to smth.); free (from), devoid (of)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 18\n",
      "ESTIMATED ENG DEF FREQUENCY: 260\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "81\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4574\n",
      "барьер\n",
      "TERM ESTIMATED FREQUENCY: 2264\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: барьер\n",
      "TERM'S INFLECTED FORMS: барьеры, барьеров, барьерам, барьеры, барьерами, барьерах, барьер, барьера, барьеру, барьер, барьером, барьере\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 561\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 561\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['barrier; bar прям. и перен.; hurdle спорт' 'Unmatched']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "barrier; bar прям. и перен.; hurdle спорт    297\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: barrier; bar прям. и перен.; hurdle спорт\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 297\n",
      "ESTIMATED ENG DEF FREQUENCY: 2264\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: барьеров на <font color=\"green\">gent</font> 26 | барьеров в <font color=\"green\">gent</font> 6 | барьером для <font color=\"green\">gent</font> 5\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 33\n",
      "\tSCALED FREQUENCY: 187\n",
      "\tLEMMED COLLOCATION: ('барьер', 'на', 'путь')\n",
      "\tORIGINAL COLLOCATION: ('барьеров', 'на', 'пути')\n",
      "\tCARD FREQUENCY: 2264\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "103\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4575\n",
      "вежливо\n",
      "TERM ESTIMATED FREQUENCY: 2263\n",
      "COOLJUGATOR_SCRAPE: QUERY NOT A NOUN, VERB OR ADJECTIVE --> NOT SCRAPING.\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: вежливо\n",
      "TERM'S INFLECTED FORMS: \n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 1121\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 1121\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'politely, courteously']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "politely, courteously    44\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: politely, courteously\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 44\n",
      "ESTIMATED ENG DEF FREQUENCY: 2263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: \n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 6\n",
      "\tLEMMED COLLOCATION: ('попрощаться', ',', 'очень', 'вежливый')\n",
      "\tORIGINAL COLLOCATION: ('попрощался', ',', 'очень', 'вежливо')\n",
      "\tCARD FREQUENCY: 2263\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "356\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4576\n",
      "дарить\n",
      "TERM ESTIMATED FREQUENCY: 2262\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: дарить\n",
      "TERM'S INFLECTED FORMS: <font color=\"blue\">дарю́</font>, <font color=\"blue\">да́ришь</font>, <font color=\"blue\">да́рит</font>, <font color=\"blue\">да́рим</font>, <font color=\"blue\">да́рите</font>, <font color=\"blue\">да́рят</font>, <font color=\"blue\">дари́</font>, <font color=\"blue\">дари́те</font>, <font color=\"blue\">дари́л бы</font>, <font color=\"blue\">дари́ла бы</font>, <font color=\"blue\">дари́ло бы</font>, <font color=\"blue\">дари́ли бы</font>, <font color=\"blue\">даря́щий</font>, <font color=\"blue\">дари́вший</font>, <font color=\"blue\">дари́мый</font>, <font color=\"blue\">да́ренный</font>, <font color=\"blue\">даря́</font>, <font color=\"blue\">дари́в</font>, <font color=\"blue\">дари́л</font>, <font color=\"blue\">дари́ла</font>, <font color=\"blue\">дари́ло</font>, <font color=\"blue\">дари́ли</font>\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 924\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 924\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['(кому-л.) give, make a present, present' 'Unmatched'\n",
      " 'favour (with), bestow (upon)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "(кому-л.) give, make a present, present    302\n",
      "favour (with), bestow (upon)                 7\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: (кому-л.) give, make a present, present\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 302\n",
      "ESTIMATED ENG DEF FREQUENCY: 2262\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: дарить в <font color=\"green\">gent</font> 2 | дарила на accs 2 | даришь на <font color=\"green\">gent</font> 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 26\n",
      "\tSCALED FREQUENCY: 147\n",
      "\tLEMMED COLLOCATION: ('дарить', 'подарок')\n",
      "\tORIGINAL COLLOCATION: ('дарю', 'подарков')\n",
      "\tCARD FREQUENCY: 2262\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: favour (with), bestow (upon)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 7\n",
      "ESTIMATED ENG DEF FREQUENCY: 40\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "91\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4577\n",
      "духи\n",
      "TERM ESTIMATED FREQUENCY: 2261\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: духи\n",
      "TERM'S INFLECTED FORMS: духи, духов, духам, духи, духами, духах\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 5060\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 5060\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'perfume ед., scent ед.']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "perfume ед., scent ед.    25\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: perfume ед., scent ед.\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 25\n",
      "ESTIMATED ENG DEF FREQUENCY: 2261\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: о духах 1 | от духов 1 | из-под духов 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 2\n",
      "\tSCALED FREQUENCY: 11\n",
      "\tLEMMED COLLOCATION: ('новое', 'дух')\n",
      "\tORIGINAL COLLOCATION: ('новые', 'духи')\n",
      "\tCARD FREQUENCY: 2261\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "375\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.\n",
      "\n",
      "\n",
      "\n",
      "4578\n",
      "елка\n",
      "TERM ESTIMATED FREQUENCY: 2258\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: елка\n",
      "TERM'S INFLECTED FORMS: ёлки, ёлок, ёлкам, ёлки, ёлками, ёлках, ёлка, ёлки, ёлке, ёлку, ёлкой, ёлке\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 440\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 440\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'fir(-tree)']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "fir(-tree)    2\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: fir(-tree)\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 2\n",
      "ESTIMATED ENG DEF FREQUENCY: 2258\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: ёлку к loc2 1\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 1\n",
      "\tSCALED FREQUENCY: 6\n",
      "\tLEMMED COLLOCATION: ('семья', 'наряжать', 'ёлка')\n",
      "\tORIGINAL COLLOCATION: ('семья', 'наряжает', 'ёлку')\n",
      "\tCARD FREQUENCY: 2258\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "398\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 75\n",
      "\tSCALED FREQUENCY: 423\n",
      "\tLEMMED COLLOCATION: ('рождественский', 'ёлка')\n",
      "\tORIGINAL COLLOCATION: ('рождественская', 'ёлка')\n",
      "\tCARD FREQUENCY: 423\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4579\n",
      "захват\n",
      "TERM ESTIMATED FREQUENCY: 2257\n",
      "RESPONSE FROM COOLJUGATOR: <Response [200]>\n",
      "RESPONSE FROM ABBYY LINGVO LIVE DICTIONARY: <Response [200]>\n",
      "TERM: захват\n",
      "TERM'S INFLECTED FORMS: захваты, захватов, захватам, захваты, захватами, захватах, захват, захвата, захвату, захват, захватом, захвате\n",
      "\n",
      "\n",
      "NUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES: 782\n",
      "NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES: 782\n",
      "RESULTS DF REDUCED TO 400 PAIRED SENTENCES.\n",
      "\n",
      "RESULTS_DF.UNIQUE() ['Unmatched' 'seizure, capture, taking, take, takeover; usurpation'\n",
      " 'clench, clinch, clutch, hold' 'claw']\n",
      "\n",
      "ENG DEF VALUE COUNTS:\n",
      "seizure, capture, taking, take, takeover; usurpation    100\n",
      "clench, clinch, clutch, hold                             35\n",
      "claw                                                      3\n",
      "Name: English definition, dtype: int64\n",
      "\n",
      "ENG DEF INDEX: 1\n",
      "ENG DEF: seizure, capture, taking, take, takeover; usurpation\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 100\n",
      "ESTIMATED ENG DEF FREQUENCY: 2257\n",
      "\n",
      "\tCOUNT COLLS: EST MIN COLL FREQ: 370\n",
      "\tCOUNT COLLS: RAW MIN COLL FREQ: 2\n",
      "\tCOUNT COLLS: FILTERING FOR LEX COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR GRAM COLLS ABOVE MIN COLL FREQ\n",
      "\tCOUNT COLLS: FILTERING FOR DEFAULT LEX COLL BELOW MIN COLL FREQ\n",
      "TOP THREE GRAM COLLS: с захватом 11 | для захвата 6 | по захвату 4\n",
      "\n",
      "\n",
      "CARDS FOR ENG DEF ONLY:\n",
      "\n",
      "\tCOLLOCATION TYPE: lex\n",
      "\tRAW FREQUENCY: 19\n",
      "\tSCALED FREQUENCY: 107\n",
      "\tLEMMED COLLOCATION: ('захват', 'заложник')\n",
      "\tORIGINAL COLLOCATION: ('захват', 'заложника')\n",
      "\tCARD FREQUENCY: 2257\n",
      "\n",
      "\n",
      "\n",
      "ENG DEF INDEX: 2\n",
      "ENG DEF: clench, clinch, clutch, hold\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 35\n",
      "ESTIMATED ENG DEF FREQUENCY: 197\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "ENG DEF INDEX: 3\n",
      "ENG DEF: claw\n",
      "NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION: 3\n",
      "ESTIMATED ENG DEF FREQUENCY: 17\n",
      "ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.\n",
      "\n",
      "\n",
      "NON MATCHED SENTS:\n",
      "262\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-96ce14ceba50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mq_forms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_forms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0mreturn_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'English definition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Unmatched'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolls_from_sents_df_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_forms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq_forms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mlex_colls_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_matched_sents_colls_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_three_gram_colls_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_to_top_coll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_colls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_forms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_min_coll_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest_min_coll_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest_non_matched_sents_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'English definition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Unmatched'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimated_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced_concordance_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mtop_three_gram_colls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-401a687caac2>\u001b[0m in \u001b[0;36mcount_colls\u001b[1;34m(sent_packages, query_forms, raw_min_coll_freq, est_min_coll_freq, est_eng_def_freq, raw_eng_def_freq, est_term_freq, raw_term_freq)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;31m#                 top_n_gram_row['Target sentence'] = top_n_gram_row['Target sentence'].str.replace(' ' + top_eng_coll + ' ', ' <b>' + top_eng_coll + '</b> ', regex = False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;31m#top_n_gram_row['Frequency'] = round(est_eng_def_freq * len(group_df.index)/raw_eng_def_freq)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[0mcolls_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolls_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_n_gram_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0mcolls_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolls_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Frequency'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7136\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7137\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7138\u001b[1;33m             \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7139\u001b[0m         )\n\u001b[0;32m   7140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 473\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m             )\n\u001b[0;32m    475\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2052\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m             b = make_block(\n\u001b[1;32m-> 2054\u001b[1;33m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36m_concat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_freq_rank = 4500\n",
    "end_freq_rank = 5000\n",
    "limited_freq_list = rnc_freq_list.iloc[start_freq_rank:end_freq_rank]\n",
    "reduced_df_size = 8000000\n",
    "max_concordance_results = 400\n",
    "est_min_coll_freq = 370\n",
    "raw_min_coll_freq = 2\n",
    "\n",
    "deck_name = 'Russian Vocab ' + str(start_freq_rank) + '-' + str(end_freq_rank)\n",
    "\n",
    "my_deck = genanki.Deck(2059400110, deck_name)\n",
    "\n",
    "reduced_df = para_texts_df.iloc[0:reduced_df_size]\n",
    "\n",
    "for index, row in limited_freq_list.iterrows():\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(index)\n",
    "    query = row['Word']\n",
    "    print(query)\n",
    "    freq_rank = row['Frequency rank']\n",
    "    estimated_freq = row['Estimated frequency']\n",
    "    print('TERM ESTIMATED FREQUENCY:', str(estimated_freq))\n",
    "    query_pos_full = row['PoS tag']\n",
    "\n",
    "    return_dict = eng_trans_and_syns(query, query_pos_full)\n",
    "    inflected_eng_defs = return_dict['inflected_eng_defs']\n",
    "    term_gender_colour = return_dict['term_gender_colour']\n",
    "    term_with_accent = return_dict['term_with_accent']\n",
    "    case_taken = return_dict['case_taken']\n",
    "    disting_gram_info = return_dict['disting_gram_info']\n",
    "    conjugation_declension_info = ', '.join(return_dict['conjugation_declension_info'])\n",
    "\n",
    "    query_forms = []\n",
    "    query_parse = morph.parse(query)[0]\n",
    "    for word_form in query_parse.lexeme:\n",
    "        form = word_form[0]\n",
    "        query_forms.append(form)\n",
    "        if 'ё' in form:\n",
    "            query_forms.append(form.replace('ё', 'е'))\n",
    "    query_forms = list(set(query_forms))\n",
    "\n",
    "    p = morph.parse(query)[0]\n",
    "    lemmed_query = p.normal_form\n",
    "    results_df = reduced_df[reduced_df['Lemmed source sentence'].str.contains(' ' + lemmed_query + ' ', regex = False)]\n",
    "\n",
    "    print('\\n\\nNUMBER OF CONCORDANCE RESULTS BEFORE DELETING DUPLICATES:', len(results_df.index))\n",
    "    results_df = results_df.drop_duplicates('Source sentence')\n",
    "    print('NUMBER OF CONCORDANCE RESULTS AFTER DELETING DUPLICATES:', len(results_df.index))\n",
    "    concordance_freq = len(results_df.iloc[:])\n",
    "    if len(results_df.index) > max_concordance_results:\n",
    "        print('RESULTS DF REDUCED TO ' + str(max_concordance_results) + ' PAIRED SENTENCES.')\n",
    "        results_df = results_df.iloc[0:max_concordance_results]\n",
    "    reduced_concordance_freq = len(results_df.iloc[:])\n",
    "\n",
    "    results_df['English definition'] = 'Unmatched'\n",
    "    eng_def_idx = 1\n",
    "    for basic_def, all_forms in inflected_eng_defs.items():\n",
    "        for form in all_forms:\n",
    "            form = form.strip().replace('.', ' ')\n",
    "            form_wds = form.split(' ')\n",
    "            wd_count = len(form_wds)\n",
    "            if wd_count == 1:\n",
    "                results_df[results_df['Standardised target sentence'].str.contains(' ' +  form + ' ', regex=False)] = results_df[results_df['Standardised target sentence'].str.contains(' ' +  form + ' ', regex=False)].replace('Unmatched', basic_def)\n",
    "            elif wd_count == 2:\n",
    "                results_df[results_df['Standardised target sentence'].str.contains(' ' +  form + ' ', regex=False)]['English definition'] = results_df[results_df['Standardised target sentence'].str.contains(' ' +  form + ' ', regex=False)]['English definition'].replace('Unmatched', basic_def)\n",
    "                results_df[results_df['Standardised target sentence'].str.contains(' '+form_wds[0]+'.*'+form_wds[1]+' ', regex=True)]['English definition'] = results_df[results_df['Standardised target sentence'].str.contains(' '+form_wds[0]+'.*'+form_wds[1]+' ', regex=True)]['English definition'].replace('Unmatched', basic_def)\n",
    "            elif wd_count == 3:\n",
    "                results_df[results_df['Standardised target sentence'].str.contains(' ' +  form + ' ', regex=False)]['English definition'] = results_df[results_df['Standardised target sentence'].str.contains(' ' +  form + ' ', regex=False)]['English definition'].replace('Unmatched', basic_def)\n",
    "                results_df[results_df['Standardised target sentence'].str.contains(' '+form_wds[0]+'.*'+form_wds[1]+' '+'.*'+form_wds[2]+' ', regex=True)]['English definition'] = results_df[results_df['Standardised target sentence'].str.contains(' '+form_wds[0]+'.*'+form_wds[1]+' '+'.*'+form_wds[2]+' ', regex=True)]['English definition'].replace('Unmatched', basic_def)\n",
    "\n",
    "    print('\\nRESULTS_DF.UNIQUE()', results_df['English definition'].unique())\n",
    "    eng_def_idx = 1\n",
    "    print('\\nENG DEF VALUE COUNTS:')\n",
    "    print(results_df[results_df['English definition']!='Unmatched']['English definition'].value_counts())\n",
    "\n",
    "    basic_defs = results_df[results_df['English definition']!='Unmatched']['English definition'].value_counts().index.tolist()\n",
    "    for eng_def in basic_defs:\n",
    "        print('\\nENG DEF INDEX:', eng_def_idx)\n",
    "        print('ENG DEF:', eng_def)\n",
    "        eng_def_df = results_df[results_df['English definition']==eng_def]\n",
    "        if eng_def_df.empty == True:\n",
    "            pass\n",
    "        else:\n",
    "            eng_def_df = eng_def_df.drop_duplicates('Source sentence')\n",
    "            print('NUMBER OF SENTENCES FOR THIS ENGLISH DEFINITION:', len(eng_def_df.index))\n",
    "            if eng_def_idx == 1:\n",
    "                eng_def_freq = estimated_freq\n",
    "            else:\n",
    "                eng_def_freq = round(estimated_freq * (len(eng_def_df.index)/reduced_concordance_freq))\n",
    "            print('ESTIMATED ENG DEF FREQUENCY:', eng_def_freq)\n",
    "\n",
    "            if eng_def_freq < est_min_coll_freq:\n",
    "                print('ESTIMATED ENGLISH DEFINITION FREQUENCY IS LOWER THAN MINIMUM COLL FREQUENCY --> NOT WRITING ANY FLASHCARDS FOR IT.')\n",
    "            else:\n",
    "                q_forms = query_forms\n",
    "                return_series = eng_def_df.apply(colls_from_sents_df_row, query_forms=q_forms, axis=1)\n",
    "                lex_colls_df, eng_def_colls_df, top_three_gram_colls_df, default_to_top_coll = count_colls(return_series.tolist(), q_forms, raw_min_coll_freq, est_min_coll_freq, eng_def_freq, len(eng_def_df.index), estimated_freq, reduced_concordance_freq)\n",
    "                \n",
    "                case_colour_dict = {'gent' : 'green',\n",
    "                                    'datv' : 'purple',\n",
    "                                   'loct' : 'blue',\n",
    "                                   'ablt' : 'aqua'}\n",
    "                gram_coll_list = []\n",
    "                for index, row in top_three_gram_colls_df.iterrows():\n",
    "                    gram_coll = ' '.join(row['Original collocation'])\n",
    "                    for key, value in case_colour_dict.items():\n",
    "                        if key in gram_coll:\n",
    "                            gram_coll = gram_coll.replace(key, '<font color=\"' + value + '\">' + key + '</font>')\n",
    "                    gram_coll_list.append(gram_coll + ' ' + str(row['Raw frequency']))\n",
    "                top_three_gram_colls = ' | '.join(gram_coll_list)\n",
    "                print('TOP THREE GRAM COLLS:', top_three_gram_colls)\n",
    "                print('\\n')\n",
    "\n",
    "                if eng_def_colls_df.empty == True:\n",
    "                    print('ENG DEF COLLS DF RETURNED EMPTY.')\n",
    "                else:\n",
    "                    # Create cards for the English definition only\n",
    "                    print('CARDS FOR ENG DEF ONLY:')\n",
    "                    row = eng_def_colls_df.iloc[0]\n",
    "                    card_freq = eng_def_freq\n",
    "                    term_or_collocation = 'Term'\n",
    "                    tl_test = query\n",
    "                    en_test = eng_def\n",
    "                    other_defs = '<br>'.join([item for item in basic_defs if item != eng_def])\n",
    "\n",
    "                    source_sent_one = row['Source sentence with term bold']\n",
    "                    target_sent_one = row['Target sentence']\n",
    "                    \n",
    "                    other_sent_pairs_en = ''\n",
    "                    other_sent_pairs_ru_term_in_bold = ''\n",
    "                    other_sent_pairs_ru_coll_in_bold = ''\n",
    "                    other_sent_pairs_en_ru_term_in_bold = ''\n",
    "                    other_sent_pairs_ru_term_in_bold_en = ''\n",
    "                    other_sent_pairs_en_ru_coll_in_bold = ''\n",
    "                    other_sent_pairs_ru_coll_in_bold_en = ''\n",
    "                    idx = 1\n",
    "                    for index, lex_coll_row in lex_colls_df.iloc[1:].iterrows():\n",
    "                        other_sent_pairs_en += lex_coll_row['Target sentence'] + '<br><br>'\n",
    "                        other_sent_pairs_ru_term_in_bold += lex_coll_row['Source sentence with term bold'] + '<br><br>'\n",
    "                        other_sent_pairs_ru_coll_in_bold += lex_coll_row['Source sentence with coll bold'] + '<br><br>'\n",
    "                        other_sent_pairs_en_ru_term_in_bold += str(lex_coll_row['Target sentence']) + '<br>' + '<font color=\\\"green\\\">' + lex_coll_row['Source sentence with term bold'] + '</font>' + '<br><br>'\n",
    "                        other_sent_pairs_ru_term_in_bold_en += lex_coll_row['Source sentence with term bold'] + '<br>' + '<font color=\\\"green\\\">' + lex_coll_row['Target sentence'] + '</font>' + '<br><br>'\n",
    "                        other_sent_pairs_en_ru_coll_in_bold += str(lex_coll_row['Target sentence']) + '<br>' + '<font color=\\\"green\\\">' + lex_coll_row['Source sentence with coll bold'] + '</font>' + '<br><br>'\n",
    "                        other_sent_pairs_ru_coll_in_bold_en += lex_coll_row['Source sentence with coll bold'] + '<br>' + '<font color=\\\"green\\\">' + lex_coll_row['Target sentence'] + '</font>' + '<br><br>'\n",
    "                        idx += 1\n",
    "                        if idx == 7:\n",
    "                            break\n",
    "\n",
    "                    print('\\n\\tCOLLOCATION TYPE:', row['Collocation type'])\n",
    "                    print('\\tRAW FREQUENCY:', row['Raw frequency'])\n",
    "                    print('\\tSCALED FREQUENCY:', row['Frequency'])\n",
    "                    print('\\tLEMMED COLLOCATION:', row['Lemmed collocation'])\n",
    "                    print('\\tORIGINAL COLLOCATION:', row['Original collocation'])\n",
    "                    print('\\tCARD FREQUENCY:', card_freq)\n",
    "                    print('\\n')\n",
    "\n",
    "                    tl_en_note = genanki.Note(\n",
    "                    model = tl_en_note_type,\n",
    "                    fields = [str(card_freq),\n",
    "                             str(freq_rank) + ' d' + str(eng_def_idx),\n",
    "                             term_or_collocation,\n",
    "                              tl_test,\n",
    "                              en_test,\n",
    "                              '<font color=\\\"' + term_gender_colour + '\\\">' + term_with_accent + '</font>' + case_taken,\n",
    "                              disting_gram_info,\n",
    "                              conjugation_declension_info,\n",
    "                              top_three_gram_colls,\n",
    "                              eng_def,\n",
    "                              other_defs,\n",
    "                              source_sent_one,\n",
    "                              target_sent_one,\n",
    "                              str(row['Source']),\n",
    "                              other_sent_pairs_ru_term_in_bold,\n",
    "                              other_sent_pairs_ru_term_in_bold_en\n",
    "                                ]\n",
    "                    )\n",
    "\n",
    "                    my_deck.add_note(tl_en_note)\n",
    "\n",
    "                    en_tl_note = genanki.Note(\n",
    "                    model = en_tl_note_type,\n",
    "                    fields = [str(round(card_freq * 1.05)),\n",
    "                            str(freq_rank) + ' d' + str(eng_def_idx),\n",
    "                             term_or_collocation,\n",
    "                              en_test,\n",
    "                              tl_test,\n",
    "                              '<font color=\\\"' + term_gender_colour + '\\\">' + term_with_accent + '</font>' + case_taken,\n",
    "                              disting_gram_info,\n",
    "                              conjugation_declension_info,\n",
    "                              top_three_gram_colls,\n",
    "                              eng_def,\n",
    "                              other_defs,\n",
    "                              source_sent_one,\n",
    "                              target_sent_one,\n",
    "                              str(row['Source']),\n",
    "                              other_sent_pairs_en,\n",
    "                              other_sent_pairs_en_ru_term_in_bold\n",
    "                                ]\n",
    "                    )\n",
    "\n",
    "                    my_deck.add_note(en_tl_note)\n",
    "\n",
    "                    # Create cards for each collocation of the English definition\n",
    "                    if default_to_top_coll == False:\n",
    "                        coll_idx = 1\n",
    "                        for index, row in eng_def_colls_df.iterrows():\n",
    "\n",
    "                            print('COLL INDEX:', coll_idx)\n",
    "                            card_freq = row['Frequency']\n",
    "                            term_or_collocation = 'Collocation'\n",
    "                            tl_test = ' '.join(row['Original collocation'])\n",
    "                            en_test = row['Target sentence']\n",
    "                            other_defs = '<br>'.join([item for item in basic_defs if item != eng_def])\n",
    "\n",
    "                            source_sent_one = row['Source sentence with coll bold']\n",
    "                            target_sent_one = row['Target sentence']\n",
    "\n",
    "                            other_sent_pairs_en = row['Other sentence pairs en']\n",
    "                            other_sent_pairs_ru_term_in_bold = row['Other sentence pairs ru term in bold']\n",
    "                            other_sent_pairs_ru_coll_in_bold = row['Other sentence pairs ru coll in bold']\n",
    "                            other_sent_pairs_en_ru_term_in_bold = row['Other sentence pairs en ru term in bold']\n",
    "                            other_sent_pairs_ru_term_in_bold_en = row['Other sentence pairs ru term in bold en']\n",
    "                            other_sent_pairs_en_ru_coll_in_bold = row['Other sentence pairs en ru coll in bold']\n",
    "                            other_sent_pairs_ru_coll_in_bold_en = row['Other sentence pairs ru coll in bold en']\n",
    "\n",
    "                            print('\\n\\tCOLLOCATION TYPE:', row['Collocation type'])\n",
    "                            print('\\tRAW FREQUENCY:', row['Raw frequency'])\n",
    "                            print('\\tSCALED FREQUENCY:', row['Frequency'])\n",
    "                            print('\\tLEMMED COLLOCATION:', row['Lemmed collocation'])\n",
    "                            print('\\tORIGINAL COLLOCATION:', row['Original collocation'])\n",
    "                            print('\\tCARD FREQUENCY:', card_freq)\n",
    "                            print('\\n')\n",
    "                            \n",
    "                            # Check if a card for the collocation has already been written\n",
    "                            if row['Lemmed collocation'] not in colls_written_to_cards:\n",
    "                    \n",
    "                                colls_written_to_cards.append(row['Lemmed collocation'])\n",
    "\n",
    "                                tl_en_note = genanki.Note(\n",
    "                                model = tl_en_note_type,\n",
    "                                fields = [str(card_freq),\n",
    "                                         str(freq_rank) + ' d' + str(eng_def_idx) + ' c' + str(coll_idx),\n",
    "                                         term_or_collocation,\n",
    "                                          tl_test,\n",
    "                                          en_test,\n",
    "                                          '<font color=\\\"' + term_gender_colour + '\\\">' + term_with_accent + '</font>' + case_taken,\n",
    "                                          disting_gram_info,\n",
    "                                          conjugation_declension_info,\n",
    "                                          top_three_gram_colls,\n",
    "                                          eng_def,\n",
    "                                          other_defs,\n",
    "                                          source_sent_one,\n",
    "                                          target_sent_one,\n",
    "                                          str(row['Source']),\n",
    "                                          other_sent_pairs_ru_coll_in_bold,\n",
    "                                          other_sent_pairs_ru_coll_in_bold_en\n",
    "                                            ]\n",
    "                                )\n",
    "\n",
    "                                my_deck.add_note(tl_en_note)\n",
    "\n",
    "                                en_tl_note = genanki.Note(\n",
    "                                model = en_tl_note_type,\n",
    "                                fields = [str(round(card_freq * 1.05)),\n",
    "                                        str(freq_rank) + ' d' + str(eng_def_idx) + ' c' + str(coll_idx),\n",
    "                                         term_or_collocation,\n",
    "                                          en_test,\n",
    "                                          tl_test,\n",
    "                                          '<font color=\\\"' + term_gender_colour + '\\\">' + term_with_accent + '</font>' + case_taken,\n",
    "                                          disting_gram_info,\n",
    "                                          conjugation_declension_info,\n",
    "                                          top_three_gram_colls,\n",
    "                                          eng_def,\n",
    "                                          other_defs,\n",
    "                                        source_sent_one,\n",
    "                                          target_sent_one,\n",
    "                                          str(row['Source']),\n",
    "                                          other_sent_pairs_en,\n",
    "                                          other_sent_pairs_en_ru_coll_in_bold\n",
    "                                            ]\n",
    "                                )\n",
    "\n",
    "                                my_deck.add_note(en_tl_note)\n",
    "\n",
    "                            coll_idx += 1                  \n",
    "\n",
    "        eng_def_idx += 1\n",
    "\n",
    "    print('\\n\\nNON MATCHED SENTS:')\n",
    "    print(len(results_df[results_df['English definition']=='Unmatched'].index))\n",
    "    # Find the top collocations in the unmatched sentences\n",
    "    if len(results_df[results_df['English definition']=='Unmatched'].index) != 0:\n",
    "        est_non_matched_sents_freq = round(estimated_freq * len(results_df.index)/concordance_freq)\n",
    "        q_forms = query_forms\n",
    "        return_series = results_df[results_df['English definition']=='Unmatched'].apply(colls_from_sents_df_row, query_forms=q_forms, axis=1)\n",
    "        lex_colls_df, non_matched_sents_colls_df, top_three_gram_colls_df, default_to_top_coll = count_colls(return_series.tolist(), q_forms, raw_min_coll_freq, est_min_coll_freq, est_non_matched_sents_freq, len(results_df[results_df['English definition']=='Unmatched'].index), estimated_freq, reduced_concordance_freq)\n",
    "\n",
    "        top_three_gram_colls = ''\n",
    "\n",
    "        if default_to_top_coll == True:\n",
    "            print('NO COLLS FOUND ABOVE MINIMUM FREQUENCIES --> NOT WRITING ANY FLASHCARDS.')\n",
    "        else:\n",
    "            if non_matched_sents_colls_df.empty == True:\n",
    "                print('NON MATCHED SENTS COLLS DF RETURNED EMPTY.')\n",
    "            else:\n",
    "                coll_idx = 1\n",
    "                for index, row in non_matched_sents_colls_df.iterrows():\n",
    "\n",
    "                    term_or_collocation = 'Collocation'\n",
    "                    eng_def = ''\n",
    "                    other_defs = '<br>'.join(basic_defs)\n",
    "                    card_freq = row['Frequency']\n",
    "                    tl_test = ' '.join(row['Original collocation'])\n",
    "                    en_test = row['Target sentence']\n",
    "\n",
    "                    source_sent_one = row['Source sentence with coll bold']\n",
    "                    target_sent_one = row['Target sentence']\n",
    "\n",
    "                    other_sent_pairs_en = row['Other sentence pairs en']\n",
    "                    other_sent_pairs_ru_term_in_bold = row['Other sentence pairs ru term in bold']\n",
    "                    other_sent_pairs_ru_coll_in_bold = row['Other sentence pairs ru coll in bold']\n",
    "                    other_sent_pairs_en_ru_term_in_bold = row['Other sentence pairs en ru term in bold']\n",
    "                    other_sent_pairs_ru_term_in_bold_en = row['Other sentence pairs ru term in bold en']\n",
    "                    other_sent_pairs_en_ru_coll_in_bold = row['Other sentence pairs en ru coll in bold']\n",
    "                    other_sent_pairs_ru_coll_in_bold_en = row['Other sentence pairs ru coll in bold en']\n",
    "\n",
    "                    print('\\n\\tCOLLOCATION TYPE:', row['Collocation type'])\n",
    "                    print('\\tRAW FREQUENCY:', row['Raw frequency'])\n",
    "                    print('\\tSCALED FREQUENCY:', row['Frequency'])\n",
    "                    print('\\tLEMMED COLLOCATION:', row['Lemmed collocation'])\n",
    "                    print('\\tORIGINAL COLLOCATION:', row['Original collocation'])\n",
    "                    print('\\tCARD FREQUENCY:', card_freq)\n",
    "                    print('\\n')\n",
    "                    \n",
    "                    # Check if a card for the collocation has already been written\n",
    "                    if row['Lemmed collocation'] not in colls_written_to_cards:\n",
    "                                \n",
    "                        colls_written_to_cards.append(row['Lemmed collocation'])\n",
    "                        \n",
    "                        tl_en_note = genanki.Note(\n",
    "                            model = tl_en_note_type,\n",
    "                            fields = [str(card_freq),\n",
    "                                    str(freq_rank) + ' c' + str(coll_idx),\n",
    "                                     term_or_collocation,\n",
    "                                      tl_test,\n",
    "                                      en_test,\n",
    "                                      '<font color=\\\"' + term_gender_colour + '\\\">' + term_with_accent + '</font>' + case_taken,\n",
    "                                      disting_gram_info,\n",
    "                                      conjugation_declension_info,\n",
    "                                      top_three_gram_colls,\n",
    "                                      eng_def,\n",
    "                                      other_defs,\n",
    "                                      source_sent_one,\n",
    "                                      target_sent_one,\n",
    "                                      str(row['Source']),\n",
    "                                      other_sent_pairs_ru_coll_in_bold,\n",
    "                                        other_sent_pairs_ru_coll_in_bold_en\n",
    "                                        ]\n",
    "                        )\n",
    "\n",
    "                        my_deck.add_note(tl_en_note)\n",
    "\n",
    "                        en_tl_note = genanki.Note(\n",
    "                        model = en_tl_note_type,\n",
    "                        fields = [str(round(card_freq * 1.05)),\n",
    "                                  str(freq_rank) + ' c' + str(coll_idx),\n",
    "                                 term_or_collocation,\n",
    "                                  en_test,\n",
    "                                  tl_test,\n",
    "                                  '<font color=\\\"' + term_gender_colour + '\\\">' + term_with_accent + '</font>' + case_taken,\n",
    "                                  disting_gram_info,\n",
    "                                  conjugation_declension_info,\n",
    "                                  top_three_gram_colls,\n",
    "                                  eng_def,\n",
    "                                  other_defs,\n",
    "                                  source_sent_one,\n",
    "                                  target_sent_one,\n",
    "                                  str(row['Source']),\n",
    "                                   other_sent_pairs_en,\n",
    "                                    other_sent_pairs_en_ru_coll_in_bold\n",
    "                                    ]\n",
    "                        )\n",
    "\n",
    "                        my_deck.add_note(en_tl_note)\n",
    "\n",
    "                    coll_idx += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_elapsed = end_time - start_time\n",
    "    if time_elapsed <= 18:\n",
    "        time.sleep(18 - time_elapsed)\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n",
    "genanki.Package(my_deck).write_to_file('C:\\\\Users\\\\MdeCL\\\\Desktop\\\\Vocab Project Desktop Files\\\\russian_vocab.apkg')\n",
    "\n",
    "print('\\n\\nFlashcard writing complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Export Anki deck file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "genanki.Package(my_deck).write_to_file('C:\\\\Users\\\\MdeCL\\\\Desktop\\\\Vocab Project Desktop Files\\\\russian_vocab.apkg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
